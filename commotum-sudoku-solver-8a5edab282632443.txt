Directory structure:
└── commotum-sudoku-solver/
    ├── README.md
    ├── conftest.py
    ├── main.py
    ├── requirements.txt
    ├── data/
    │   ├── dataset_download.py
    │   └── sudoku-extreme-processed/
    │       ├── lvl-0-inputs.npy
    │       ├── lvl-0-outputs.npy
    │       ├── lvl-1-inputs.npy
    │       ├── lvl-1-outputs.npy
    │       ├── lvl-10-inputs.npy
    │       ├── lvl-10-outputs.npy
    │       ├── lvl-100-inputs.npy
    │       ├── lvl-100-outputs.npy
    │       ├── lvl-101-inputs.npy
    │       ├── lvl-101-outputs.npy
    │       ├── lvl-102-inputs.npy
    │       ├── lvl-102-outputs.npy
    │       ├── lvl-103-inputs.npy
    │       ├── lvl-103-outputs.npy
    │       ├── lvl-104-inputs.npy
    │       ├── lvl-104-outputs.npy
    │       ├── lvl-105-inputs.npy
    │       ├── lvl-105-outputs.npy
    │       ├── lvl-106-inputs.npy
    │       ├── lvl-106-outputs.npy
    │       ├── lvl-107-inputs.npy
    │       ├── lvl-107-outputs.npy
    │       ├── lvl-108-inputs.npy
    │       ├── lvl-108-outputs.npy
    │       ├── lvl-109-inputs.npy
    │       ├── lvl-109-outputs.npy
    │       ├── lvl-11-inputs.npy
    │       ├── lvl-11-outputs.npy
    │       ├── lvl-110-inputs.npy
    │       ├── lvl-110-outputs.npy
    │       ├── lvl-111-inputs.npy
    │       ├── lvl-111-outputs.npy
    │       ├── lvl-112-inputs.npy
    │       ├── lvl-112-outputs.npy
    │       ├── lvl-113-inputs.npy
    │       ├── lvl-113-outputs.npy
    │       ├── lvl-114-inputs.npy
    │       ├── lvl-114-outputs.npy
    │       ├── lvl-115-inputs.npy
    │       ├── lvl-115-outputs.npy
    │       ├── lvl-116-inputs.npy
    │       ├── lvl-116-outputs.npy
    │       ├── lvl-117-inputs.npy
    │       ├── lvl-117-outputs.npy
    │       ├── lvl-118-inputs.npy
    │       ├── lvl-118-outputs.npy
    │       ├── lvl-119-inputs.npy
    │       ├── lvl-119-outputs.npy
    │       ├── lvl-12-inputs.npy
    │       ├── lvl-12-outputs.npy
    │       ├── lvl-120-inputs.npy
    │       ├── lvl-120-outputs.npy
    │       ├── lvl-121-inputs.npy
    │       ├── lvl-121-outputs.npy
    │       ├── lvl-122-inputs.npy
    │       ├── lvl-122-outputs.npy
    │       ├── lvl-123-inputs.npy
    │       ├── lvl-123-outputs.npy
    │       ├── lvl-124-inputs.npy
    │       ├── lvl-124-outputs.npy
    │       ├── lvl-125-inputs.npy
    │       ├── lvl-125-outputs.npy
    │       ├── lvl-126-inputs.npy
    │       ├── lvl-126-outputs.npy
    │       ├── lvl-127-inputs.npy
    │       ├── lvl-127-outputs.npy
    │       ├── lvl-128-inputs.npy
    │       ├── lvl-128-outputs.npy
    │       ├── lvl-129-inputs.npy
    │       ├── lvl-129-outputs.npy
    │       ├── lvl-13-inputs.npy
    │       ├── lvl-13-outputs.npy
    │       ├── lvl-130-inputs.npy
    │       ├── lvl-130-outputs.npy
    │       ├── lvl-131-inputs.npy
    │       ├── lvl-131-outputs.npy
    │       ├── lvl-132-inputs.npy
    │       ├── lvl-132-outputs.npy
    │       ├── lvl-133-inputs.npy
    │       ├── lvl-133-outputs.npy
    │       ├── lvl-134-inputs.npy
    │       ├── lvl-134-outputs.npy
    │       ├── lvl-135-inputs.npy
    │       ├── lvl-135-outputs.npy
    │       ├── lvl-136-inputs.npy
    │       ├── lvl-136-outputs.npy
    │       ├── lvl-137-inputs.npy
    │       ├── lvl-137-outputs.npy
    │       ├── lvl-138-inputs.npy
    │       ├── lvl-138-outputs.npy
    │       ├── lvl-139-inputs.npy
    │       ├── lvl-139-outputs.npy
    │       ├── lvl-14-inputs.npy
    │       ├── lvl-14-outputs.npy
    │       ├── lvl-140-inputs.npy
    │       ├── lvl-140-outputs.npy
    │       ├── lvl-141-inputs.npy
    │       ├── lvl-141-outputs.npy
    │       ├── lvl-142-inputs.npy
    │       ├── lvl-142-outputs.npy
    │       ├── lvl-143-inputs.npy
    │       ├── lvl-143-outputs.npy
    │       ├── lvl-144-inputs.npy
    │       ├── lvl-144-outputs.npy
    │       ├── lvl-145-inputs.npy
    │       ├── lvl-145-outputs.npy
    │       ├── lvl-146-inputs.npy
    │       ├── lvl-146-outputs.npy
    │       ├── lvl-147-inputs.npy
    │       ├── lvl-147-outputs.npy
    │       ├── lvl-148-inputs.npy
    │       ├── lvl-148-outputs.npy
    │       ├── lvl-149-inputs.npy
    │       ├── lvl-149-outputs.npy
    │       ├── lvl-15-inputs.npy
    │       ├── lvl-15-outputs.npy
    │       ├── lvl-150-inputs.npy
    │       ├── lvl-150-outputs.npy
    │       ├── lvl-151-inputs.npy
    │       ├── lvl-151-outputs.npy
    │       ├── lvl-152-inputs.npy
    │       ├── lvl-152-outputs.npy
    │       ├── lvl-153-inputs.npy
    │       ├── lvl-153-outputs.npy
    │       ├── lvl-154-inputs.npy
    │       ├── lvl-154-outputs.npy
    │       ├── lvl-155-inputs.npy
    │       ├── lvl-155-outputs.npy
    │       ├── lvl-156-inputs.npy
    │       ├── lvl-156-outputs.npy
    │       ├── lvl-157-inputs.npy
    │       ├── lvl-157-outputs.npy
    │       ├── lvl-158-inputs.npy
    │       ├── lvl-158-outputs.npy
    │       ├── lvl-159-inputs.npy
    │       ├── lvl-159-outputs.npy
    │       ├── lvl-16-inputs.npy
    │       ├── lvl-16-outputs.npy
    │       ├── lvl-160-inputs.npy
    │       ├── lvl-160-outputs.npy
    │       ├── lvl-161-inputs.npy
    │       ├── lvl-161-outputs.npy
    │       ├── lvl-162-inputs.npy
    │       ├── lvl-162-outputs.npy
    │       ├── lvl-163-inputs.npy
    │       ├── lvl-163-outputs.npy
    │       ├── lvl-164-inputs.npy
    │       ├── lvl-164-outputs.npy
    │       ├── lvl-165-inputs.npy
    │       ├── lvl-165-outputs.npy
    │       ├── lvl-166-inputs.npy
    │       ├── lvl-166-outputs.npy
    │       ├── lvl-167-inputs.npy
    │       ├── lvl-167-outputs.npy
    │       ├── lvl-168-inputs.npy
    │       ├── lvl-168-outputs.npy
    │       ├── lvl-169-inputs.npy
    │       ├── lvl-169-outputs.npy
    │       ├── lvl-17-inputs.npy
    │       ├── lvl-17-outputs.npy
    │       ├── lvl-170-inputs.npy
    │       ├── lvl-170-outputs.npy
    │       ├── lvl-171-inputs.npy
    │       ├── lvl-171-outputs.npy
    │       ├── lvl-172-inputs.npy
    │       ├── lvl-172-outputs.npy
    │       ├── lvl-173-inputs.npy
    │       ├── lvl-173-outputs.npy
    │       ├── lvl-174-inputs.npy
    │       ├── lvl-174-outputs.npy
    │       ├── lvl-175-inputs.npy
    │       ├── lvl-175-outputs.npy
    │       ├── lvl-176-inputs.npy
    │       ├── lvl-176-outputs.npy
    │       ├── lvl-177-inputs.npy
    │       ├── lvl-177-outputs.npy
    │       ├── lvl-178-inputs.npy
    │       ├── lvl-178-outputs.npy
    │       ├── lvl-179-inputs.npy
    │       ├── lvl-179-outputs.npy
    │       ├── lvl-18-inputs.npy
    │       ├── lvl-18-outputs.npy
    │       ├── lvl-180-inputs.npy
    │       ├── lvl-180-outputs.npy
    │       ├── lvl-181-inputs.npy
    │       ├── lvl-181-outputs.npy
    │       ├── lvl-182-inputs.npy
    │       ├── lvl-182-outputs.npy
    │       ├── lvl-183-inputs.npy
    │       ├── lvl-183-outputs.npy
    │       ├── lvl-184-inputs.npy
    │       ├── lvl-184-outputs.npy
    │       ├── lvl-185-inputs.npy
    │       ├── lvl-185-outputs.npy
    │       ├── lvl-186-inputs.npy
    │       ├── lvl-186-outputs.npy
    │       ├── lvl-187-inputs.npy
    │       ├── lvl-187-outputs.npy
    │       ├── lvl-188-inputs.npy
    │       ├── lvl-188-outputs.npy
    │       ├── lvl-189-inputs.npy
    │       ├── lvl-189-outputs.npy
    │       ├── lvl-19-inputs.npy
    │       ├── lvl-19-outputs.npy
    │       ├── lvl-190-inputs.npy
    │       ├── lvl-190-outputs.npy
    │       ├── lvl-191-inputs.npy
    │       ├── lvl-191-outputs.npy
    │       ├── lvl-192-inputs.npy
    │       ├── lvl-192-outputs.npy
    │       ├── lvl-193-inputs.npy
    │       ├── lvl-193-outputs.npy
    │       ├── lvl-194-inputs.npy
    │       ├── lvl-194-outputs.npy
    │       ├── lvl-195-inputs.npy
    │       ├── lvl-195-outputs.npy
    │       ├── lvl-196-inputs.npy
    │       ├── lvl-196-outputs.npy
    │       ├── lvl-197-inputs.npy
    │       ├── lvl-197-outputs.npy
    │       ├── lvl-198-inputs.npy
    │       ├── lvl-198-outputs.npy
    │       ├── lvl-199-inputs.npy
    │       ├── lvl-199-outputs.npy
    │       ├── lvl-2-inputs.npy
    │       ├── lvl-2-outputs.npy
    │       ├── lvl-20-inputs.npy
    │       ├── lvl-20-outputs.npy
    │       ├── lvl-200-inputs.npy
    │       ├── lvl-200-outputs.npy
    │       ├── lvl-201-inputs.npy
    │       ├── lvl-201-outputs.npy
    │       ├── lvl-202-inputs.npy
    │       ├── lvl-202-outputs.npy
    │       ├── lvl-203-inputs.npy
    │       ├── lvl-203-outputs.npy
    │       ├── lvl-204-inputs.npy
    │       ├── lvl-204-outputs.npy
    │       ├── lvl-205-inputs.npy
    │       ├── lvl-205-outputs.npy
    │       ├── lvl-206-inputs.npy
    │       ├── lvl-206-outputs.npy
    │       ├── lvl-207-inputs.npy
    │       ├── lvl-207-outputs.npy
    │       ├── lvl-208-inputs.npy
    │       ├── lvl-208-outputs.npy
    │       ├── lvl-209-inputs.npy
    │       ├── lvl-209-outputs.npy
    │       ├── lvl-21-inputs.npy
    │       ├── lvl-21-outputs.npy
    │       ├── lvl-210-inputs.npy
    │       ├── lvl-210-outputs.npy
    │       ├── lvl-211-inputs.npy
    │       ├── lvl-211-outputs.npy
    │       ├── lvl-212-inputs.npy
    │       ├── lvl-212-outputs.npy
    │       ├── lvl-213-inputs.npy
    │       ├── lvl-213-outputs.npy
    │       ├── lvl-214-inputs.npy
    │       ├── lvl-214-outputs.npy
    │       ├── lvl-215-inputs.npy
    │       ├── lvl-215-outputs.npy
    │       ├── lvl-216-inputs.npy
    │       ├── lvl-216-outputs.npy
    │       ├── lvl-217-inputs.npy
    │       ├── lvl-217-outputs.npy
    │       ├── lvl-218-inputs.npy
    │       ├── lvl-218-outputs.npy
    │       ├── lvl-219-inputs.npy
    │       ├── lvl-219-outputs.npy
    │       ├── lvl-22-inputs.npy
    │       ├── lvl-22-outputs.npy
    │       ├── lvl-220-inputs.npy
    │       ├── lvl-220-outputs.npy
    │       ├── lvl-221-inputs.npy
    │       ├── lvl-221-outputs.npy
    │       ├── lvl-222-inputs.npy
    │       ├── lvl-222-outputs.npy
    │       ├── lvl-223-inputs.npy
    │       ├── lvl-223-outputs.npy
    │       ├── lvl-224-inputs.npy
    │       ├── lvl-224-outputs.npy
    │       ├── lvl-225-inputs.npy
    │       ├── lvl-225-outputs.npy
    │       ├── lvl-226-inputs.npy
    │       ├── lvl-226-outputs.npy
    │       ├── lvl-227-inputs.npy
    │       ├── lvl-227-outputs.npy
    │       ├── lvl-228-inputs.npy
    │       ├── lvl-228-outputs.npy
    │       ├── lvl-229-inputs.npy
    │       ├── lvl-229-outputs.npy
    │       ├── lvl-23-inputs.npy
    │       ├── lvl-23-outputs.npy
    │       ├── lvl-230-inputs.npy
    │       ├── lvl-230-outputs.npy
    │       ├── lvl-231-inputs.npy
    │       ├── lvl-231-outputs.npy
    │       ├── lvl-232-inputs.npy
    │       ├── lvl-232-outputs.npy
    │       ├── lvl-233-inputs.npy
    │       ├── lvl-233-outputs.npy
    │       ├── lvl-234-inputs.npy
    │       ├── lvl-234-outputs.npy
    │       ├── lvl-235-inputs.npy
    │       ├── lvl-235-outputs.npy
    │       ├── lvl-236-inputs.npy
    │       ├── lvl-236-outputs.npy
    │       ├── lvl-237-inputs.npy
    │       ├── lvl-237-outputs.npy
    │       ├── lvl-238-inputs.npy
    │       ├── lvl-238-outputs.npy
    │       ├── lvl-239-inputs.npy
    │       ├── lvl-239-outputs.npy
    │       ├── lvl-24-inputs.npy
    │       ├── lvl-24-outputs.npy
    │       ├── lvl-240-inputs.npy
    │       ├── lvl-240-outputs.npy
    │       ├── lvl-241-inputs.npy
    │       ├── lvl-241-outputs.npy
    │       ├── lvl-242-inputs.npy
    │       ├── lvl-242-outputs.npy
    │       ├── lvl-243-inputs.npy
    │       ├── lvl-243-outputs.npy
    │       ├── lvl-244-inputs.npy
    │       ├── lvl-244-outputs.npy
    │       ├── lvl-245-inputs.npy
    │       ├── lvl-245-outputs.npy
    │       ├── lvl-246-inputs.npy
    │       ├── lvl-246-outputs.npy
    │       ├── lvl-247-inputs.npy
    │       ├── lvl-247-outputs.npy
    │       ├── lvl-248-inputs.npy
    │       ├── lvl-248-outputs.npy
    │       ├── lvl-249-inputs.npy
    │       ├── lvl-249-outputs.npy
    │       ├── lvl-25-inputs.npy
    │       ├── lvl-25-outputs.npy
    │       ├── lvl-250-inputs.npy
    │       ├── lvl-250-outputs.npy
    │       ├── lvl-251-inputs.npy
    │       ├── lvl-251-outputs.npy
    │       ├── lvl-252-inputs.npy
    │       ├── lvl-252-outputs.npy
    │       ├── lvl-253-inputs.npy
    │       ├── lvl-253-outputs.npy
    │       ├── lvl-254-inputs.npy
    │       ├── lvl-254-outputs.npy
    │       ├── lvl-255-inputs.npy
    │       ├── lvl-255-outputs.npy
    │       ├── lvl-256-inputs.npy
    │       ├── lvl-256-outputs.npy
    │       ├── lvl-257-inputs.npy
    │       ├── lvl-257-outputs.npy
    │       ├── lvl-258-inputs.npy
    │       ├── lvl-258-outputs.npy
    │       ├── lvl-259-inputs.npy
    │       ├── lvl-259-outputs.npy
    │       ├── lvl-26-inputs.npy
    │       ├── lvl-26-outputs.npy
    │       ├── lvl-260-inputs.npy
    │       ├── lvl-260-outputs.npy
    │       ├── lvl-261-inputs.npy
    │       ├── lvl-261-outputs.npy
    │       ├── lvl-262-inputs.npy
    │       ├── lvl-262-outputs.npy
    │       ├── lvl-263-inputs.npy
    │       ├── lvl-263-outputs.npy
    │       ├── lvl-264-inputs.npy
    │       ├── lvl-264-outputs.npy
    │       ├── lvl-265-inputs.npy
    │       ├── lvl-265-outputs.npy
    │       ├── lvl-266-inputs.npy
    │       ├── lvl-266-outputs.npy
    │       ├── lvl-267-inputs.npy
    │       ├── lvl-267-outputs.npy
    │       ├── lvl-268-inputs.npy
    │       ├── lvl-268-outputs.npy
    │       ├── lvl-269-inputs.npy
    │       ├── lvl-269-outputs.npy
    │       ├── lvl-27-inputs.npy
    │       ├── lvl-27-outputs.npy
    │       ├── lvl-270-inputs.npy
    │       ├── lvl-270-outputs.npy
    │       ├── lvl-271-inputs.npy
    │       ├── lvl-271-outputs.npy
    │       ├── lvl-272-inputs.npy
    │       ├── lvl-272-outputs.npy
    │       ├── lvl-273-inputs.npy
    │       ├── lvl-273-outputs.npy
    │       ├── lvl-274-inputs.npy
    │       ├── lvl-274-outputs.npy
    │       ├── lvl-275-inputs.npy
    │       ├── lvl-275-outputs.npy
    │       ├── lvl-276-inputs.npy
    │       ├── lvl-276-outputs.npy
    │       ├── lvl-277-inputs.npy
    │       ├── lvl-277-outputs.npy
    │       ├── lvl-278-inputs.npy
    │       ├── lvl-278-outputs.npy
    │       ├── lvl-279-inputs.npy
    │       ├── lvl-279-outputs.npy
    │       ├── lvl-28-inputs.npy
    │       ├── lvl-28-outputs.npy
    │       ├── lvl-280-inputs.npy
    │       ├── lvl-280-outputs.npy
    │       ├── lvl-281-inputs.npy
    │       ├── lvl-281-outputs.npy
    │       ├── lvl-282-inputs.npy
    │       ├── lvl-282-outputs.npy
    │       ├── lvl-283-inputs.npy
    │       ├── lvl-283-outputs.npy
    │       ├── lvl-284-inputs.npy
    │       ├── lvl-284-outputs.npy
    │       ├── lvl-285-inputs.npy
    │       ├── lvl-285-outputs.npy
    │       ├── lvl-286-inputs.npy
    │       ├── lvl-286-outputs.npy
    │       ├── lvl-288-inputs.npy
    │       ├── lvl-288-outputs.npy
    │       ├── lvl-289-inputs.npy
    │       ├── lvl-289-outputs.npy
    │       ├── lvl-29-inputs.npy
    │       ├── lvl-29-outputs.npy
    │       ├── lvl-290-inputs.npy
    │       ├── lvl-290-outputs.npy
    │       ├── lvl-291-inputs.npy
    │       ├── lvl-291-outputs.npy
    │       ├── lvl-292-inputs.npy
    │       ├── lvl-292-outputs.npy
    │       ├── lvl-293-inputs.npy
    │       ├── lvl-293-outputs.npy
    │       ├── lvl-294-inputs.npy
    │       ├── lvl-294-outputs.npy
    │       ├── lvl-295-inputs.npy
    │       ├── lvl-295-outputs.npy
    │       ├── lvl-296-inputs.npy
    │       ├── lvl-296-outputs.npy
    │       ├── lvl-297-inputs.npy
    │       ├── lvl-297-outputs.npy
    │       ├── lvl-298-inputs.npy
    │       ├── lvl-298-outputs.npy
    │       ├── lvl-3-inputs.npy
    │       ├── lvl-3-outputs.npy
    │       ├── lvl-30-inputs.npy
    │       ├── lvl-30-outputs.npy
    │       ├── lvl-300-inputs.npy
    │       ├── lvl-300-outputs.npy
    │       ├── lvl-304-inputs.npy
    │       ├── lvl-304-outputs.npy
    │       ├── lvl-305-inputs.npy
    │       ├── lvl-305-outputs.npy
    │       ├── lvl-306-inputs.npy
    │       ├── lvl-306-outputs.npy
    │       ├── lvl-307-inputs.npy
    │       ├── lvl-307-outputs.npy
    │       ├── lvl-308-inputs.npy
    │       ├── lvl-308-outputs.npy
    │       ├── lvl-309-inputs.npy
    │       ├── lvl-309-outputs.npy
    │       ├── lvl-31-inputs.npy
    │       ├── lvl-31-outputs.npy
    │       ├── lvl-310-inputs.npy
    │       ├── lvl-310-outputs.npy
    │       ├── lvl-311-inputs.npy
    │       ├── lvl-311-outputs.npy
    │       ├── lvl-313-inputs.npy
    │       ├── lvl-313-outputs.npy
    │       ├── lvl-315-inputs.npy
    │       ├── lvl-315-outputs.npy
    │       ├── lvl-317-inputs.npy
    │       ├── lvl-317-outputs.npy
    │       ├── lvl-318-inputs.npy
    │       ├── lvl-318-outputs.npy
    │       ├── lvl-32-inputs.npy
    │       ├── lvl-32-outputs.npy
    │       ├── lvl-320-inputs.npy
    │       ├── lvl-320-outputs.npy
    │       ├── lvl-321-inputs.npy
    │       ├── lvl-321-outputs.npy
    │       ├── lvl-324-inputs.npy
    │       ├── lvl-324-outputs.npy
    │       ├── lvl-325-inputs.npy
    │       ├── lvl-325-outputs.npy
    │       ├── lvl-327-inputs.npy
    │       ├── lvl-327-outputs.npy
    │       ├── lvl-33-inputs.npy
    │       ├── lvl-33-outputs.npy
    │       ├── lvl-330-inputs.npy
    │       ├── lvl-330-outputs.npy
    │       ├── lvl-336-inputs.npy
    │       ├── lvl-336-outputs.npy
    │       ├── lvl-339-inputs.npy
    │       ├── lvl-339-outputs.npy
    │       ├── lvl-34-inputs.npy
    │       ├── lvl-34-outputs.npy
    │       ├── lvl-342-inputs.npy
    │       ├── lvl-342-outputs.npy
    │       ├── lvl-344-inputs.npy
    │       ├── lvl-344-outputs.npy
    │       ├── lvl-346-inputs.npy
    │       ├── lvl-346-outputs.npy
    │       ├── lvl-35-inputs.npy
    │       ├── lvl-35-outputs.npy
    │       ├── lvl-353-inputs.npy
    │       ├── lvl-353-outputs.npy
    │       ├── lvl-358-inputs.npy
    │       ├── lvl-358-outputs.npy
    │       ├── lvl-36-inputs.npy
    │       ├── lvl-36-outputs.npy
    │       ├── lvl-362-inputs.npy
    │       ├── lvl-362-outputs.npy
    │       ├── lvl-364-inputs.npy
    │       ├── lvl-364-outputs.npy
    │       ├── lvl-365-inputs.npy
    │       ├── lvl-365-outputs.npy
    │       ├── lvl-366-inputs.npy
    │       ├── lvl-366-outputs.npy
    │       ├── lvl-369-inputs.npy
    │       ├── lvl-369-outputs.npy
    │       ├── lvl-37-inputs.npy
    │       ├── lvl-37-outputs.npy
    │       ├── lvl-372-inputs.npy
    │       ├── lvl-372-outputs.npy
    │       ├── lvl-373-inputs.npy
    │       ├── lvl-373-outputs.npy
    │       ├── lvl-375-inputs.npy
    │       ├── lvl-375-outputs.npy
    │       ├── lvl-38-inputs.npy
    │       ├── lvl-38-outputs.npy
    │       ├── lvl-381-inputs.npy
    │       ├── lvl-381-outputs.npy
    │       ├── lvl-383-inputs.npy
    │       ├── lvl-383-outputs.npy
    │       ├── lvl-385-inputs.npy
    │       ├── lvl-385-outputs.npy
    │       ├── lvl-39-inputs.npy
    │       ├── lvl-39-outputs.npy
    │       ├── lvl-390-inputs.npy
    │       ├── lvl-390-outputs.npy
    │       ├── lvl-392-inputs.npy
    │       ├── lvl-392-outputs.npy
    │       ├── lvl-4-inputs.npy
    │       ├── lvl-4-outputs.npy
    │       ├── lvl-40-inputs.npy
    │       ├── lvl-40-outputs.npy
    │       ├── lvl-41-inputs.npy
    │       ├── lvl-41-outputs.npy
    │       ├── lvl-42-inputs.npy
    │       ├── lvl-42-outputs.npy
    │       ├── lvl-43-inputs.npy
    │       ├── lvl-43-outputs.npy
    │       ├── lvl-44-inputs.npy
    │       ├── lvl-44-outputs.npy
    │       ├── lvl-440-inputs.npy
    │       ├── lvl-440-outputs.npy
    │       ├── lvl-45-inputs.npy
    │       ├── lvl-45-outputs.npy
    │       ├── lvl-452-inputs.npy
    │       ├── lvl-452-outputs.npy
    │       ├── lvl-46-inputs.npy
    │       ├── lvl-46-outputs.npy
    │       ├── lvl-465-inputs.npy
    │       ├── lvl-465-outputs.npy
    │       ├── lvl-47-inputs.npy
    │       ├── lvl-47-outputs.npy
    │       ├── lvl-48-inputs.npy
    │       ├── lvl-48-outputs.npy
    │       ├── lvl-49-inputs.npy
    │       ├── lvl-49-outputs.npy
    │       ├── lvl-5-inputs.npy
    │       ├── lvl-5-outputs.npy
    │       ├── lvl-50-inputs.npy
    │       ├── lvl-50-outputs.npy
    │       ├── lvl-51-inputs.npy
    │       ├── lvl-51-outputs.npy
    │       ├── lvl-52-inputs.npy
    │       ├── lvl-52-outputs.npy
    │       ├── lvl-53-inputs.npy
    │       ├── lvl-53-outputs.npy
    │       ├── lvl-54-inputs.npy
    │       ├── lvl-54-outputs.npy
    │       ├── lvl-55-inputs.npy
    │       ├── lvl-55-outputs.npy
    │       ├── lvl-56-inputs.npy
    │       ├── lvl-56-outputs.npy
    │       ├── lvl-57-inputs.npy
    │       ├── lvl-57-outputs.npy
    │       ├── lvl-58-inputs.npy
    │       ├── lvl-58-outputs.npy
    │       ├── lvl-59-inputs.npy
    │       ├── lvl-59-outputs.npy
    │       ├── lvl-6-inputs.npy
    │       ├── lvl-6-outputs.npy
    │       ├── lvl-60-inputs.npy
    │       ├── lvl-60-outputs.npy
    │       ├── lvl-61-inputs.npy
    │       ├── lvl-61-outputs.npy
    │       ├── lvl-62-inputs.npy
    │       ├── lvl-62-outputs.npy
    │       ├── lvl-63-inputs.npy
    │       ├── lvl-63-outputs.npy
    │       ├── lvl-64-inputs.npy
    │       ├── lvl-64-outputs.npy
    │       ├── lvl-65-inputs.npy
    │       ├── lvl-65-outputs.npy
    │       ├── lvl-66-inputs.npy
    │       ├── lvl-66-outputs.npy
    │       ├── lvl-67-inputs.npy
    │       ├── lvl-67-outputs.npy
    │       ├── lvl-68-inputs.npy
    │       ├── lvl-68-outputs.npy
    │       ├── lvl-69-inputs.npy
    │       ├── lvl-69-outputs.npy
    │       ├── lvl-7-inputs.npy
    │       ├── lvl-7-outputs.npy
    │       ├── lvl-70-inputs.npy
    │       ├── lvl-70-outputs.npy
    │       ├── lvl-71-inputs.npy
    │       ├── lvl-71-outputs.npy
    │       ├── lvl-72-inputs.npy
    │       ├── lvl-72-outputs.npy
    │       ├── lvl-73-inputs.npy
    │       ├── lvl-73-outputs.npy
    │       ├── lvl-74-inputs.npy
    │       ├── lvl-74-outputs.npy
    │       ├── lvl-75-inputs.npy
    │       ├── lvl-75-outputs.npy
    │       ├── lvl-76-inputs.npy
    │       ├── lvl-76-outputs.npy
    │       ├── lvl-77-inputs.npy
    │       ├── lvl-77-outputs.npy
    │       ├── lvl-78-inputs.npy
    │       ├── lvl-78-outputs.npy
    │       ├── lvl-79-inputs.npy
    │       ├── lvl-79-outputs.npy
    │       ├── lvl-8-inputs.npy
    │       ├── lvl-8-outputs.npy
    │       ├── lvl-80-inputs.npy
    │       ├── lvl-80-outputs.npy
    │       ├── lvl-81-inputs.npy
    │       ├── lvl-81-outputs.npy
    │       ├── lvl-82-inputs.npy
    │       ├── lvl-82-outputs.npy
    │       ├── lvl-83-inputs.npy
    │       ├── lvl-83-outputs.npy
    │       ├── lvl-84-inputs.npy
    │       ├── lvl-84-outputs.npy
    │       ├── lvl-85-inputs.npy
    │       ├── lvl-85-outputs.npy
    │       ├── lvl-86-inputs.npy
    │       ├── lvl-86-outputs.npy
    │       ├── lvl-87-inputs.npy
    │       ├── lvl-87-outputs.npy
    │       ├── lvl-88-inputs.npy
    │       ├── lvl-88-outputs.npy
    │       ├── lvl-89-inputs.npy
    │       ├── lvl-89-outputs.npy
    │       ├── lvl-9-inputs.npy
    │       ├── lvl-9-outputs.npy
    │       ├── lvl-90-inputs.npy
    │       ├── lvl-90-outputs.npy
    │       ├── lvl-91-inputs.npy
    │       ├── lvl-91-outputs.npy
    │       ├── lvl-92-inputs.npy
    │       ├── lvl-92-outputs.npy
    │       ├── lvl-93-inputs.npy
    │       ├── lvl-93-outputs.npy
    │       ├── lvl-94-inputs.npy
    │       ├── lvl-94-outputs.npy
    │       ├── lvl-95-inputs.npy
    │       ├── lvl-95-outputs.npy
    │       ├── lvl-96-inputs.npy
    │       ├── lvl-96-outputs.npy
    │       ├── lvl-97-inputs.npy
    │       ├── lvl-97-outputs.npy
    │       ├── lvl-98-inputs.npy
    │       ├── lvl-98-outputs.npy
    │       ├── lvl-99-inputs.npy
    │       └── lvl-99-outputs.npy
    ├── engine/
    │   ├── __init__.py
    │   ├── display.py
    │   ├── solver.py
    │   └── utils.py
    ├── modes/
    │   ├── __init__.py
    │   ├── breakdown_puzzles.py
    │   ├── daily_puzzle.py
    │   ├── level_puzzle.py
    │   ├── list_puzzle.py
    │   └── random_puzzle.py
    ├── New/
    │   ├── main.py
    │   └── notes.md
    ├── notes/
    │   ├── architecture.md
    │   ├── Berthier.md
    │   ├── current_output.md
    │   ├── desired_output.md
    │   ├── grid.md
    │   ├── HRM.md
    │   ├── Levels.md
    │   ├── plan.md
    │   ├── PLAN2.MD
    │   ├── PLAN3.md
    │   ├── Steps.md
    │   └── taxonomy.md
    ├── strategies/
    │   ├── __init__.py
    │   ├── chains.py
    │   ├── fish.py
    │   ├── intersections.py
    │   ├── singles.py
    │   ├── strategies.py
    │   ├── subsets.py
    │   ├── uniqueness.py
    │   └── wings.py
    ├── sudoku_extreme/
    │   ├── test.csv
    │   └── train.csv
    └── tests/
        ├── test_bug.py
        ├── test_fish.py
        ├── test_intersections.py
        ├── test_singles.py
        ├── test_subsets.py
        └── test_uniqueness.py

================================================
FILE: README.md
================================================
# Sudoku Solver — Human‑Style, Strategy‑First

A human‑style Sudoku solver that generates step‑by‑step solving sequences. It downloads the sudoku-extreme dataset, buckets puzzles by difficulty, and applies modular strategies (singles, subsets, intersections, and more) to produce human‑like deductions.

---

## Table of Contents

* [Features](#features)
* [Installation](#installation)
* [Data: Download & Prepare](#data-download--prepare)
* [Quickstart](#quickstart)
* [How It Works](#how-it-works)

  * [Default Strategies](#default-strategies)
  * [Strategy Taxonomy](#strategy-taxonomy)
  * [Implemented Strategies (today)](#implemented-strategies-today)
* [Outputs: Sequences](#outputs-sequences)
* [Project Structure](#project-structure)
* [Extending](#extending)
* [Dataset & Citations](#dataset--citations)

  * [Dataset: Hardest Sudoku Puzzle Dataset V2](#dataset-hardest-sudoku-puzzle-dataset-v2)
  * [Paper: Hierarchical Reasoning Model (HRM)](#paper-hierarchical-reasoning-model-hrm)
* [License](#license)
* [Acknowledgements](#acknowledgements)

---

## Features

* **Human‑like strategy engine**: Singles, pairs, triplets, quads, intersections, fish, wings, and chains.
* **Batch‑first design**: Vectorized candidate computation across puzzles.
* **Reproducible sampling**: Daily deterministic selection in `main.py` for a random puzzle.
* **Dataset pipeline**: Downloads from Hugging Face and saves grouped `.npy` files per difficulty.

---

## Installation

* **Python**: 3.9+ recommended
* **Create env and install**:

  ```bash
  python -m venv .venv
  source .venv/bin/activate
  pip install -r requirements.txt
  ```
* **Requirements** (from `requirements.txt`): `numpy`, `huggingface_hub`, `tqdm`

---

## Data: Download & Prepare

This project uses the **`sapientinc/sudoku-extreme`** dataset on Hugging Face and saves per‑difficulty buckets as NumPy arrays.

* Generate processed files:

  ```bash
  python dataset_download.py
  ```
* Output directory: `data/sudoku-extreme-processed/`
* Files created per difficulty level `L`:

  * `lvl-L-inputs.npy` (shape: `(N, 9, 9)`)
  * `lvl-L-outputs.npy` (shape: `(N, 9, 9)`)

> The download script uses `hf_hub_download` with `repo_type="dataset"` and reads `train.csv` and `test.csv`. Ratings are preserved so puzzles can be bucketed by difficulty.

---

## Quickstart

Run the daily random puzzle (level 0) and print the step‑by‑step sequence:

```bash
python main.py
```

This selects a reproducible puzzle index (seeded by today’s date), solves it with human strategies, and prints each step with deductions.

### Solve a batch for a specific difficulty

Use the programmatic API to load and solve a difficulty bucket:

```python
import numpy as np
from solver import load_and_solve_difficulty

# Solve level 10, optionally subsample the first 100 puzzles
sequences = load_and_solve_difficulty(10, data_dir="data/sudoku-extreme-processed", subsample=100)

# sequences is a List[List[Dict]] where each inner list is a puzzle's step-by-step sequence
print(len(sequences), "puzzles solved")
```

---

## How It Works

* **`dataset_download.py`**: Downloads CSVs from the HF dataset, converts to 9×9 arrays, groups by difficulty, and writes `.npy` files.
* **`solver.py`**:

  * `solve_batch(inputs, outputs, max_steps=100, verbose=False)`: Human‑style loop that records sequences of steps. At each step it:

    * Computes candidates (vectorized)
    * Runs selected strategies via `strategies.find_deductions_batch`
    * Applies fills (certainties) and records all deductions
  * `load_and_solve_difficulty(diff, data_dir, subsample=None)`: Loads level buckets and solves them.
* **`strategies/strategies.py`**: Central hub that imports strategy functions and maps names → functions in `STRATEGY_FUNCTIONS`. Also expands grouped names like `hidden_single` into row/col/box variants.
* **`utils.py`**: Validation (`is_solved`, `is_valid`), application of deductions (`apply_deductions`), and a grid pretty‑printer.

### Set-notation core

Let $N=\{1,\dots,9\}$ be digits, $R=C=\{1,\dots,9\}$ rows and columns, and $X=R\times C$ the set of cells. $B$ denotes the nine blocks. A *house* $H$ is any row, column, or block. For a cell $x=(r,c)$, $\text{Peers}(x)=\text{row}(x)\cup\text{col}(x)\cup\text{blk}(x)\setminus\{x\}$. For a house $H$ and digit $n$, $\text{Pos}(H,n)=\{x\in H\mid n\text{ is a candidate in }x\}$.

### Default Strategies

In `solver.solve_batch`, the default list is:

```python
strategies = ["naked_single", "hidden_single", "subsets", "intersections", "fish"]
```

You can adjust this list to enable or disable groups as new strategies are implemented.

### Strategy Taxonomy

Strategies are organized by action type, complexity, and scope. The solver should apply simpler methods first for natural, human‑like progress.

| Strategy                 | Action Type                       | Complexity/Size                         | Scope                      | Notes                                        |
| ------------------------ | --------------------------------- | --------------------------------------- | -------------------------- | -------------------------------------------- |
| Naked Single             | Certainty (fill cell)             | Single (1 candidate in cell)            | Cell‑only                  | Simplest. Applied first.                     |
| Hidden Single            | Certainty (fill cell)             | Single (1 cell for a candidate in unit) | Unit (row/col/box)         | Only one place in the unit fits a candidate. |
| Locked Candidates        | Operation on unknowns (eliminate) | Pair/Triple                             | Intersection (box↔row/col) | Pointing/Claiming eliminations.              |
| Naked Pair/Triplet/Quad  | Operation on unknowns (eliminate) | Pair/Triple/Quad                        | Unit (row/col/box)         | Reduce other cells in unit.                  |
| Hidden Pair/Triplet/Quad | Operation on unknowns (eliminate) | Pair/Triple/Quad                        | Unit (row/col/box)         | Inverse of naked subsets.                    |
| Unique Rectangle Type 1 | Certainty (fill cell) | 4-cell rectangle | Grid-wide | Three cells share a pair; fourth forced. |
| XY‑Wing                  | Operation on unknowns (eliminate) | Triple (3 cells)                        | Chain                      | Bivalue pivot with two wings.                |
| XYZ‑Wing                 | Operation on unknowns (eliminate) | Triple (3 cells)                        | Chain                      | Trivalue pivot + two wings.                  |
| X‑Wing                   | Operation on unknowns (eliminate) | Quad (4‑cell rectangle)                 | Grid‑wide                  | Row/col rectangle pattern.                   |
| Swordfish                | Operation on unknowns (eliminate) | 9 cells (3×3)                           | Grid‑wide                  | 3 rows × 3 cols alignment.                   |
| Coloring                 | Eliminate or certainty            | Variable                                | Chain                      | Candidate graph coloring.                    |
| Forcing Chain            | Eliminate or certainty            | Variable                                | Chain                      | Implication chains; nice loops.              |
| Nishio                   | Eliminate via trial               | Variable                                | Trial/chain                | Assume and propagate until contradiction.    |

### Implemented Strategies (today)

* **Singles** (`strategies/singles.py`):

  * `naked_single`
  * `hidden_single_row`, `hidden_single_col`, `hidden_single_box` (group name: `hidden_single`)
* **Subsets** (`strategies/subsets.py`):

  * `naked_subsets` (pairs/triplets/quads; row/col/box)
  * `hidden_subsets` (pairs/triplets/quads; row/col/box)
* **Intersections** (`strategies/intersections.py`):

  * `locked_pointing` (row/col variants)
  * `locked_claiming` (row/col variants)
* **Fish** (`strategies/fish.py`):

  * `x_wing_row`, `x_wing_col`
  * `swordfish_row`, `swordfish_col`
  * `jellyfish_row`, `jellyfish_col`
* **Uniqueness** (`strategies/uniqueness.py`):

  * `ur_type1`
  * `ur_type2`
  * `ur_type2b`

`utils.apply_deductions` now handles both fills and eliminations, updating candidate masks so deductions from advanced strategies propagate immediately.

---

## Outputs: Sequences

Each puzzle’s solution is a sequence of step records:

* `{"step": i, "grid_state": List[int], "deductions": List[Dict]}`
* `grid_state` is a flat 81‑length snapshot after the step
* `deductions` contains items like:

  * Singles: `{ "type": "naked_single", "position": (r, c), "value": v }`
  * Eliminations: `{ "type": "locked_pointing", "eliminations": [ ((r, c), [values...]), ... ] }`
  * Uniqueness: { "type": "ur_type1", "position": (r, c), "value": v }
  * Uniqueness: { "type": "ur_type2", "eliminations": [ ((r, c), [values...]), ... ] }
  * Uniqueness: { "type": "ur_type2b", "eliminations": [ ((r, c), [values...]), ... ] }

You can save these sequences for ML or analysis.

---

## Project Structure

```
dataset_download.py        # Download + bucket dataset into .npy files
main.py                    # Daily random demo; prints the solving sequence for one puzzle
solver.py                  # Batch solver + difficulty loader API
strategies/
  strategies.py            # Strategy registry + grouped names expansion + batch deduction driver
  singles.py               # Singles
  subsets.py               # Naked/hidden subsets
  intersections.py         # Locked candidates (pointing/claiming)
  fish.py, wings.py, chains.py   # Placeholders for advanced strategies
utils.py                   # Validation, application of deductions (fills), pretty printing
data/                      # Generated .npy files per difficulty level
```

---

## Extending

* Add a new strategy in an existing family (or create a new module), export a function with signature:

  * `fn(candidates: np.ndarray, all_deductions: list[list[dict]]) -> None`
* Register it in `STRATEGY_FUNCTIONS` in `strategies/strategies.py`.
* Include it in the `strategies` list passed to `find_deductions_batch` and in `solver.solve_batch`.
* Update `utils.apply_deductions` if the new strategy performs eliminations that should affect subsequent steps.

---

## Dataset & Citations

### Dataset: Hardest Sudoku Puzzle Dataset V2

This project uses the **`sapientinc/sudoku-extreme`** dataset on Hugging Face.

* **Composition**: mixture of easy and very hard Sudoku puzzles collected from the community.
* **Splits & size**: Train `train.csv` (≈3.8M), Test `test.csv` (≈423k), **total** ≈4,254,780 rows.
* **Characteristics**: exact de‑duplication; each puzzle has a unique solution; train/test are mathematically inequivalent; **rating** = number of backtracks required by the `tdoku` solver (higher is harder).
* **Sources**: `tdoku` benchmarks and `enjoysudoku` community threads.

**Suggested dataset citation (BibTeX)**

```bibtex
@dataset{sapientai_2024_sudoku_extreme_v2,
  title        = {Hardest Sudoku Puzzle Dataset V2},
  author       = {{Sapient AI}},
  year         = {2024},
  howpublished = {\url{https://huggingface.co/datasets/sapientinc/sudoku-extreme}},
  note         = {Accessed: 2025-08-13}
}
```

### Paper: Hierarchical Reasoning Model (HRM)

If you use results or ideas from HRM, please cite their paper:

```bibtex
@misc{wang2025hierarchicalreasoningmodel,
  title         = {Hierarchical Reasoning Model},
  author        = {Guan Wang and Jin Li and Yuhao Sun and Xing Chen and Changling Liu and Yue Wu and Meng Lu and Sen Song and Yasin Abbasi Yadkori},
  year          = {2025},
  eprint        = {2506.21734},
  archivePrefix = {arXiv},
  primaryClass  = {cs.AI},
  url           = {https://arxiv.org/abs/2506.21734}
}
```

---

## License

**Your code:** MIT License.

* This repository’s **source code** is licensed under MIT. A full LICENSE text is included below for copy‑paste. Add `SPDX-License-Identifier: MIT` to new source files.
* Third‑party assets (datasets, papers, and external repos) keep **their own licenses/terms**. See **Third‑Party Notices** and **Data usage** below.

### Third‑Party Notices (summary)

* **HRM (sapientinc/HRM)** — *Apache‑2.0*. We **do not bundle HRM code** here. If you later import/copy HRM code or ship binaries containing it, include a copy of the Apache‑2.0 license and preserve any `NOTICE` provided by HRM. Attribute the authors and indicate significant changes.
* **tdoku (t-dillon/tdoku)** — *BSD‑2‑Clause*. We do **not** ship tdoku code; the dataset’s “rating” uses tdoku for backtrack counts. If you embed tdoku, retain its copyright notice and license text in source/binaries.
* **Dataset: sapientinc/sudoku‑extreme** — License not explicitly stated in the dataset card at the time of writing. We **do not redistribute** the CSVs; instead, we provide a script that downloads them from Hugging Face. Follow the dataset card’s Usage Guidelines and any terms shown there.

### Data usage

* This repo provides **download scripts only** for `sapientinc/sudoku‑extreme` and stores derived **.npy** groupings locally. Please consult the dataset card for terms and avoid rehosting the raw CSVs in this repo or in your releases.

---

## Copy‑paste LICENSE & Notices

### `LICENSE` (MIT)

```text
MIT License

Copyright (c) 2025 VUCA INC.

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

### `THIRD_PARTY_NOTICES.md`

```markdown
# Third‑Party Notices

This project may refer to or integrate the following third‑party materials. Each item retains its own license/terms.

## HRM — Hierarchical Reasoning Model
- Upstream: https://github.com/sapientinc/HRM
- License: Apache‑2.0
- Notes: We do not bundle HRM code. If you import or ship HRM code, include the Apache‑2.0 LICENSE and preserve any NOTICE from upstream; attribute authors and indicate significant changes.

## Tdoku — Fast Sudoku Solver
- Upstream: https://github.com/t-dillon/tdoku
- License: BSD‑2‑Clause
- Notes: We do not bundle tdoku code. If you embed it, retain its copyright notice and license text in source and/or distribution.

## Dataset — sapientinc/sudoku‑extreme (Hardest Sudoku Puzzle Dataset V2)
- Upstream: https://huggingface.co/datasets/sapientinc/sudoku-extreme
- License: not explicitly stated in the dataset card at the time of writing
- Notes: This repo does not redistribute the dataset. Use the provided script to download from Hugging Face and follow the dataset card’s Usage Guidelines.
```

---

## Acknowledgements

* **Dataset**: Sapient AI’s *Hardest Sudoku Puzzle Dataset V2* on Hugging Face (`sapientinc/sudoku-extreme`).

* **Upstream sources referenced by the dataset**: `tdoku` benchmarks and the `enjoysudoku` community.

* **Dataset**: Sapient AI’s *Hardest Sudoku Puzzle Dataset V2* on Hugging Face (`sapientinc/sudoku-extreme`).

<!-- Refactor summary: utils.py, solver.py and strategy modules now use uint16 masks; legacy (N,9,9,9) boolean paths removed. -->



================================================
FILE: conftest.py
================================================
"""Pytest configuration to ensure package imports work."""

import sys
from pathlib import Path

ROOT = Path(__file__).resolve().parent
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))




================================================
FILE: main.py
================================================
#!/usr/bin/env python3
"""Sudoku CLI entry point."""

from __future__ import annotations

import argparse

from modes import daily_puzzle, random_puzzle, level_puzzle
from engine.utils import is_valid_level


def _prompt_mode() -> str:
    mode = input("Choose mode [daily/random/level]: ").strip().lower()
    return mode


def _prompt_level() -> int | None:
    raw = input("Enter level (non-negative integer): ").strip()
    if not raw:
        return None
    try:
        val = int(raw)
    except ValueError:
        print("Invalid level: must be an integer.")
        return None
    if val < 0:
        print("Invalid level: must be >= 0.")
        return None
    if not is_valid_level(val):
        print(f"Level {val} not found in available data.")
        return None
    return val


def _interactive() -> int:
    mode = _prompt_mode()
    if mode not in {"daily", "random", "level"}:
        print("Invalid mode.")
        return 2

    level = None
    if mode == "level":
        level = _prompt_level()
        if level is None:
            return 2
        return level_puzzle.run(level=level)
    else:
        maybe = _prompt_level()
        if maybe is not None:
            level = maybe
        if mode == "daily":
            return daily_puzzle.run(level=level)
        if mode == "random":
            return random_puzzle.run(level=level)
    return 2


def build_parser() -> argparse.ArgumentParser:
    p = argparse.ArgumentParser(prog="sudoku", description="Sudoku 9x9 CLI")
    group = p.add_mutually_exclusive_group()
    group.add_argument(
        "-d", "--daily", action="store_true", help="Play the daily puzzle"
    )
    group.add_argument(
        "-r", "--random", action="store_true", help="Play a random puzzle"
    )
    p.add_argument(
        "-l",
        "--level",
        type=int,
        help=(
            "Integer level id. If used without --daily or --random, "
            "plays a random puzzle from that level."
        ),
    )
    return p


def main(argv: list[str] | None = None) -> int:
    parser = build_parser()
    args = parser.parse_args(argv)

    no_args = not (args.daily or args.random or args.level is not None)
    if no_args:
        return _interactive()

    if args.daily:
        if args.level is not None and not is_valid_level(args.level):
            parser.error(f"Invalid level: {args.level}")
        return daily_puzzle.run(level=args.level)

    if args.random:
        if args.level is not None and not is_valid_level(args.level):
            parser.error(f"Invalid level: {args.level}")
        return random_puzzle.run(level=args.level)

    if args.level is not None:
        if not is_valid_level(args.level):
            parser.error(f"Invalid level: {args.level}")
        return level_puzzle.run(level=args.level)

    parser.print_help()
    return 2


if __name__ == "__main__":
    raise SystemExit(main())



================================================
FILE: requirements.txt
================================================
numpy
huggingface_hub
tqdm 


================================================
FILE: data/dataset_download.py
================================================
import os
import csv
import json
import numpy as np
from typing import Dict, List, Tuple
from huggingface_hub import hf_hub_download
from tqdm import tqdm

# Configuration (hardcoded for now, can be made configurable later)
SOURCE_REPO = "sapientinc/sudoku-extreme"
OUTPUT_DIR = "data/sudoku-extreme-processed"
SETS = ["train", "test"]  # Process both train and test CSVs

def download_and_process_datasets() -> Dict[int, Tuple[List[np.ndarray], List[np.ndarray]]]:
    """
    Downloads the Sudoku datasets from Hugging Face, processes them into 9x9 numpy arrays,
    determines the min and max difficulty levels, and groups inputs/outputs by difficulty level.
    
    Returns a dictionary where keys are difficulty levels (integers), and values are tuples of
    (inputs_list, outputs_list), each being lists of 9x9 np.uint8 arrays.
    """
    all_inputs = []
    all_outputs = []
    all_ratings = []
    
    # Download and read each CSV
    for set_name in SETS:
        csv_path = hf_hub_download(SOURCE_REPO, f"{set_name}.csv", repo_type="dataset")
        
        with open(csv_path, newline="") as csvfile:
            reader = csv.reader(csvfile)
            next(reader)  # Skip header (source, q, a, rating)
            for source, q, a, rating in tqdm(reader, desc=f"Processing {set_name} set"):
                # Assert lengths
                assert len(q) == 81 and len(a) == 81, f"Invalid puzzle length in {set_name} set"
                
                # Convert q to 9x9 array (blanks as 0)
                input_arr = np.frombuffer(q.replace('.', '0').encode(), dtype=np.uint8).reshape(9, 9) - ord('0')
                # Convert a to 9x9 array
                output_arr = np.frombuffer(a.encode(), dtype=np.uint8).reshape(9, 9) - ord('0')
                
                all_inputs.append(input_arr)
                all_outputs.append(output_arr)
                all_ratings.append(int(rating))
    
    # Determine min and max difficulty
    if not all_ratings:
        raise ValueError("No puzzles found in datasets")
    min_diff = min(all_ratings)
    max_diff = max(all_ratings)
    print(f"Difficulty range: {min_diff} to {max_diff}")
    
    # Create buckets for each difficulty level
    buckets: Dict[int, Tuple[List[np.ndarray], List[np.ndarray]]] = {}
    for diff in range(min_diff, max_diff + 1):
        buckets[diff] = ([], [])  # (inputs, outputs)
    
    # Assign puzzles to buckets
    for inp, out, rating in zip(all_inputs, all_outputs, all_ratings):
        inputs_list, outputs_list = buckets[rating]
        inputs_list.append(inp)
        outputs_list.append(out)
    
    return buckets

def save_buckets(buckets: Dict[int, Tuple[List[np.ndarray], List[np.ndarray]]]):
    """
    Saves the grouped inputs and outputs as numpy files in the output directory.
    For each difficulty level, saves:
    - lvl-<diff>-inputs.npy: stacked array of shape (num_puzzles, 9, 9)
    - lvl-<diff>-outputs.npy: stacked array of shape (num_puzzles, 9, 9)
    """
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    for diff, (inputs_list, outputs_list) in buckets.items():
        if inputs_list:
            inputs_array = np.stack(inputs_list)  # Shape: (num_puzzles, 9, 9)
            outputs_array = np.stack(outputs_list)  # Shape: (num_puzzles, 9, 9)
            
            np.save(os.path.join(OUTPUT_DIR, f"lvl-{diff}-inputs.npy"), inputs_array)
            np.save(os.path.join(OUTPUT_DIR, f"lvl-{diff}-outputs.npy"), outputs_array)
            print(f"Saved level {diff}: {len(inputs_list)} puzzles")

if __name__ == "__main__":
    buckets = download_and_process_datasets()
    save_buckets(buckets)


================================================
FILE: data/sudoku-extreme-processed/lvl-0-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:2434b1d1583e577f7b3dd99af4ac4d7366f9825db4628ab16a1705a111960f22
size 49745144



================================================
FILE: data/sudoku-extreme-processed/lvl-0-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:44f5b176a267b87c497d09a3d8f83a504e2afb00415ee5c5472a2bb96ec3d9da
size 49745144



================================================
FILE: data/sudoku-extreme-processed/lvl-1-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:544a47f115d16ccf451ad705fb0959ec2cbda0ce83bdbcc4f9ec2dc28c8fa6db
size 21518588



================================================
FILE: data/sudoku-extreme-processed/lvl-1-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:d995e92fa1b921f4a0b60d98ea60617d95fbf358f043f8165290a3a82497834c
size 21518588



================================================
FILE: data/sudoku-extreme-processed/lvl-10-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:c3053584101af85ae33af1f3614ad89259f442491742d1f75d6ddd2eff4c02a4
size 6182210



================================================
FILE: data/sudoku-extreme-processed/lvl-10-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:3c015cb19af17eecdc21e4afc5c6e3ddd1334849ae933842e9064cb9b2dc9b04
size 6182210



================================================
FILE: data/sudoku-extreme-processed/lvl-100-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e42884ff86c61a6de48829d77b2e328ea7f6e6b60276859be13641dcd8f73775
size 152489



================================================
FILE: data/sudoku-extreme-processed/lvl-100-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:61bfae788a29f5b5de6a85ec723e8d2781072629893fa94a8714d414e74b823c
size 152489



================================================
FILE: data/sudoku-extreme-processed/lvl-101-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:bcc31d6c2c9deebe0a48905fcca170e4adfe6c5d1ede121d1c2575db442bd04f
size 149249



================================================
FILE: data/sudoku-extreme-processed/lvl-101-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:ea5411110f72ac1a7f0a7c20617aaeb0c55f95460ec70c10e22f7a9e8b744343
size 149249



================================================
FILE: data/sudoku-extreme-processed/lvl-102-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e67ee32951b1801c8a9493fb209a45888106065e2606e843d5a1c98bb4aa3660
size 133778



================================================
FILE: data/sudoku-extreme-processed/lvl-102-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:12d9be38f2f3ba78b06c6edf9c571c6d76d0e2930d64827544ebb5e6ab3faeec
size 133778



================================================
FILE: data/sudoku-extreme-processed/lvl-103-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:be9b56d1019c50064675048d61dc51b70a4561a8df9e9854a143d2d372c4e22a
size 128108



================================================
FILE: data/sudoku-extreme-processed/lvl-103-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:95db6f4a81179d96fada0f8ee2cc2e17e6c8ccfd21547fb852d7d9fb6bfaf36e
size 128108



================================================
FILE: data/sudoku-extreme-processed/lvl-104-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:0c342627d0187ef8cc8cacef1010dfb343dd9dadc5203116f72b351bc988b685
size 127946



================================================
FILE: data/sudoku-extreme-processed/lvl-104-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:eb9cb3c960fd7eceeea5f35c71e0569244edaa276420d7bdc1f72d29a02d0ed3
size 127946



================================================
FILE: data/sudoku-extreme-processed/lvl-105-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:023b4443cd25cad1c850b0716bd3eec457d80485a3ff344798a48a0ae38cc491
size 116363



================================================
FILE: data/sudoku-extreme-processed/lvl-105-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b39beef15a15602e0894f2f1fd7fd3d3a66232421046f662aec72c217d7c531a
size 116363



================================================
FILE: data/sudoku-extreme-processed/lvl-106-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:37d570536cade1e97b3dc7fbc1988d97f52aac82c8a573d23aa53ed4ec25e14d
size 113285



================================================
FILE: data/sudoku-extreme-processed/lvl-106-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:acab944b84cbab1f17536d03099ee064da95af0018695801a48ae5c7ddab2b22
size 113285



================================================
FILE: data/sudoku-extreme-processed/lvl-107-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:df9f74f968fde13b978f63e9206527189db209947f7e85c64bacba43f4a8cfe6
size 110855



================================================
FILE: data/sudoku-extreme-processed/lvl-107-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:73806b527ba2f8dda2d294fcce8e4ef5c21df548fb90d2a1f17c664382613b5c
size 110855



================================================
FILE: data/sudoku-extreme-processed/lvl-108-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:76f3cd7d27932f0fb2b4b788d9eac6b088f5c0e7fb4ba7947714d3f1e558ef78
size 107291



================================================
FILE: data/sudoku-extreme-processed/lvl-108-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:43066b78d80f8bea7edfaa0a4958ec6d3b144aa754f04d4c97cf7d1d31490a85
size 107291



================================================
FILE: data/sudoku-extreme-processed/lvl-109-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:c1267cb0293d81f7acc7446ef9e7a2e46f737ea2b9b4f1bdd265458ad344e5b0
size 107615



================================================
FILE: data/sudoku-extreme-processed/lvl-109-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:5f4a81ddffe1fe798aa267dc9b6539424d3b9ffeded3103b7ccd5f38ebdd62ad
size 107615



================================================
FILE: data/sudoku-extreme-processed/lvl-11-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:df1762d44629b195e719385cece7e9df805730be1add68120fd73be67d70fb2d
size 6244175



================================================
FILE: data/sudoku-extreme-processed/lvl-11-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:35f85e33a6854dcafa7e788f7c02f311dd67b04fbc1751a0002dfe8314cd23dc
size 6244175



================================================
FILE: data/sudoku-extreme-processed/lvl-110-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:c59e9a2cabf26c127b28c2448a3457376dd98e4ef24d9db907f94bbf04f89fec
size 99758



================================================
FILE: data/sudoku-extreme-processed/lvl-110-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:82e80bc8bdbb00450295e80ef45870a5b8e5ae4b1d72f23df633d5cb688fccd5
size 99758



================================================
FILE: data/sudoku-extreme-processed/lvl-111-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:dbc8270575138c54ada9e6f849bfb2b12a308b3d9b743593243eab6fb0b31eb0
size 90200



================================================
FILE: data/sudoku-extreme-processed/lvl-111-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:ede37d2531756ff354e8d14b1da158efb2cf94f4c075b54a6b55ecf51d675b38
size 90200



================================================
FILE: data/sudoku-extreme-processed/lvl-112-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:2f9696721bf43d49db11d284f2be0a137f1ef3d43268c252ac855c948124e52d
size 86717



================================================
FILE: data/sudoku-extreme-processed/lvl-112-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:0f6aa2b12c5e30cca06a3356d0b9165caa8b437eca74ee77d4d74f0b75fe56f9
size 86717



================================================
FILE: data/sudoku-extreme-processed/lvl-113-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:be87c4ae46b5a0186bd8e5ebbc7de5e50fa3871f85848b4b1362f4cec6b01e0b
size 83396



================================================
FILE: data/sudoku-extreme-processed/lvl-113-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b8bf561eefff055d5df5eb0a027a6bdf5458da8cc2a40507367a8bb0c2333e1b
size 83396



================================================
FILE: data/sudoku-extreme-processed/lvl-114-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:c7467a79d1295dedb6e6490f8cbbba1ce2b17d1706eca7bbb9110548baa3be28
size 82262



================================================
FILE: data/sudoku-extreme-processed/lvl-114-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:ee56a0de8c601dac9be55f566e4539aed932e77fee9400462a2e247ee1ccffb2
size 82262



================================================
FILE: data/sudoku-extreme-processed/lvl-115-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:4f955a9145ae6f81d67a5a7103ea6e4343f47c9badb1af68bc9287317da59e08
size 79589



================================================
FILE: data/sudoku-extreme-processed/lvl-115-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:8a58d0d095453b11ee5926cb20fab6cf400ba252d56583aa00c87264a49f2d65
size 79589



================================================
FILE: data/sudoku-extreme-processed/lvl-116-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e3934bd4b0ce03fe853f996234dfc10664bef0bfe2668025e6255e549838fbe9
size 79427



================================================
FILE: data/sudoku-extreme-processed/lvl-116-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:1ba9b4b506db43e1cd4d887a4e8edcf34defb6e6bdd4cdb5e8d893435d2e882d
size 79427



================================================
FILE: data/sudoku-extreme-processed/lvl-117-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:89369cbeea33ec89eb08a96d23f12605e1096ab956948d84d7027837a8d4f541
size 70679



================================================
FILE: data/sudoku-extreme-processed/lvl-117-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:bf1871d014bbc98b9b3442b42b3c971884cc841f86a161e34ed2f32c27e04bfe
size 70679



================================================
FILE: data/sudoku-extreme-processed/lvl-118-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:3a3a04c47ec2a8114d568d3ea54557d7ab857cf61da0f323794278ce226bc8ec
size 66467



================================================
FILE: data/sudoku-extreme-processed/lvl-118-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:f92588df8643e3e70c7bde19ef009565b1b2eeb2ec81984c90eac558226975e8
size 66467



================================================
FILE: data/sudoku-extreme-processed/lvl-119-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:8708bc66db0a3659179084ac0ed15b4a039ea3d70354a160fc51798a2af8fd9c
size 63794



================================================
FILE: data/sudoku-extreme-processed/lvl-119-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:0a3063b33003ef031948f39963ee7e0cf2ebfe3879a8d2c261fae2d09937b1bd
size 63794



================================================
FILE: data/sudoku-extreme-processed/lvl-12-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:950055a8121d371a57192f46c097cb4ec89f824383b6c1c1d52f4e3d0681bd8e
size 6173705



================================================
FILE: data/sudoku-extreme-processed/lvl-12-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:26d7d3e768176fcdd5ec1690c4caba06f49b6b4da7bf531b84bfc2e7d6a8c8e9
size 6173705



================================================
FILE: data/sudoku-extreme-processed/lvl-120-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:147f89c772329c513804638f06d7bf36fcd3c10d1cd89e9eb19252a5fa5eae5c
size 64523



================================================
FILE: data/sudoku-extreme-processed/lvl-120-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:a7c66fbccc687e2a3b0b435c1c4f099a59983c02b2ad6421ee2bd2ebdb4b306e
size 64523



================================================
FILE: data/sudoku-extreme-processed/lvl-121-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:61c43f2de6e8369d6a466315ca2dd8c9d16540072e48093a67d92c6040d40af1
size 62255



================================================
FILE: data/sudoku-extreme-processed/lvl-121-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:86473e403f3d9c20e7fe597f94331d5fe7035459842c832294836686dd739588
size 62255



================================================
FILE: data/sudoku-extreme-processed/lvl-122-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:817eb6cc276d037017527d7c6a5b37a4cf033c4568cf8a4812431d87850e86ba
size 55451



================================================
FILE: data/sudoku-extreme-processed/lvl-122-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:699ef4959eab0561e92cb6118d4e335a3063ddeea1be704fdbb75784ce5a63d8
size 55451



================================================
FILE: data/sudoku-extreme-processed/lvl-123-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b3c07cc819e3b05f201d2181387f2c68d6fa4f430ff9fcf31d1067eb6d7ada9b
size 56666



================================================
FILE: data/sudoku-extreme-processed/lvl-123-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:0eda19ada2a54f59cac0818df697a121980990ca034c4219054c5b6f3b605b4f
size 56666



================================================
FILE: data/sudoku-extreme-processed/lvl-124-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:7e3121fcf38116790199aa3d4789cc745547204fd527446cbc716b0efcfedd47
size 53750



================================================
FILE: data/sudoku-extreme-processed/lvl-124-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:30d8f700742937554ae0ed212a7f5ba4bc28346a536210778be8e25429f4f58b
size 53750



================================================
FILE: data/sudoku-extreme-processed/lvl-125-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:ce2275df057ad6d4ae32514fa8ab7ab41140343903e012a2c4bac2a8bde08d26
size 50591



================================================
FILE: data/sudoku-extreme-processed/lvl-125-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:712e640c2dcf63bb3e528de334f0af09c80f983aaadcb52b7d9e3ec48d65fb3b
size 50591



================================================
FILE: data/sudoku-extreme-processed/lvl-126-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:bfe7d104fb619e052a37bc3279a46949bf7bbe711b4485fdd8dc2a0f400c1997
size 44678



================================================
FILE: data/sudoku-extreme-processed/lvl-126-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:4d0856bf015296d27cf308a95c732c982032e6c0920e106eed597553ae97284d
size 44678



================================================
FILE: data/sudoku-extreme-processed/lvl-127-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:f1f669fcedbb3709e570ad3d62cca41072971d0bade39a992440a1b499736936
size 46622



================================================
FILE: data/sudoku-extreme-processed/lvl-127-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:bdf8a5215537a13e1812d87346a840ab0e9985e474594e5cdbbb033f484721ab
size 46622



================================================
FILE: data/sudoku-extreme-processed/lvl-128-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:9db056440a1f3a62f2a5825f6ed8b248546bad99ea1c09641bde3d72f235f0ee
size 46217



================================================
FILE: data/sudoku-extreme-processed/lvl-128-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:7e78ee1a814d583fbf5fa5ab667598bd5ea281dcafc5eec4e32d9bc4b10b84b8
size 46217



================================================
FILE: data/sudoku-extreme-processed/lvl-129-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b058f495f7c7fa850bf8582bd5fe29f0b22b4a7d730307fbd353203deed982ac
size 46136



================================================
FILE: data/sudoku-extreme-processed/lvl-129-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:1e6cdc39087b5baf7d31b556072bc187ee52a054343343bb3f1488bab28f5ba3
size 46136



================================================
FILE: data/sudoku-extreme-processed/lvl-13-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:636c1afe34b34e26bd55487cda9e13b59aacd1e60b20f03d074525b51cd1f876
size 6204485



================================================
FILE: data/sudoku-extreme-processed/lvl-13-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:899b2b16649b15c55f317421983dce63c3108d6dcffb149ca124f2a2fce9bea9
size 6204485



================================================
FILE: data/sudoku-extreme-processed/lvl-130-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e233a5502ea1ec63d1a6c63b203bdb960ecb92c87dacdf8071501daa764d028c
size 40709



================================================
FILE: data/sudoku-extreme-processed/lvl-130-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:1506f93a8a853887866525eb0faae8df4293bbeaf3a1b44228a8251a09eb0a2e
size 40709



================================================
FILE: data/sudoku-extreme-processed/lvl-131-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:af12bf4b3b2eb8b7d23fd8c874bcef91cdaf311758f8d5796f5c041e0ca54da2
size 41843



================================================
FILE: data/sudoku-extreme-processed/lvl-131-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:4244502dd8215b2206b5db3728dd6b40446268b36da53745c138cda6a872432a
size 41843



================================================
FILE: data/sudoku-extreme-processed/lvl-132-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:76e6720153cba98eb56d1d14156c5f51106d30bd43a9c5c98d6fa9f4e746110a
size 35687



================================================
FILE: data/sudoku-extreme-processed/lvl-132-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:98f8c663c01e29af91c3d91fe46ef1854e126c1a586a11da0ff40ceedbd368e9
size 35687



================================================
FILE: data/sudoku-extreme-processed/lvl-133-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:7dc6c0a46b9e1344133a8ace0084680a48d48f5029f2b5fff57e7a550ee27b89
size 38684



================================================
FILE: data/sudoku-extreme-processed/lvl-133-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:c7f5d6435616b6885e1efbefb5278009a0656e05fe89db1023a08f49fa222be4
size 38684



================================================
FILE: data/sudoku-extreme-processed/lvl-134-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:49a6fde6400e3907b5681671f4f5569c486c71703e03a7eee6461ebccb3d7473
size 33338



================================================
FILE: data/sudoku-extreme-processed/lvl-134-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:a1b6503317ca551670bf83635fd45163b455205da11bd3351e526d17a8442ba7
size 33338



================================================
FILE: data/sudoku-extreme-processed/lvl-135-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:542ce70872ee3cdb3fc404944e67e9fbc0867d6ce97f57bcb000157309044bd5
size 33014



================================================
FILE: data/sudoku-extreme-processed/lvl-135-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:9ac7aa1a76f5f5bbc41fc808d1ff13bbfc25b5a64bf080e36755a9c8450bd6aa
size 33014



================================================
FILE: data/sudoku-extreme-processed/lvl-136-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:0d29c27b7cc90416253510e861b9f03da52d5c010390fae411f519083079fd3e
size 30908



================================================
FILE: data/sudoku-extreme-processed/lvl-136-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:fdd7b666583e20a3e22b099b12083a241c4c9634bc077dd0ae8bf02659490e2c
size 30908



================================================
FILE: data/sudoku-extreme-processed/lvl-137-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:83c519619c3b3f05aa9bafa49e1a339b368572796b502f9f20f9071c06e58492
size 31394



================================================
FILE: data/sudoku-extreme-processed/lvl-137-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:1fa9ec610d96760fca70c729dc226cef95e49e25ef068ed077977f39c47a35f4
size 31394



================================================
FILE: data/sudoku-extreme-processed/lvl-138-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:133ece0114b37f017ef36510c65f73770056f2402ef136c2ed12100cf1915941
size 30098



================================================
FILE: data/sudoku-extreme-processed/lvl-138-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:9c068f1cec66eed2ecabd2a913517c7a3a672e0dc0be49b8efaa95798f8a6c12
size 30098



================================================
FILE: data/sudoku-extreme-processed/lvl-139-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:8fced34f95ac1c3b73848478c579be73b1bd2e0591d1d9ceab5889e26e161c6e
size 30098



================================================
FILE: data/sudoku-extreme-processed/lvl-139-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:0f1f7371b5e20da44e1b963307729beb3f9c918ea97a3df581f1a332fa49257a
size 30098



================================================
FILE: data/sudoku-extreme-processed/lvl-14-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:f98dabec1c055bb631c615f351c5644b321bf635f2573efe76cbf099d602bb27
size 6345992



================================================
FILE: data/sudoku-extreme-processed/lvl-14-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:02155bbf51ab908fe36ac9cd3391ac7db794661274bc2d50b78a548d3e8229f7
size 6345992



================================================
FILE: data/sudoku-extreme-processed/lvl-140-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:681b2cda542aa69ccc9444bac3db94e655a6ad999b880f4a4c3d0546e1437d93
size 26939



================================================
FILE: data/sudoku-extreme-processed/lvl-140-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:123bcdd8e0a078768b5301167b2f50b8b864b3b4d39da3f82a22e47d0aefb75e
size 26939



================================================
FILE: data/sudoku-extreme-processed/lvl-141-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:9b60e8500cdc0046f986f8062d8a1e81797b3187276beea2587a2ed9b69575d3
size 29045



================================================
FILE: data/sudoku-extreme-processed/lvl-141-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e6f2b10bd4aee9be0ae0e3d0644baca96790efef300e828989d65c69dc0ef5e2
size 29045



================================================
FILE: data/sudoku-extreme-processed/lvl-142-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:c3a141af0e2de6807e3e6d362033d971ef4792317f8ed051e6105f9c0901f77d
size 23942



================================================
FILE: data/sudoku-extreme-processed/lvl-142-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:20b47c03ca30bc1725def879a6e5675d89c17fc0616e4e359f83553cfd26e984
size 23942



================================================
FILE: data/sudoku-extreme-processed/lvl-143-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:4133c717ec31690c5717df8d859362ba632e5af9f6f231270fbd484e0525c231
size 21512



================================================
FILE: data/sudoku-extreme-processed/lvl-143-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:c2dee5d047e1ef40a72a20ba4a357b3389bd1a4ac5256efc1afbd6a61c91eb4d
size 21512



================================================
FILE: data/sudoku-extreme-processed/lvl-144-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:52af4deabbff87196c34ad07688a9a1a711a526de402f5109766f0f27e8a5ab1
size 22079



================================================
FILE: data/sudoku-extreme-processed/lvl-144-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:3a7075cace7266eca7feeb4248da6377d30121b6772f3de8b80a32d0a1246ee7
size 22079



================================================
FILE: data/sudoku-extreme-processed/lvl-145-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:664dbaf7c533a7e2a669519c61914959d7b2e0dc3f06a2f9c69991aff6dc075c
size 22808



================================================
FILE: data/sudoku-extreme-processed/lvl-145-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:cde4fb3cf0889f6757bfbe5dee458999342ef7529a979cd0b5226ae3729e4fe1
size 22808



================================================
FILE: data/sudoku-extreme-processed/lvl-146-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:6315aaa99d66454d598345c3c4908e80ee52781f6eb41202d35f7d5974c09c70
size 21593



================================================
FILE: data/sudoku-extreme-processed/lvl-146-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e4841524226fc57e61f00812070ec11c8d1c34499862a06a681aba7169924486
size 21593



================================================
FILE: data/sudoku-extreme-processed/lvl-147-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:5bdb0162f6684729d4711a8abe1f6a2e0be0ff1fbcf3e41b3d0c748b7b8a82b6
size 20135



================================================
FILE: data/sudoku-extreme-processed/lvl-147-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:90d10447ed0365f4288a42c9efa40f75c5117377ca8b3ea41e7b28ed1d4d2fd2
size 20135



================================================
FILE: data/sudoku-extreme-processed/lvl-148-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:fe4b927da44dcbc29379ee80c1ff0b45230dca8b399eb3ec8afdb98aa78b952e
size 19811



================================================
FILE: data/sudoku-extreme-processed/lvl-148-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:d3828afb7860724bd83cb0b5404bccbad96f5e83ea8786d5a8309f27a68b45dc
size 19811



================================================
FILE: data/sudoku-extreme-processed/lvl-149-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:51e43373702c971e87c991d753f80c31e8e43097605f5928e98eee5ad6ca40fe
size 18515



================================================
FILE: data/sudoku-extreme-processed/lvl-149-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:88f84427f4f0094bf9a3e5f2743adca3c94cd5a3ed57d94eb03b46e51c6ac926
size 18515



================================================
FILE: data/sudoku-extreme-processed/lvl-15-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:cafdcb171c7811934b840c6d90141c9c36732953634902301a35e984c29f0982
size 6067352



================================================
FILE: data/sudoku-extreme-processed/lvl-15-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:99d6fef92f1d8026b6f060c181d65261e8b6aab72138736254b7899c011c7789
size 6067352



================================================
FILE: data/sudoku-extreme-processed/lvl-150-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:239c75a7620100992ed52008604505268ad35c79aa8a364ee423ecd1b2c9a2a5
size 19001



================================================
FILE: data/sudoku-extreme-processed/lvl-150-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:151eb212b8b20fcaea539a79dddcdd6e13ea4750b1b995b9c7b95d2769c5a096
size 19001



================================================
FILE: data/sudoku-extreme-processed/lvl-151-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:bd845133877ebf2a195aaa0e8a63ff06f99ea5d0ef4bca89291d6b1eddad0132
size 18029



================================================
FILE: data/sudoku-extreme-processed/lvl-151-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:6e798f495bdf9eab3902e83a4c5996eae6be9eb0736efc3e992a1cc8d225bcce
size 18029



================================================
FILE: data/sudoku-extreme-processed/lvl-152-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:c0b9f681b9c37f1f734cae6887a9eefca582f923cdf0a8a1568ce0fb9ed5edff
size 17462



================================================
FILE: data/sudoku-extreme-processed/lvl-152-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:280ca2725096cb32e56c9b2b66a168468dbaeb10da2c13f14db03d6f2cb41726
size 17462



================================================
FILE: data/sudoku-extreme-processed/lvl-153-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:49319019efd9f239bb18bd702b2d526fb4d00705efd74fff93c2a2116a61589b
size 15518



================================================
FILE: data/sudoku-extreme-processed/lvl-153-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:0bc95619b24bd65b4b9d40ec1765ffe4ab00e7568a56b407c6cdf5d06543cf98
size 15518



================================================
FILE: data/sudoku-extreme-processed/lvl-154-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:6712c6f10b5fbe090f62090a4aa1074ecc751019b4d51f58fa3cc86c5cffd468
size 15194



================================================
FILE: data/sudoku-extreme-processed/lvl-154-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e72be5eeb1f03246cb2d5d12fbea62ff461c3c99a3de2bae3fd57501be0752ed
size 15194



================================================
FILE: data/sudoku-extreme-processed/lvl-155-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:24a4d0508335f846d88a19f7c870216c11a30475ed2cd22a40a32f903ead72cc
size 14303



================================================
FILE: data/sudoku-extreme-processed/lvl-155-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b73baa574c46e423257c79066b14dbc56b57b06c101173a205c2c5dbd2b992bc
size 14303



================================================
FILE: data/sudoku-extreme-processed/lvl-156-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:a00b579cc436e0d4f715c1c21e2896a383254b7fcdf9492e47d0e47ede105f0e
size 13979



================================================
FILE: data/sudoku-extreme-processed/lvl-156-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:d6a21a8f1a398490d781cdfa7a0b258546f834eb777fd2eb4b70fea8e87946ca
size 13979



================================================
FILE: data/sudoku-extreme-processed/lvl-157-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:126890d31cf8a2baa697edcafd7103c3e28db6b2332c9a5f6dd64239f3698f08
size 15113



================================================
FILE: data/sudoku-extreme-processed/lvl-157-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:396f2f2a2e0d9955147c96c9c1a6c41ade872f057cf2a27fef61141b6afe6660
size 15113



================================================
FILE: data/sudoku-extreme-processed/lvl-158-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:db060dfb152a4ab4a88e12f90dda9cc7f2511c8420f4d85eec4fee34b24329e9
size 12116



================================================
FILE: data/sudoku-extreme-processed/lvl-158-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:0a1548582b51f20a78ade48eb346ac7e6baa5e04e06ae85cbf226459edb74731
size 12116



================================================
FILE: data/sudoku-extreme-processed/lvl-159-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e0e177feaf8d78737cdd4dfb4eccfe9d11138bb48e83728930b83769d518ecd0
size 14951



================================================
FILE: data/sudoku-extreme-processed/lvl-159-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:dadf5f27893a35c70b79f2e1bc2e2425d23c931af45a0595a4e4c9dc9c724c53
size 14951



================================================
FILE: data/sudoku-extreme-processed/lvl-16-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e1af9b791cc1361bebd096f78ed468d6c323de2c24810e75fb4f21f423f38226
size 5672963



================================================
FILE: data/sudoku-extreme-processed/lvl-16-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:fda1fe4833b0b9083b48a21ffb9655e84b747d538e39d587a60265371bb3f317
size 5672963



================================================
FILE: data/sudoku-extreme-processed/lvl-160-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:d1ab9b9f819a07468355fc1701da53b65b39a186e05cc53af7edc26435ba946b
size 12278



================================================
FILE: data/sudoku-extreme-processed/lvl-160-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:fd5c71bfd358a6ddebacf65c4d011562f5bd6f343db76acf90712d1e7aa1cea9
size 12278



================================================
FILE: data/sudoku-extreme-processed/lvl-161-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:9faab3ed36454bc85f4b531eeb267903769929fabf2e4f3883e6e73c426be6b2
size 11387



================================================
FILE: data/sudoku-extreme-processed/lvl-161-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:6f81fc03a5ed4609f1e957ded2a8afee803be0c5faa50b454fc320bc7cf6e0e3
size 11387



================================================
FILE: data/sudoku-extreme-processed/lvl-162-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:c5d0d8a214fb57447e04fe4540bf42a31633828f54e1b683930df80ebb9a3d28
size 10901



================================================
FILE: data/sudoku-extreme-processed/lvl-162-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:7982f818a198532ab40ff5d33b4076a256108ecfcf84caadd934c66fd14f95a1
size 10901



================================================
FILE: data/sudoku-extreme-processed/lvl-163-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:28e3c146d9c4ba87623c90608711d263830391cb01f80b36051d32b3091c63e3
size 10172



================================================
FILE: data/sudoku-extreme-processed/lvl-163-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:124752d08b04be12e0f568d0de1ad905510530316e9d0128257f0811ac7fb2e8
size 10172



================================================
FILE: data/sudoku-extreme-processed/lvl-164-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:959a93958b535bc7f0ff28e6993235661bf4ed552185f13c5fed052bc3c189fe
size 11144



================================================
FILE: data/sudoku-extreme-processed/lvl-164-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:965888799c79286a146618cb4803aca5101922ed03a5f9c566c4dad6e6861367
size 11144



================================================
FILE: data/sudoku-extreme-processed/lvl-165-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:2f7c9e911c7c3e1fe68a6a307e55e5f77296f107c09eefaed381bd3c41552208
size 10658



================================================
FILE: data/sudoku-extreme-processed/lvl-165-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:21246a48bcd3c9c53f36c264a4f73570c334142a553de3458028cf9699f05ebe
size 10658



================================================
FILE: data/sudoku-extreme-processed/lvl-166-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:abb1fa246c2f385ed7953af0cc2a5c806c140d6104d8b2961352e9083385019b
size 9443



================================================
FILE: data/sudoku-extreme-processed/lvl-166-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:796ca5eaa26f8eb086494f8cd3e61cce94dc50ef00c47e4628638d325ff55e51
size 9443



================================================
FILE: data/sudoku-extreme-processed/lvl-167-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:4e6d078c73246099b6935f9264de54d36bcc03a8686a09b374e0c5ba7f363234
size 7418



================================================
FILE: data/sudoku-extreme-processed/lvl-167-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:96dc5b51377377fa00246e3e104e06640ed6547a40047d75201f6e4708f9367c
size 7418



================================================
FILE: data/sudoku-extreme-processed/lvl-168-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:701c5a7256334488cd875e50ab0ec1002f723e2ea7222781af2a41480216f732
size 9605



================================================
FILE: data/sudoku-extreme-processed/lvl-168-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:3ca4f58af1b4522a3870b304e1efdfc8f68cb62db0ae73c369bf0e260ae18b2c
size 9605



================================================
FILE: data/sudoku-extreme-processed/lvl-169-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e0608f28b39c969f03131f5e2cecfaa8de4afb1bd7ee5750214af1fa01086846
size 9038



================================================
FILE: data/sudoku-extreme-processed/lvl-169-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:c6924d70f2f3c90bdc10be433d8cc8dfb70eb44e3f55e090c3ae28e95fd0e339
size 9038



================================================
FILE: data/sudoku-extreme-processed/lvl-17-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:07a89bf9aac4dbb49f71d4e17d3820dcd2ef9fdae3f82ce60c8fa7d1a0b4ae7e
size 5444867



================================================
FILE: data/sudoku-extreme-processed/lvl-17-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:198e8507152e06f3cc9f6a602d2d6d3ea908f23ae7e213d8ad8b8aa2831d1546
size 5444867



================================================
FILE: data/sudoku-extreme-processed/lvl-170-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:c7f306c1b7334e3acb521e84ec603b15d3f30eb1f1ee9d4071c74001a0275e1f
size 8390



================================================
FILE: data/sudoku-extreme-processed/lvl-170-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:0a7c9beef551e27d227099c3b5382f224165b4343968ebaeec5dc6e7638d3b57
size 8390



================================================
FILE: data/sudoku-extreme-processed/lvl-171-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:a9ac968d2dd088b8023e6bbbed8e2823a629da7985df1120cdd4141f6f400339
size 7661



================================================
FILE: data/sudoku-extreme-processed/lvl-171-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:933aef5fc73d146eb08403263ee7ffc0aca7c4d56e773a151c7273b7909f880e
size 7661



================================================
FILE: data/sudoku-extreme-processed/lvl-172-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:027f0c96d09a71f4ae306ff5a082c6f3f8e1a96372fe673e428629b49e3a01bf
size 7337



================================================
FILE: data/sudoku-extreme-processed/lvl-172-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:14f02ed7b6988c6cd8facd3e80ef3e3eccab5f8e565e25b1cc5840a3374a7c05
size 7337



================================================
FILE: data/sudoku-extreme-processed/lvl-173-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:62a0aae8b15f10dc7bd5986a2567b5300d2216d345b30ce44150bb028d8187a4
size 7823



================================================
FILE: data/sudoku-extreme-processed/lvl-173-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:95d8c95c4d7e280bb0c69998547fb31507b073417b0356f6279cc0fc37c7d456
size 7823



================================================
FILE: data/sudoku-extreme-processed/lvl-174-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:13a03df9c5f65341d8792b5c81febd6c9bc0f02727ff73740b090fbe7af6902d
size 7175



================================================
FILE: data/sudoku-extreme-processed/lvl-174-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:ae72b027b01b3c2eefb2d6b8e35ef0b19d1c2ff975a4e52e0818ef92bccfe49c
size 7175



================================================
FILE: data/sudoku-extreme-processed/lvl-175-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:43d29a807b2f29dd7b25f5bff57ae5bd92e5484c90006eed70f694bdb1eda8eb
size 7094



================================================
FILE: data/sudoku-extreme-processed/lvl-175-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:86e8aea9479d193eb2e552da2062e8107d57e38045b9b0cc1bead6872cac1266
size 7094



================================================
FILE: data/sudoku-extreme-processed/lvl-176-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:420ade429f045acdb0d65ae4a3686a4232bdc4e708a03cb1afae70c68c2196cd
size 6851



================================================
FILE: data/sudoku-extreme-processed/lvl-176-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:69c29563f7b9d74b7b669d13b8bbf8c412507b1a3df5cb5fb6b1fa0655f8b2df
size 6851



================================================
FILE: data/sudoku-extreme-processed/lvl-177-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:7a4949fde804651aae30c7274eaf783492dc18a7aefca6b21a5ac93eda67d8b5
size 6851



================================================
FILE: data/sudoku-extreme-processed/lvl-177-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:05fc7feceff0c183ebaa2b97539ad6b47d888c0adde20d4087e5b7ef73e4a2ee
size 6851



================================================
FILE: data/sudoku-extreme-processed/lvl-178-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:d67e94369c812027a1dcb34b2cafe516aca0cda195fbce7e8bcb882ff46a4e94
size 5879



================================================
FILE: data/sudoku-extreme-processed/lvl-178-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:8f81002806f254ecf28b020a00e6c4db364d11d758476d6704686c04c310fcd3
size 5879



================================================
FILE: data/sudoku-extreme-processed/lvl-179-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:79bfa65f845576cf16c5cc2ddbb421e926081d264bb44236e5c3fb4ad270fe7d
size 6122



================================================
FILE: data/sudoku-extreme-processed/lvl-179-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:f8cb725a41fb41aa6adde37031e7cdfa8a794af8adc0d1ccca17a3a12b03928b
size 6122



================================================
FILE: data/sudoku-extreme-processed/lvl-18-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:5c9bcb8a93b89c218dc7d684814b1544442914e35febdc42ef121a132f6ad99b
size 5648906



================================================
FILE: data/sudoku-extreme-processed/lvl-18-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:9f7bbd99adf9d2fe96d758b5d6d1e265b5829451d43681ac32978cb072c8b963
size 5648906



================================================
FILE: data/sudoku-extreme-processed/lvl-180-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:59f02011e2188d945500d34b5913ac1786d4445197e24849642b070f4fd3f502
size 4988



================================================
FILE: data/sudoku-extreme-processed/lvl-180-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e3b98c5a4efcad357d5c06a0a6f47293dfcc0a99bf2e0a0fc547ef005a1e6aa5
size 4988



================================================
FILE: data/sudoku-extreme-processed/lvl-181-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:4ec61b82f5f4e271456e885a2f5ec5cefeb258611701fa864c1187b5b29e1736
size 6608



================================================
FILE: data/sudoku-extreme-processed/lvl-181-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:4aa4a5927729504344eaa8edc5af03dc7ec655fa7392fbdb132400b8eb6d731a
size 6608



================================================
FILE: data/sudoku-extreme-processed/lvl-182-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e9ef947072e5ad57467c7344becc7cc1515d4ecae321391ff2dbbc5b86740871
size 5069



================================================
FILE: data/sudoku-extreme-processed/lvl-182-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:a4d728c850b6a97312fc600224bd86c2371aad07457c4074aee533657343e8da
size 5069



================================================
FILE: data/sudoku-extreme-processed/lvl-183-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:586fdebcf530612942e8c33671f9a85ff3a2ad1c1879d36dca46b5dd2f75863a
size 6203



================================================
FILE: data/sudoku-extreme-processed/lvl-183-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:4c897d7ac60c07753609cd3f9dbe0344bb2fccb649e514bfc7d098285c55300f
size 6203



================================================
FILE: data/sudoku-extreme-processed/lvl-184-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:5592853b600294dd6c038b8f377a1a62e7ff2c6667ef3f78c9192fe83e4f6080
size 5393



================================================
FILE: data/sudoku-extreme-processed/lvl-184-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:4e7196d857f94a1cafc62a098ad740d7a4934bc43e128ae89df1e489d5cbda7a
size 5393



================================================
FILE: data/sudoku-extreme-processed/lvl-185-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b497d2efff9d07d0442fd59f74c94b3968aa474996ccb9f236112239343d0119
size 4583



================================================
FILE: data/sudoku-extreme-processed/lvl-185-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:dbe12dbb7ecb1ff40e5f092055b5276809f0a716f7bbba6b68da9b66af5e1f87
size 4583



================================================
FILE: data/sudoku-extreme-processed/lvl-186-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:8b1984282290605dc9fe600de2a4b9ad74936b638d0bc73f5c254dee3268eb38
size 4502



================================================
FILE: data/sudoku-extreme-processed/lvl-186-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b5b3ec901d9668969b33d339c6c17d214e3c42265d982597ec28197a04a79a53
size 4502



================================================
FILE: data/sudoku-extreme-processed/lvl-187-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:27f50a953affff9d938b98cdfc40ea60d54581bbda6aad791b84f7fc42d9f220
size 4664



================================================
FILE: data/sudoku-extreme-processed/lvl-187-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:4d1e7949e214d1f70f068f4dc9d8aa79ff3fa91fe31559b3ab71d90920f0acc3
size 4664



================================================
FILE: data/sudoku-extreme-processed/lvl-188-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e8e5350910b2b4bae670428479291c26bcb4ef780480f4c3025178d691b89ce5
size 4826



================================================
FILE: data/sudoku-extreme-processed/lvl-188-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:eac1ffccc9ce6acd2769c1e0881017238a74f545fb77f7d94a164d523ed08327
size 4826



================================================
FILE: data/sudoku-extreme-processed/lvl-189-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b7eaff2a13f9141a4e7a05eec8154e6fa0461ac4034a8a99ea4b6b36e66163f7
size 4745



================================================
FILE: data/sudoku-extreme-processed/lvl-189-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:7a2b1dd7e7b0fef335495b4bd1d9dbb88ff88323b8a5ad59cf8413144662a42e
size 4745



================================================
FILE: data/sudoku-extreme-processed/lvl-19-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b3f3d31eb78bfa3d5bb6dc68ccc847acfac051f99d4e480c5309a181f654c1e9
size 5805074



================================================
FILE: data/sudoku-extreme-processed/lvl-19-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:700c7f1f749982c7b3439de7beaf5eab74d13ef71a423624648ec6b60a7f2e96
size 5805074



================================================
FILE: data/sudoku-extreme-processed/lvl-190-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:78dd53e27c8ed79c99276e315848aca16534652ab4836e1a82b34e58a89985fa
size 4178



================================================
FILE: data/sudoku-extreme-processed/lvl-190-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:7d9046f1df203e03805859ca437f4dcb0a418c1857a632601960d8cb15a9f239
size 4178



================================================
FILE: data/sudoku-extreme-processed/lvl-191-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:1f27bf445655d91185a6bdc962cb5c2d9d6eb1f6392baf0d5136de6f97faff1c
size 3935



================================================
FILE: data/sudoku-extreme-processed/lvl-191-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:ad169cb5920b6a5e28d80a5c8b3fad7a80c426db77ef1c079fd4becf55e0ea93
size 3935



================================================
FILE: data/sudoku-extreme-processed/lvl-192-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:59df9e652e260b495d87e7664bebfce555905c06ea5cb13c6a43ab15d2492fd3
size 3854



================================================
FILE: data/sudoku-extreme-processed/lvl-192-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:2705bb9d54caa9c0ab18db4230cad6b4b59160b2ad2728ae31be497c29b411f5
size 3854



================================================
FILE: data/sudoku-extreme-processed/lvl-193-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:cd0365fbde20b02e409e769a7a2feef62d98f053cf21e06e3c8628a99ca3260c
size 3287



================================================
FILE: data/sudoku-extreme-processed/lvl-193-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:809864961c0cdc2d8d8a0cc8a5160fdc41aff49ba6e597ab207afd4208bdbfd6
size 3287



================================================
FILE: data/sudoku-extreme-processed/lvl-194-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:96936670b62dc0f6723814dff52510e7cda34688ff97eb769c84c4a63975830d
size 3044



================================================
FILE: data/sudoku-extreme-processed/lvl-194-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:4458fd1a1e326bd7608eb0e4bf9f46fe4608ddb73c3414dccc9fabe3c11b4029
size 3044



================================================
FILE: data/sudoku-extreme-processed/lvl-195-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:6fbc0d14d2b27380e7db193d1eb277b6d6b2da495952590167a62028dcf0740f
size 4340



================================================
FILE: data/sudoku-extreme-processed/lvl-195-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:3eb98defd8e6c2f46071b91eb89256e2f16c454d717e12548da80f2b26192fce
size 4340



================================================
FILE: data/sudoku-extreme-processed/lvl-196-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:714a79023bd2007a896e27fad62bca4ac8daec904f889fa46752beafb14fc204
size 3773



================================================
FILE: data/sudoku-extreme-processed/lvl-196-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:26f5e5517b627ccc163f66225fe37cdcd7461b1e6427c71d9e706eceab9ae391
size 3773



================================================
FILE: data/sudoku-extreme-processed/lvl-197-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:df79c15627ad1fe2c6e0e8be9d31d56c2015a26dfa90954582438246d38f93f9
size 3449



================================================
FILE: data/sudoku-extreme-processed/lvl-197-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:d8ab47a8ebe651a28a1ca84c445cbf419e10f8fde97434b6245d321521bef1ea
size 3449



================================================
FILE: data/sudoku-extreme-processed/lvl-198-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e9813fdba7afe01cc762171d471e36f8603aa94e78527064a4590fc75791733c
size 3044



================================================
FILE: data/sudoku-extreme-processed/lvl-198-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:dfc8fb07e48de50636d08eb1c7be4d6a09a137704b2c8c1647cdc09a070c4890
size 3044



================================================
FILE: data/sudoku-extreme-processed/lvl-199-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:3208be700c5378ae80758a273ca8c4caec194efba41666156400dc2c1165b3c7
size 2315



================================================
FILE: data/sudoku-extreme-processed/lvl-199-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:07251b70f3fac9d7a1f36c9f218aaf287b75f993d13f2df62cc1c6c06d4a783f
size 2315



================================================
FILE: data/sudoku-extreme-processed/lvl-2-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:6d49e5d217d271b414f5cb277c150178f9aa12e50971b1addd66f0c8716c16c8
size 12225701



================================================
FILE: data/sudoku-extreme-processed/lvl-2-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b48c32f8b9fa9926120c18c1b65a16720e338b0121660f1a61d378f47711f551
size 12225701



================================================
FILE: data/sudoku-extreme-processed/lvl-20-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e659dc099d768e946d742f16936aa3b8e64f4e98effb6e982b7bf843ea709a40
size 5717513



================================================
FILE: data/sudoku-extreme-processed/lvl-20-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:1b23b6f2cc19ae1f8149e90ab584bda7b784a50307ba1589cb1904bd3b6b622d
size 5717513



================================================
FILE: data/sudoku-extreme-processed/lvl-200-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:297a29a11df9a59179090e7f4ebd7a3ca4d1cdc5eab4a69c20681154e63ab3d0
size 3611



================================================
FILE: data/sudoku-extreme-processed/lvl-200-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:a5e2186e325fc3ad4509282085e81758b697464811c65e4cee030494b6233056
size 3611



================================================
FILE: data/sudoku-extreme-processed/lvl-201-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:a3c73695a3ee374c17e527ad914c916b0625f8125af003fb63248d0e4663562a
size 2477



================================================
FILE: data/sudoku-extreme-processed/lvl-201-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:a4113726f8448a57abcf7635ad1003b46415968318ac5524a4308511b2f01bae
size 2477



================================================
FILE: data/sudoku-extreme-processed/lvl-202-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:0ae0d886b6d091c99c8beaddf23df0d81632d87f244b14ef688643778d43cdc6
size 3449



================================================
FILE: data/sudoku-extreme-processed/lvl-202-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:efc00fe6351f8bf2b1bf0059b72e59adc11665fc087538688a3ecef76f32cb08
size 3449



================================================
FILE: data/sudoku-extreme-processed/lvl-203-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b9c97c8b738d85803715a505e1b1ff831f186bfa4a6c1ff354df82f947580959
size 2639



================================================
FILE: data/sudoku-extreme-processed/lvl-203-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:09a0bd85642e90798e5ca61694cf0b73368b37d900e74003bf528aa0f63dd51c
size 2639



================================================
FILE: data/sudoku-extreme-processed/lvl-204-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:75daeea1a95b1126e8ca8e1d51b61cd49dd2c8a33af3498726965fdb8737fc6b
size 2801



================================================
FILE: data/sudoku-extreme-processed/lvl-204-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:072111319b465e3c0f1b4097733eed2b944df8dff00a1c1ab526be2568d46d86
size 2801



================================================
FILE: data/sudoku-extreme-processed/lvl-205-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:5d3d46f4bf63c1ee9a14e8ac6e404dedc7d7fd4b4da3cc22cc18d3a059b635b3
size 2963



================================================
FILE: data/sudoku-extreme-processed/lvl-205-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:963394d229503fc4a0355bdf0a8dc2ce0be933ea30b6b5e812cf5730a07dccc2
size 2963



================================================
FILE: data/sudoku-extreme-processed/lvl-206-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:09d18bcf187cdba3864bc918a70260880b6f06b6be8156556cfc81a2368b0a9a
size 3287



================================================
FILE: data/sudoku-extreme-processed/lvl-206-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:3a69cf18751d31d92af844bac0418179833a6d3d9506243c25c64b6173fd72a2
size 3287



================================================
FILE: data/sudoku-extreme-processed/lvl-207-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:91632351b4a59ab1d14c58e26cee2af29beed3f6a1306f2c0e474d43a42e5c92
size 2234



================================================
FILE: data/sudoku-extreme-processed/lvl-207-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:db0ef8df8b9c66ef034f2e001e94cb49b78bc0e7fee28191b9fa9ada70f1c72f
size 2234



================================================
FILE: data/sudoku-extreme-processed/lvl-208-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:14e3c2eb4d811cc4536cee801575535d3af39fb4237884a62c9a8a4f41f377f2
size 2639



================================================
FILE: data/sudoku-extreme-processed/lvl-208-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:d793f628e9a437eaa9a5e1d91d2707ddf85e84417d07f51c0794be67167f9ad9
size 2639



================================================
FILE: data/sudoku-extreme-processed/lvl-209-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:cc73f1580aaa8a5077407da920fcd05724c4467bd9e8e993ec6fae3ea572de1e
size 2153



================================================
FILE: data/sudoku-extreme-processed/lvl-209-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e3269fdf986a4c3c385c49ad5e85e876729792e18f61dc96eb421c6fcfaeab07
size 2153



================================================
FILE: data/sudoku-extreme-processed/lvl-21-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:84ccbb6ed097426dd7c21a95157bb3abb438e3b341434840c76f25eb6788357d
size 5495087



================================================
FILE: data/sudoku-extreme-processed/lvl-21-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b7cf15c6921da73bc470bcdcdaad7fa3f223de6bed6fae71bbf84e16fc77671f
size 5495087



================================================
FILE: data/sudoku-extreme-processed/lvl-210-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:9f02471bcc2e69812a5739657b90c07cae3d9b6dce4feffccdf7a1f4de7b03e0
size 1991



================================================
FILE: data/sudoku-extreme-processed/lvl-210-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:d49ab9c34de726a22fdb95f2d5d66487f21bd6c16bd6b862b9cec72c166f72d9
size 1991



================================================
FILE: data/sudoku-extreme-processed/lvl-211-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:912422092f90ec6bf7a33b292823cf2fb3c9fbfa0484c6ffedaad4c5e8e479bb
size 2558



================================================
FILE: data/sudoku-extreme-processed/lvl-211-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:8119e0d1db930aeac6c79b850f4eb8ba02a7b0c6104644500b506b219a9ecb54
size 2558



================================================
FILE: data/sudoku-extreme-processed/lvl-212-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:09b3dfd476e07502c0ca6b3740950c1d4c9444b1ce3c8c46308bcaf3d793c71f
size 2234



================================================
FILE: data/sudoku-extreme-processed/lvl-212-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:c6db54525129a600ad30c3b70d2ace9ce0e2e6ddd8ac6d21995674432562a362
size 2234



================================================
FILE: data/sudoku-extreme-processed/lvl-213-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:fae0a5186c1fb70c88328767fcf18237ad4c176a4583487885118d0733326318
size 2153



================================================
FILE: data/sudoku-extreme-processed/lvl-213-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:c96a1261951fd7863af6a02fa688a32b72dced9ce1f57d1c550cd9d9cdfa33f9
size 2153



================================================
FILE: data/sudoku-extreme-processed/lvl-214-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:a88cde2cc99ebd60e55f3f9e0de6c0aab53c194f57448b72ed3157737fe09b3d
size 2396



================================================
FILE: data/sudoku-extreme-processed/lvl-214-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:8cf14161c1cedb5823c75a46b4804bc8fdb6a191faa70d6c3ef1769762a834de
size 2396



================================================
FILE: data/sudoku-extreme-processed/lvl-215-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:2c8b795c0c8210d1320fd8f8acc02ca804deda41d2fb525a8a59bc4e1f9da70c
size 2315



================================================
FILE: data/sudoku-extreme-processed/lvl-215-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:d799e907ae3db02fed140ab57b5ce88226f685140ad94881a592e6db766e05b7
size 2315



================================================
FILE: data/sudoku-extreme-processed/lvl-216-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:9060385aa1b0fe78e2af89467c48f5527399a6536a24f014627742cf2bd34110
size 1667



================================================
FILE: data/sudoku-extreme-processed/lvl-216-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:868ba8540387e6b02f5213476b61ad4734bf9482678ca298f8b41677fe96d7d5
size 1667



================================================
FILE: data/sudoku-extreme-processed/lvl-217-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:3c7075556c5290394d811b82dd6650efc720c722ac9777373a48dba1e42df693
size 1991



================================================
FILE: data/sudoku-extreme-processed/lvl-217-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:14b6abe6401ec0ed216f498e4b3aded13bb9c0adf4fb06adac85d824353631d9
size 1991



================================================
FILE: data/sudoku-extreme-processed/lvl-218-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:018a01d3a1db9d8ef9686c7e3659c1cddd892dac740f2b7b2a4c92f5720c20b1
size 1505



================================================
FILE: data/sudoku-extreme-processed/lvl-218-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e2ac91c3f5710260b30f1922e163d0a2b063def7110451aaa2dea24165176839
size 1505



================================================
FILE: data/sudoku-extreme-processed/lvl-219-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e45c9d1ba0baaa535edc6bdaeee3888555f1716d82e8c5db5824b03e3b38e467
size 1991



================================================
FILE: data/sudoku-extreme-processed/lvl-219-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:5eaa675fd3449d4edbe503c09b43325233341b0228eb436bc7bdeeb5744ec0f8
size 1991



================================================
FILE: data/sudoku-extreme-processed/lvl-22-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:64c9eae8cf01cd6a7fef4de9b38603e011517dba1de38280fb68e301ca27adcc
size 5441789



================================================
FILE: data/sudoku-extreme-processed/lvl-22-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:af7ecd1f25ce08d3646fc23e2ab78f0eb5cbcd5132d9fe66db57311cc6cd511f
size 5441789



================================================
FILE: data/sudoku-extreme-processed/lvl-220-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:5e175d553b1649d85ad106381760ef1bc073a1da2d8b8a6d62cbdea8455b1ba9
size 1991



================================================
FILE: data/sudoku-extreme-processed/lvl-220-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:16e39ba07408c8450fc7a20f89f286904785ec246f9f6bac11f59b2aaee343a8
size 1991



================================================
FILE: data/sudoku-extreme-processed/lvl-221-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:f906e4feb610b7332fb0f2ca2952f6654ab1471c699e3b338bb91c0c3fb35b33
size 1181



================================================
FILE: data/sudoku-extreme-processed/lvl-221-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:eb93bd7e26071ec0a0387b9147572c67c1180e9b829702d140948ddefc8ea5d1
size 1181



================================================
FILE: data/sudoku-extreme-processed/lvl-222-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e3d1cabfad132c585ca0d3297073b5be90ade2616d05c108e292372c8bcfdbbc
size 1505



================================================
FILE: data/sudoku-extreme-processed/lvl-222-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:bd7cd85df0dc33d674bf15e599a00e7619b89c4a3c084d618cc3d2277fcc176e
size 1505



================================================
FILE: data/sudoku-extreme-processed/lvl-223-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:f2fcd754b7ed25d3a7eade028347673f881e724c8bb9f0bfa2e733b248ce0c0a
size 1343



================================================
FILE: data/sudoku-extreme-processed/lvl-223-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e17314e094a013666025c3006096aac29c5d159aad9695a9b025f362a396a94b
size 1343



================================================
FILE: data/sudoku-extreme-processed/lvl-224-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:4d73dcec496aaca1162830d84d30927c1c59fb7788cb9952e6e3887f5a7a7c9a
size 1748



================================================
FILE: data/sudoku-extreme-processed/lvl-224-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:87758830309a908dce6652fc4f65745f66a87617976a221e1d4f4e3e4eb07465
size 1748



================================================
FILE: data/sudoku-extreme-processed/lvl-225-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:47e51ec58208239c09627a12ad236ff27f3b134015e31de5def3f441b3a365c7
size 938



================================================
FILE: data/sudoku-extreme-processed/lvl-225-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:6f6686ab896145847fc201735f91e22a55eb0328cdd77d1454a6da13ec86279e
size 938



================================================
FILE: data/sudoku-extreme-processed/lvl-226-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:da443e2949c5a9ccc4575819151598d687b744846035d2e0fbf45657fec03693
size 1505



================================================
FILE: data/sudoku-extreme-processed/lvl-226-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:296706fe3cc84c74a00a95be0a761b8efde0c71a83e3bc2c276089e375e6fa0d
size 1505



================================================
FILE: data/sudoku-extreme-processed/lvl-227-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:6994e5dfe9ba87ba271ce2a42c4988edfdc0dbb33733132cca576d60b53ff7b6
size 1586



================================================
FILE: data/sudoku-extreme-processed/lvl-227-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:8c1cdd672d034cdda2b8ea4186665103cd1c5ad66fb6d9df0eef64b2580fa410
size 1586



================================================
FILE: data/sudoku-extreme-processed/lvl-228-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:905a210f14c32e1b646e9765cea3b1fed8ed45f52b3f4693519570b682fd46f9
size 1100



================================================
FILE: data/sudoku-extreme-processed/lvl-228-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:feb5d1609b6fb7fc1b0a57243259d5cf3562341bbe460fe98723c6c72cc3fb39
size 1100



================================================
FILE: data/sudoku-extreme-processed/lvl-229-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:4f477070cb661d4cf3c156cb91ded725ac9ab5ce2c325a800b802365c4ef66b8
size 1181



================================================
FILE: data/sudoku-extreme-processed/lvl-229-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:21994d215023cb0ef35d0572dcbd1cd68879eb6d5af65c9462b5bad14797847b
size 1181



================================================
FILE: data/sudoku-extreme-processed/lvl-23-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:c62f12a005a0daf73a622e486b37f210bb5abeb1ca62313e691e0f73af888348
size 5397563



================================================
FILE: data/sudoku-extreme-processed/lvl-23-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:3f7121616181b599aac0536c8a76ccdcd6847a5ec6e9ef6e5caad3a3f566e09b
size 5397563



================================================
FILE: data/sudoku-extreme-processed/lvl-230-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:324f9c938c9932dd64724749690e215602c8aa1e0899a26a80682db3a3e8d467
size 1181



================================================
FILE: data/sudoku-extreme-processed/lvl-230-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:a6841e8f1c086ca53efb8f605321240dbc2788b597be6cd232135b3a14ff7e46
size 1181



================================================
FILE: data/sudoku-extreme-processed/lvl-231-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:50563cc1730096d6ac5837ceae297dfbb5a1162b33794b7b9b6b7eea4b0c4196
size 1100



================================================
FILE: data/sudoku-extreme-processed/lvl-231-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:abdbd8c1daab957077cbf023e84927ffe019e6fb58637720e6935e42b8cc36f0
size 1100



================================================
FILE: data/sudoku-extreme-processed/lvl-232-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:c55fdae94de3150125f9063b644015c9377c51f828bd8cab1e0207312189290d
size 857



================================================
FILE: data/sudoku-extreme-processed/lvl-232-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:c5fb6d04cda00ee213eb60d531a02b26c80fa051ccf85387f1d3c115586b47e5
size 857



================================================
FILE: data/sudoku-extreme-processed/lvl-233-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:f4e68360dc647685ccc6cd7d25217d0c3e544232346ab018b6d3549de27ef69b
size 1019



================================================
FILE: data/sudoku-extreme-processed/lvl-233-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:0e37d2828a6453c1c3b0defd6875d46a0ad3172ee48573e02b59d38406dd1ec4
size 1019



================================================
FILE: data/sudoku-extreme-processed/lvl-234-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:ccfffe7bb17a44ae2d2abda91e9964af32c1be8cb1526352f1edfa6d2c74a002
size 1505



================================================
FILE: data/sudoku-extreme-processed/lvl-234-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:a2a835e4aab0920e5851ca5bace13c2f9f8b872edc10e43a62a3568f975758ef
size 1505



================================================
FILE: data/sudoku-extreme-processed/lvl-235-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:cb2b324452933972e6dcb56625525aaf10912ffea9291a80b511f7f8bf641651
size 938



================================================
FILE: data/sudoku-extreme-processed/lvl-235-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:7e57089e624f4471454c8529dad9792e32aaeeb1957323a891ddf9fa2e14e6be
size 938



================================================
FILE: data/sudoku-extreme-processed/lvl-236-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:bbe52076aeb7964413fa518be772d4da2a909c062f50890769aea13f1fc932ea
size 1100



================================================
FILE: data/sudoku-extreme-processed/lvl-236-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:0b7f3849e2cdce75a33e6b3701f0ae65605a645ad1bb97cfc1a33ddf60c46917
size 1100



================================================
FILE: data/sudoku-extreme-processed/lvl-237-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:421a447662d42ee4a9a1ec9a0349983d3fec4747e6faf83c4c5a7110b0ef5fb5
size 1424



================================================
FILE: data/sudoku-extreme-processed/lvl-237-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:36b76ef40b3567db9614c8370780a23054269583bd30744714e3c39fb8af1170
size 1424



================================================
FILE: data/sudoku-extreme-processed/lvl-238-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:d6b0ac59c0cc1f43b115494996a45437c0c80439fa5b08384af65abf1594122b
size 776



================================================
FILE: data/sudoku-extreme-processed/lvl-238-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:348aa788109c732fefe4fdfa01fe5c43338581e24862b06fd9fdadd0cb0b5784
size 776



================================================
FILE: data/sudoku-extreme-processed/lvl-239-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:863b1361a01f48f4a1f38483dfecae90b4dd8ab8ef2a1461097fe0189fe58cc0
size 776



================================================
FILE: data/sudoku-extreme-processed/lvl-239-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:0cb9c37fc35d662d0bff74b86634b9c0a9d0c3d9f19e4cd614cdc79a311028f2
size 776



================================================
FILE: data/sudoku-extreme-processed/lvl-24-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b75561acc094580ddb2bf3926a573e60748636829d7f2c16d4e8d3f7605d971d
size 5352770



================================================
FILE: data/sudoku-extreme-processed/lvl-24-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e64f16277b8af21c64c0c9d3ff9ebcaa18a588ebbce9b51745c45ec224e8a42d
size 5352770



================================================
FILE: data/sudoku-extreme-processed/lvl-240-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:208ce0c1213f03dccd8e797245536813f4c1a85ceac0de03667fb4ebcf89a4bf
size 776



================================================
FILE: data/sudoku-extreme-processed/lvl-240-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:40caaa12efefab979f5db348de67918ef4c4aa4b99e03b71af9c6a44ab5ad836
size 776



================================================
FILE: data/sudoku-extreme-processed/lvl-241-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:2591ef6dffca94fa1d1eb60f7673c5520306be2d102826c8afdfbf1c37ecd640
size 857



================================================
FILE: data/sudoku-extreme-processed/lvl-241-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:19bcdbd78f0f8bebcf00fcfd57ed0f37f3893ceaed5a54710b8e6aa800247b50
size 857



================================================
FILE: data/sudoku-extreme-processed/lvl-242-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:bd1cd2547d43503fac3eb894598fa112f5f3eda538d8a35b5a660600a86a5e86
size 614



================================================
FILE: data/sudoku-extreme-processed/lvl-242-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:debca45fbc0fd403b3edf1dbe85bd7c5b2f2205f71a5995ff29b245939db5d67
size 614



================================================
FILE: data/sudoku-extreme-processed/lvl-243-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:5c7c19430f3ca4c1633d98355ec7d6f7b7667810711d005a1026c93ead93d72c
size 1262



================================================
FILE: data/sudoku-extreme-processed/lvl-243-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:01c868e1fc9cbb1a4826f38318895dc7e88cd3451b5831f5fd975fb9aeb3288a
size 1262



================================================
FILE: data/sudoku-extreme-processed/lvl-244-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e7335914278bfb6c08f2e9ac0b74567338d7924c614678d004e8a0e3598686d5
size 938



================================================
FILE: data/sudoku-extreme-processed/lvl-244-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:657ec923d49c184b148b946034b28da0b1d6298f864d0140e236b2e756e2caed
size 938



================================================
FILE: data/sudoku-extreme-processed/lvl-245-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:2c78a96c01ffc18a1394a43646d40c82cc439f07b3592c182ec949d16535b535
size 533



================================================
FILE: data/sudoku-extreme-processed/lvl-245-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:820005ff9a6b7893d0680a3c0bc97eeb618b2e403b984826bd804930b32d0f74
size 533



================================================
FILE: data/sudoku-extreme-processed/lvl-246-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:0ba74323c5b5ace92cb5a785802e7b5ae7645923447930001e33b2b433113622
size 614



================================================
FILE: data/sudoku-extreme-processed/lvl-246-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e905e307746f7b3047a2d16d9709ea42dc82c948b597ee775b2b311ac1a99514
size 614



================================================
FILE: data/sudoku-extreme-processed/lvl-247-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:eb3503c6cc206cb89b3e7c1f1e62566220d332d45f33b799f4eb822905429e7f
size 614



================================================
FILE: data/sudoku-extreme-processed/lvl-247-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:a35651c20a71888d8e705568d01ca248211763c17444ced2717db510e53bb443
size 614



================================================
FILE: data/sudoku-extreme-processed/lvl-248-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:08d0654d786e5dcede070695a3c32d23542042b7222da5690b24cefe0a4a5afe
size 695



================================================
FILE: data/sudoku-extreme-processed/lvl-248-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:77a6b04cc5cb47132a6814054e2236fb1a96f322ab1bd46d2881d6130552184e
size 695



================================================
FILE: data/sudoku-extreme-processed/lvl-249-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:d4686655592920cca20ac45a07baecea2c3fea2bdccee467e2635120549abfda
size 776



================================================
FILE: data/sudoku-extreme-processed/lvl-249-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:1ebc67be9f857fa480d35f5ad752dbb9b9dee3feeb28c27994ee83306a0386ab
size 776



================================================
FILE: data/sudoku-extreme-processed/lvl-25-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:bddc23573d846437e22309cc61b7789f6be7351853cc4f664d1f3945b8e951ea
size 5140064



================================================
FILE: data/sudoku-extreme-processed/lvl-25-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b3d88eb886737e6b09eb3fc3bfbb0ea5a13d4aaded26cc93e174dc12202beeef
size 5140064



================================================
FILE: data/sudoku-extreme-processed/lvl-250-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:d09f9ce75fc5f0ab0c23e917bcc6fec017fb5231f1eb5fd2440613aa220111d8
size 614



================================================
FILE: data/sudoku-extreme-processed/lvl-250-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:5a84b616148fd3a9c64a5df7bd6de6e9eed1c1839650a8ae33ece4f0b6bdf28c
size 614



================================================
FILE: data/sudoku-extreme-processed/lvl-251-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:962c7b4517b4dbf3c7198bd83a4642f579dd9ac2d930c8068e0110be3d4f5e38
size 1019



================================================
FILE: data/sudoku-extreme-processed/lvl-251-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:f4b07b631e996714d438e7273f559c6a39b4ffbfcd85df00d7116a6e2f17f0a5
size 1019



================================================
FILE: data/sudoku-extreme-processed/lvl-252-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:02b0f181ce97084c7b6650eb8d408da52062484408be738b00293ba117cbacdc
size 938



================================================
FILE: data/sudoku-extreme-processed/lvl-252-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:3ba66e38c560b8fe145b18bc73f49c23e060ca192490208aa04f87df7676a1b8
size 938



================================================
FILE: data/sudoku-extreme-processed/lvl-253-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:42349b69802c588155dcb3d2e305f31a90e99df6861156cf014c18265104e350
size 452



================================================
FILE: data/sudoku-extreme-processed/lvl-253-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:bb3a65fa1d4505e4d81097aadc0e2e2f8ebfb6d329678f82b3ae89fe3ccf76aa
size 452



================================================
FILE: data/sudoku-extreme-processed/lvl-254-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:dbf233d06af097d5edd41db86a6e9cdfec48d4b3754e86762d746d0b1b90ad4d
size 695



================================================
FILE: data/sudoku-extreme-processed/lvl-254-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:5c2e587b84ab4f32ecbdccd75229ef0277eaf6ff56000afc28656c288532588e
size 695



================================================
FILE: data/sudoku-extreme-processed/lvl-255-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:f2472ea8f98f73abc15d7f6d21d63b5d72f3323ce8f1e55312fe7407b36d1a21
size 776



================================================
FILE: data/sudoku-extreme-processed/lvl-255-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:1809dfb04478e41e8262dc4aaef4715e9880c23aee949ca38391eb365521be60
size 776



================================================
FILE: data/sudoku-extreme-processed/lvl-256-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:aa9150ff7394468d31f09642c57225ba6b4c18a75ca857ff0e627a8127a5d46d
size 533



================================================
FILE: data/sudoku-extreme-processed/lvl-256-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e1f6d3caeacef656f236b0e879f0f5bad38f8d8855c628c167b878a62e9ff392
size 533



================================================
FILE: data/sudoku-extreme-processed/lvl-257-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:9b1266e96c4d2acbe435830769150ef77f23e8f9e5c71396da4de6ae2fea9622
size 452



================================================
FILE: data/sudoku-extreme-processed/lvl-257-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b595b4c71e891dd22015743fdce65058390bb1d9a4ab7157210aa7cf0d93dca9
size 452



================================================
FILE: data/sudoku-extreme-processed/lvl-258-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:742eb537b334b7b48ea4b0aade09a1a4f6c9588de2c249cf3ea005d7a27721f3
size 695



================================================
FILE: data/sudoku-extreme-processed/lvl-258-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:038b946026107fbbd90f231de703e9f759210fc23a05c7854e1ead03df550b18
size 695



================================================
FILE: data/sudoku-extreme-processed/lvl-259-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b87c72ae46dd4192f4ee3a6c8c78fed91c60c7134b3a41e7109c68d722a2ed24
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-259-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:5e1d0005c6ef1757942731f2cd783731a88855d91603f34de5d154a9d1ed3fdd
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-26-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:70a20029231d712fbca47d7ce2b2e8bf917a237ce214e2ff9b32316e1958c52f
size 5022128



================================================
FILE: data/sudoku-extreme-processed/lvl-26-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:bccc9637af5eeb8dbad54b1db1d5db8e0944dd5b2dd9ab35dbc7d6c6e2059e7a
size 5022128



================================================
FILE: data/sudoku-extreme-processed/lvl-260-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:791eb2e8e7fc67a46a30143ba10b6c74052b0722a059c92d9a500f300de842a4
size 695



================================================
FILE: data/sudoku-extreme-processed/lvl-260-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:371ccfeb4c189884fc2c8f395cd243961b192f13f732a203cef59848cde7d582
size 695



================================================
FILE: data/sudoku-extreme-processed/lvl-261-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:ccfcd48ba74f23ff31f7066361deb5431c7dafb8e5e98756cfc06fa88379c545
size 452



================================================
FILE: data/sudoku-extreme-processed/lvl-261-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:d4e3e607e944af93132ac6f391e518aa6653f1e89c7c343a106ac0d39bbc2d83
size 452



================================================
FILE: data/sudoku-extreme-processed/lvl-262-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:64b5dccf9575caece4a6193bdfee7d5a9c69b3d7ae84d4217ad15a24ac35516c
size 533



================================================
FILE: data/sudoku-extreme-processed/lvl-262-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:ef121141590b6927504109ec755d96d7127178d6ac064f5174790dd70130cd58
size 533



================================================
FILE: data/sudoku-extreme-processed/lvl-263-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:fae150bfdeb1e3c78fecadcc8923802e4aeb6402bcc5c156182cfd3067eb6387
size 371



================================================
FILE: data/sudoku-extreme-processed/lvl-263-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:243790912143f83cb359a26dbd01db1bfeceafb1a3e2276ddc9da5d3358075f5
size 371



================================================
FILE: data/sudoku-extreme-processed/lvl-264-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:5e9a15d3180ca2700213fffc7469cb00afd6e59d434a107921495b99d0c0ff8f
size 452



================================================
FILE: data/sudoku-extreme-processed/lvl-264-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:8e54f6d4c419f7fb8a094d09163e013d6f61c53a2df087156bcb7500d1132322
size 452



================================================
FILE: data/sudoku-extreme-processed/lvl-265-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:9b9ec4677817be9002550b6cb9343017edd4a7f4f9ec1dbd8d2f99bd1680a950
size 695



================================================
FILE: data/sudoku-extreme-processed/lvl-265-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:4c166cdf936839b53117b230d662844e695e3ddf9086f56c253998a6a73d1936
size 695



================================================
FILE: data/sudoku-extreme-processed/lvl-266-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:7d94744f990be7450eea5978d411cdd84e7b1d9c7138dbba2f553497f446d50c
size 614



================================================
FILE: data/sudoku-extreme-processed/lvl-266-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:34d576ad9ab27de4b7e96ccd4c19dae7de5876aaa25a034afe4e0dae96f4aea1
size 614



================================================
FILE: data/sudoku-extreme-processed/lvl-267-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:5453c53d01af9772b39852df6f749c2cd0d84e6473ee04cdd7ea73ee3ad8d795
size 452



================================================
FILE: data/sudoku-extreme-processed/lvl-267-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:820f3338efa1c07233a1a0c5ed93c691c649736dbe4e5d3a58b82533a84c83c6
size 452



================================================
FILE: data/sudoku-extreme-processed/lvl-268-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b89d9f5b0ece04f07207c3ce1f879c85d054a1161fbe3c678a50decf7b58ff7a
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-268-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:3d8505d7ee92f127ab7fa4bf6b47e16f70bcff86ee504961c9d567484a8def68
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-269-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:73c7690e6ee027e21907215fec621e10eeb2bf9126bbbfb3954989b75fdc5669
size 695



================================================
FILE: data/sudoku-extreme-processed/lvl-269-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:908489421565785599158b7676dd25a02bcb737badb103f8f06c778bae4cc384
size 695



================================================
FILE: data/sudoku-extreme-processed/lvl-27-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b18444daa5e95e68fddecdafbd20b494dfa4a6def9fc64e9f5423403fe8367c6
size 4798649



================================================
FILE: data/sudoku-extreme-processed/lvl-27-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:98538df76bff7a252c88d334188e72d9ee6c1a482efe9777d1a14b86f2e6c1be
size 4798649



================================================
FILE: data/sudoku-extreme-processed/lvl-270-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:bae8a852e38f4a17ad1f7bf619c3eff50cedbb4fabe312b83d46064022d3c354
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-270-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:c6388d920a8ab034727a7be2c54604764337c27ce80c13513ed1535df99f922d
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-271-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:41fb4966f27bdcf43de6e20031fab04926313a69466decd3d2a2247145212909
size 533



================================================
FILE: data/sudoku-extreme-processed/lvl-271-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:ec603c1f46329fb94ebd6b08c862226d1cf31a5aee509e0e2e6d29fca32b4107
size 533



================================================
FILE: data/sudoku-extreme-processed/lvl-272-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:a0f1d518ea366fa671eba84b005786a9e3928d2b2b05cccaa4536c17534df315
size 371



================================================
FILE: data/sudoku-extreme-processed/lvl-272-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e3a792366f26cc668e7c7c275f0491c1027fe32b76767ab25c4863f8a84d38ef
size 371



================================================
FILE: data/sudoku-extreme-processed/lvl-273-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:efcdc83930a0a013d06d263fc2c6fd86ada98642124214e23f5688c4c1cf23b8
size 614



================================================
FILE: data/sudoku-extreme-processed/lvl-273-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:7d9e3ceb296f691dd68231fa3c1e2ef7e397f9f20ce61e82c53af04bbe7297f8
size 614



================================================
FILE: data/sudoku-extreme-processed/lvl-274-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:29334a9640d7bf0f616d6430c7e8e7ec37b1c12220677a7d5fc21c60d69d536f
size 776



================================================
FILE: data/sudoku-extreme-processed/lvl-274-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:32bedba90bc2ebfcf8bdd0a16c618b77b1607bc9d6aa0aa9269d004835f795f7
size 776



================================================
FILE: data/sudoku-extreme-processed/lvl-275-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:043063409623fb9ccb706ac5941d444a5ba509334c70a5939f8a946066677012
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-275-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:05bcccc59f8be7897c0828c82e3b63623e12342a178451a05b5860058145bd2f
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-276-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:74ebb280c48ade356fc2a23f86ed1b377aeed25ec5c15b56981665c94c9627ed
size 371



================================================
FILE: data/sudoku-extreme-processed/lvl-276-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:df82be602d739ba6d0f0c8bfecdc1785edbc4f0146dde51878f455bea5240d5f
size 371



================================================
FILE: data/sudoku-extreme-processed/lvl-277-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e7ee7493b65dbff38504548d75605444938ca42791ff9dc10dacbb7c3d7eb363
size 371



================================================
FILE: data/sudoku-extreme-processed/lvl-277-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:2dbeb19b266614620740793e92de900df4027eada7302d1c271b2a790a0d93aa
size 371



================================================
FILE: data/sudoku-extreme-processed/lvl-278-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:938d22337fea3b8577a9990a8b8b490b07fbf708f994cc45308fc85642b478e1
size 371



================================================
FILE: data/sudoku-extreme-processed/lvl-278-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:0e3615179b98b55053d1d3fe3c3aaa145ebdcebd640ceb6000f699981b91db68
size 371



================================================
FILE: data/sudoku-extreme-processed/lvl-279-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:d4c98a7336802c7095bd7cc5a13fdb69cfb3c03cebfd330b6aca8d21ca2d11fd
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-279-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:5fde4f3b8c9b081523cbfd066a11bf1333b5ce85ada41df750893db54a9af65a
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-28-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:7460728af9a5b82980a68d687ba6c861ab9c2ce9154b37e952b03e54f8af5d43
size 4750211



================================================
FILE: data/sudoku-extreme-processed/lvl-28-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:28b1898436706155bd4f812f0b3675835e7c1f825ea41d94a9d41afbbeed9c9b
size 4750211



================================================
FILE: data/sudoku-extreme-processed/lvl-280-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:85b202840b033ca629551498555a6456a3a07ad94caa75baf453a35e5612636f
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-280-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:9b7d48c2121a15aabe3a43cba7943bac6dada4f1d5b6fb0095c290349fafc96d
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-281-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:92fdda02406d74a8fc06566b74d60630fed2e3d8e6285bccdba86893de94c579
size 452



================================================
FILE: data/sudoku-extreme-processed/lvl-281-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:4d331041824f36391da89217604dd9db08774eafebaa3b89a64dcbd7ac81c05e
size 452



================================================
FILE: data/sudoku-extreme-processed/lvl-282-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:82292ccf145b854982484e40aad472276a25054b586ebeb4717a35064789eac0
size 371



================================================
FILE: data/sudoku-extreme-processed/lvl-282-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:d862c5c2ad5d3e6916206a195f894bc394e3ff2acd6f283368e847d4d7c24223
size 371



================================================
FILE: data/sudoku-extreme-processed/lvl-283-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:2e91453265dc2c0f8f67b7551eaa9b400541850ff1c2e8a9a7302d9829bc542b
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-283-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e603a7de092f28f69e02db608ffc4685dc5511f5b8fc3c0e564543f26c144ecb
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-284-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b8626c88202e8e877a0cc8b667b94ea7fe6572ee40abfbc37b5196bb11062db0
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-284-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e16f41787f063ea1f47c2fef9de1fdfca1d940de4dd4d2786e608026bf0da9e1
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-285-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:3c01cafa374cace9bb3d89b0030f3c6f949c61d2daeac03e0712d11a71935deb
size 533



================================================
FILE: data/sudoku-extreme-processed/lvl-285-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:1a48e41963f3f7766da94f9d9733e4056a55ab7a9a61e0eb6b0848ffab818024
size 533



================================================
FILE: data/sudoku-extreme-processed/lvl-286-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:9983215f22687a2b1308687b3ddf7b29b0e8a80fbd0ea9dcfebcf5cd56625744
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-286-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:9d302f8c491ff9f951d6963a6d35f396c8702f6b4be6f508f283d0930ec1e2bd
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-288-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:5fc544aa41e19ca374ca3ba7c977a43fff8a0ad16baabdfc88e68afdea05e650
size 371



================================================
FILE: data/sudoku-extreme-processed/lvl-288-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:8aaf1573ea7d41cebff37ecb43f4afb8d3907fdb0e436a65a6f3c42aa34c58ac
size 371



================================================
FILE: data/sudoku-extreme-processed/lvl-289-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:5235c729c71af60777b272b30b967c96776bb358319e074a8d10f10c5435bfc3
size 371



================================================
FILE: data/sudoku-extreme-processed/lvl-289-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e28fa18acb82f2e758993c247e1b70a67f353579da8c44b4da3082dbadf5bd36
size 371



================================================
FILE: data/sudoku-extreme-processed/lvl-29-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:5643acecbbdc063a5354c3056e0ccc7e77c92d5d671b9c1c820a6e8db27027d6
size 4685978



================================================
FILE: data/sudoku-extreme-processed/lvl-29-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e2d04510bf7401a857cc18812f45fde328b6230381984a091b1d239b413682f2
size 4685978



================================================
FILE: data/sudoku-extreme-processed/lvl-290-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:8fa24fc90f0904644a339cf4861da10d6acde9e545b73c1b079b29988d9cf6eb
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-290-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:757a605ce0720651228602d1eaf593e1573287325df8653bff04b23e75ecc0e0
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-291-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:7935d5f360657c1c3b1e64288d10d1ce16a62258cb9f17a90d5fc05a8d18f99a
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-291-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:4baf191d4270193946053225acd4a81414b1e066b04ac680cb20c96aabc91d7a
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-292-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:3a7b47cb0f80c2f6243ae74a5870585f5715b80651783228374697d5f8746fbb
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-292-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:45dd0c354bf56c8b94e9bbc2d153c90490e135410b2dc1063fa4d936d77dff99
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-293-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:c35c43c875267b9aaad313c73dec32d23c518af90bcec3cd9cc9680bd2388b5c
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-293-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:2a440baa3b0b9aa9636d440b8744c78d9572199060fb2bf990cf6125bde1f21a
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-294-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:2f38fe4c72880b2d5883fb171c6f5b1e9909ef27f807f222145904985e503f9d
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-294-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:d3fbacaa5b9dea9a8415d120aa5012dbdc6a72045433e6b8b9d462f0e5d9a763
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-295-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:902bcd1e696a13750f3f593e0bed6ded5d10e59834753be8d2a5bb55861ed11b
size 371



================================================
FILE: data/sudoku-extreme-processed/lvl-295-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:403e87b2c24a027fb663991b1aee6b35858252333106bdaf2a24bd66c935ea5e
size 371



================================================
FILE: data/sudoku-extreme-processed/lvl-296-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:fbfee5b843903fe9e52ab626bb96323c1abf3fe56cb5198d58ab2f67096c95d6
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-296-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:5d749eb7ee29c8f1ae0fd469e72338387b0d9af442573076ba16fcb39f1a28d9
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-297-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:771b31308a4a27bc48bc3962c804e9422db7957c85e2bf7db91190c19e87c110
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-297-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:2ef82dac7f098215cb7898db4398330802691205ba3cca521b7d5fd01a27b703
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-298-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:c2b77efe0a643d307062a951e8be939845aa82db382a70059fbbc9378082c8fb
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-298-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:cffe9682e616eca3d90059bd4ce92e9fdac8c2b490bb13632f268ce44b836751
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-3-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b5676da3b25544a30081c2b9bde17381815f847dd6d18e879f3ac66626e85d1a
size 7445162



================================================
FILE: data/sudoku-extreme-processed/lvl-3-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:7ee0f6b4587c88f4eff4b0da1654450f3ad21660484b07592a52a1ab01756929
size 7445162



================================================
FILE: data/sudoku-extreme-processed/lvl-30-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:4112d5ac6bcb981f6186ca239c8ead5129fb360e40e138fc504e0cb50007b4e3
size 4532969



================================================
FILE: data/sudoku-extreme-processed/lvl-30-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b5a680a093db3702be993f2a79bd067144388fd48644d8449811109a021f192d
size 4532969



================================================
FILE: data/sudoku-extreme-processed/lvl-300-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:df4f0bb8d87763db659f9b162cf0db09260d9a45b3cb504e3b2407c47d52c4f7
size 452



================================================
FILE: data/sudoku-extreme-processed/lvl-300-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:106781f40a1c4bffe3909ccdadeafd25aa2c059294461b68071ce77fa94d1d48
size 452



================================================
FILE: data/sudoku-extreme-processed/lvl-304-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:a54b5f0226c2794d9ee2383e4dbf665d1219e2ad0e571d81feae3f5d3fe23fa4
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-304-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b63d9ea8d7bf798d3d8d4065ea867973f6c01bcf14498c4341e262d885bca375
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-305-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:d5c54e916055734c5251bb64d613dce8fe7fd3f6b5b93bf994a5caa55f0ae262
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-305-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:7afb218c39868f6602c05c149ab3250b58df7b30448ef9253dcc29d5381423b6
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-306-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:02d0bb4f1a99b75b16e7b0896929733dcc24dec95e31ad8e2facbdcab8c441dc
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-306-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b835fe03ef19e92806ad48eb32e4bca3feeecfcb52a6b02fd7880f63720c3ed8
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-307-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:aeddc1fc023c8fa1a6060370f8f5737abb56934eb9cbde0f3b931ad791c2cfec
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-307-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:f641dadd4cd43b81176c4f6c653cf743a4f03c0dce57622a1f48b6bb8e0bb90e
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-308-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b123e0f7141e72b2089f1394b03a2403b29136ca0a0a024a8fd2f47857850f0c
size 371



================================================
FILE: data/sudoku-extreme-processed/lvl-308-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:f013d87009a30f709cf14910640b303faea1838d94fb734f2a7df0da0af38968
size 371



================================================
FILE: data/sudoku-extreme-processed/lvl-309-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:96e506db22cd1a7f7f925c3571eb8c9ed7f7f2d429d40f145d3eb4dc832861c8
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-309-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e47ec901bd20d37e86af54bf62964b3eecb5ba43e803f6ca02b00ebe2d6a42ce
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-31-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:8a10b2ae522f91b78dbf62c8fc56513a30a8acfba6c5514f960c5fbebefbc632
size 4345859



================================================
FILE: data/sudoku-extreme-processed/lvl-31-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e1618678273b07050764d3d05e450f439558f89055ad90b0e04c52aca7b69062
size 4345859



================================================
FILE: data/sudoku-extreme-processed/lvl-310-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:2acbf591c35493dcef42bc4b50f18f4d77e2ec11f6a6e39a5ac869532c56133c
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-310-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:46077c86161cd48618e09243ddd17abe8ca983892c1a54d111e0068ddbf66af9
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-311-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:2f7314b388e099aab7b24a46a253a3ca5fc693700f4e6ed2e83c7dee91bcf38b
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-311-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:10c56a5cb390e9b61baa6b244b091194f5fb20a75d875100cac9e037cc3de6ae
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-313-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:9f387bffb1e5dd5ab372e0b4de87ba3e7eb9c1f9076e403fa7cd3a758706975f
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-313-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:aae47c078b12bd9c8c885b45ab1ee8cce17da2b7adaa83089a9928cac40a327b
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-315-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:823cd1044aa062c1f0f56c46ba72147c9bd987ec114a07b97f98f11caf7d00a6
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-315-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:d3e1f95d4270548f58868d14c1e1668b14ddb750d8fbe8440a267d9fa51747a3
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-317-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:6d9f2f73b0a6498dee22a87cc3af20de6dc87b49abebb825b3e0290d67c86078
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-317-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:18bdae27ddd9766405fea67d565264528972a46eebbf39f91f5f45b3415508e0
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-318-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:8903c3a430600b8511f84951da46688e740d4ce74135b01a8a0ae5cd3781c677
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-318-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:4b3b1ef9b5ae5b5f53f365adfd5344c677952a3725af5b479ffe3436289ec8f1
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-32-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:64ea9ea33d4c76b118b018743e06c3ce21d8b3bcfac5e3b3ab2df6a50fd9ea3a
size 4205567



================================================
FILE: data/sudoku-extreme-processed/lvl-32-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:a760bd602535ee5ef2d3af1edb49998c9237c92caa21e967fb17645652f8e05e
size 4205567



================================================
FILE: data/sudoku-extreme-processed/lvl-320-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:8590801d7d8f4405eef3747770dde3650a00a329bdb929d989d2039c31c3130d
size 452



================================================
FILE: data/sudoku-extreme-processed/lvl-320-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:728bedf540b0487d07842ce0ef7be7d4207c5e58885a9d09cc0d5965232c878e
size 452



================================================
FILE: data/sudoku-extreme-processed/lvl-321-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b5468d3c8b5a1e4d12a5189a2803331f953cea3fac54193702a56a770e632104
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-321-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:0f8cd461e968abbbc29219f4ee38f5c9bf75e9c0dcd5bf1057f22d4cc58a9a7f
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-324-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:39d9c5491ff8a78b77b6df201ebb329869e1c63f84589856a773ada8d1ea0e27
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-324-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:5eda56c5a5c5aaae00f82df2833bd1ba51b9afc737c700a391cbc61738ee14e3
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-325-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:99b6ffc91a9ebe482e507caeb51ede748e8ed316718af3ca01f5e5b2b76076ba
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-325-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:fc6c03bf9084875a491cd7b90d5af0448c0b168c0460f43fcf7c91d96efe25d2
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-327-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:3fb69083b0b4b3869b22690453887f6134fb7eb17f0da87b39ea34769df23024
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-327-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:f51c89575d164e4b4c14163cbe3f5de65f4a899af35c6153bf3cb9b33aa14c9d
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-33-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:f8392cdf8fc2e4e2839de6b827ca0310dfbe43dbf0452b92b966ab7015d937a1
size 4089818



================================================
FILE: data/sudoku-extreme-processed/lvl-33-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:77a1d8d56d98f1211340ea618ed7b87569ac7fa21efeccc6eb59f4228d848900
size 4089818



================================================
FILE: data/sudoku-extreme-processed/lvl-330-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:02019cd851d41e3dcd3a9cd7d0725c97a0c6ac15f2ad5278605c045d0fec1eff
size 371



================================================
FILE: data/sudoku-extreme-processed/lvl-330-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:98f0d78f69d8b8fd78fb4e390917445ea1b1bd1d1f547ad8952387f2d6f7a582
size 371



================================================
FILE: data/sudoku-extreme-processed/lvl-336-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:4a4eedf82e026ed3aabdc9f334c27a45d7e0877deb68fd8ce7c385dbed8333d1
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-336-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:8f2fc96296c2a9f531789e9d2b73ba28430b2c93344b2f52b1ed6d10bd531e9b
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-339-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:355a25f7e7946be92c1c6d15a39e8dd2f87ae2af159deaca67801c0be5992ecf
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-339-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:78c67ec6911611fb36abbbae7360fa4dcd0751b01a6ed05de3c1bb483aed9d4a
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-34-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:3f7c88df2314a4b5cbe189a4511693e52ba01e64537d9284aea12356eed22504
size 4029311



================================================
FILE: data/sudoku-extreme-processed/lvl-34-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:65819f98b2d450b8971ed0b8c9b8a3ab0c7fbe9c03db32c28152a156511b6d51
size 4029311



================================================
FILE: data/sudoku-extreme-processed/lvl-342-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:2a977c3120528e5bd9f0b76cb597813e5d1dce44a4d59a5ec359c54e0fd2ed18
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-342-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:1bc622b931f0fc608f3251d6b8d339b9b340fd5bba296d2b67fad9e0faef600f
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-344-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:17a647f5a1fc11363acbfb94db7341847ca59ea75b9634e41c46e7e4cdb34149
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-344-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:d9c465fed12ad38d85a93be2578db14f52f629d0f7e128a927b6d6a8ba9e54fb
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-346-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:51e00cf11bac053075c3bf7b1aca5ee86005c17ee0705147f1fa3246a176792e
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-346-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b9fd6037a55dd0533f69aa2d45fb9b1700175c9cc093b1535318b92509c009f9
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-35-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:5a44f2cd27f808e67279d8e653831588c77c4601ee45d39bb2774cbd1e526cba
size 3920609



================================================
FILE: data/sudoku-extreme-processed/lvl-35-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:f54f1a14bac8e46482bfd958607c8c9cdf7cf6cbe36209d10c52e9c00dcae9c7
size 3920609



================================================
FILE: data/sudoku-extreme-processed/lvl-353-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:6ffb0432c5c1306beead6ba1329ea10de7ee2576d7c85a297b44cdd6eace969f
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-353-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e38e9ebf6f74d8bfbcb4511499942098880a8d1f54b4fe3eb49ec4f18966a558
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-358-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:df3843e62baec788a267cc6d52e76c8953c85dcf5069bea4c7165057521174f7
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-358-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:0225dc9c9ee90e39d7a75e1d213e8cd177b9ba95ab50280f11aa3d07392c33f4
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-36-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:05e3b4fc3f2e3a206aff61fc68b72f92ab6b598bc6fc62aa4ccb4897d8a195fe
size 3705959



================================================
FILE: data/sudoku-extreme-processed/lvl-36-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:6d5d9be75ada040e15e24f37ade01f24931545984edc09be4970113e13ff1684
size 3705959



================================================
FILE: data/sudoku-extreme-processed/lvl-362-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:883e9193932c4d17b3663e32bb3ab0055c5c15729da455ef3698b33b668eeff8
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-362-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:6484d45c18d598f044fdecd14b41b81e7aaa73abad15c61de036f0b19ec6bed1
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-364-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e307b3c1cecdeda3ece2a6f2b52116dc267b31c179c8e96915987127fd396d01
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-364-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:da95e38aedc3656ad75cb523f38faf7091ac6efb53709a4577417a7f12e12496
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-365-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:ba396008bc116f41b56072757dbe3582990547d826bdb475cc83e96a24264f13
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-365-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:653bad2a0e9c8a79dac91aedd401dea5ff2ff90df787ae90dd8924499da134d5
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-366-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:c622c1299f5ea754bd64ce7d42260b9e6aba9b18464d5b88b4f95f1b1449a9a4
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-366-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:4d47fa87ee4ad071657e6c6ba407a9bbce7a7bfe723086653ca69e9ce4b6e424
size 290



================================================
FILE: data/sudoku-extreme-processed/lvl-369-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:5188feace66d3a6f937d1caedc6323c72d72d80196a830abdd37552676c24627
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-369-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:5894a7f7623c6c76ed8ae1daf6bd04ffa9cef988adb6024923f3fbccd19f2f30
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-37-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:9672b9d82082ccf674ed40362f9ecabba2fce4727b612edd78c2b2a7838ad9b9
size 3456317



================================================
FILE: data/sudoku-extreme-processed/lvl-37-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:7d8be31b0cceb1761a34f5d03b40d57203632b6ad54b6a9e0f9525c16213e8a9
size 3456317



================================================
FILE: data/sudoku-extreme-processed/lvl-372-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:92ed21ee6a1c7a8356a191ff1c992b34b6d3996be1f3db938786169f0551c407
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-372-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:cbf1e70ddba00963860f1d8e6023ad1b65843465697be1f6bdacc493b449d05c
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-373-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:690dd1159c1fd743c3e6e17e94dbd86f22e6baaf2f57f05604dc0abe26c75417
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-373-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:bf34b48eb8aade0b9edab5c09167ad331856739e4e9d33455ba7a48f9e970829
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-375-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b7d40ae650ab7dc48edd6e111cc12529a597830912c86370dce9048aa3762fec
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-375-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:31f3846f617a7503aa99685e8e1b80c9c91a98d135f2f30a6645d08a4d46ab17
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-38-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:580cb1148c55ca7b9f8d3666577750c34c807733d6f2eef3fa41c00db46fda3d
size 3422864



================================================
FILE: data/sudoku-extreme-processed/lvl-38-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:2a5ae1aa9c819946341d0abd77f3b70d0bcdc1bba07c706fab27465f4328d648
size 3422864



================================================
FILE: data/sudoku-extreme-processed/lvl-381-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:f8a116f6446822b3596479ebd0d12f1d02f212029da445b186feb68fc150408e
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-381-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:41a119981047b218bb3bce49f234785bb64a152a881886211f04ce74b01e7d86
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-383-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:32ecd4b62bf0689a2f213daa9f1282a49b139677a1e0b346da35a83a3bfc6643
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-383-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:55a197b626bf7d492bc4458f2ce5ded1eed55d054a9f2d24472ba977ebc14c9a
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-385-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:2b3c0ce1ec4d2d2ad2a648bc8bf60926113dfc8ebff841b7851508710ecbff25
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-385-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b4bc70c938d8b2abf79bd65a87423ab7bf3e34949cce3021357b6e7a037fe889
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-39-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b68b750d66e1c52f6de2783b8bb1dfd4a49762a17482841e30c1d629b5b69eeb
size 3330362



================================================
FILE: data/sudoku-extreme-processed/lvl-39-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:c740ad8ececf1394d336f294040d37e7c87d570c151b4d6a75e2dc7eb71c4fd0
size 3330362



================================================
FILE: data/sudoku-extreme-processed/lvl-390-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:6c3992a252aa0b0a0b61f6356470e32745ba47888813d01e1dd64d2ab8799669
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-390-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:8a7adbdde951037e196530d3c6a75e4c76c346111b39b314ec40016dc7bf1c1b
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-392-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:c33752e946ecfba4acb09559623b8cf4cbc7a07ec297c7228f8017a5212b6b8f
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-392-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:34112f4f9bf6d7d82d68fcf81f4793116b9677c68a38f9326b8fc334a79e54d0
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-4-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:6704f451610a9a27e002d9c01de865492b383f8f4683ba10fe2fb0809bdb4d56
size 6475754



================================================
FILE: data/sudoku-extreme-processed/lvl-4-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:eb7989c9b080861d58a1417276344fe2642f8b7b1297de656be3d81f8fdd0fe0
size 6475754



================================================
FILE: data/sudoku-extreme-processed/lvl-40-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:6cf86bff2281c75a6c0fd660ab23bbf1573fdbb7a9e364206a069919faa09caf
size 3185129



================================================
FILE: data/sudoku-extreme-processed/lvl-40-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:4bd5ae64f65bc36bc2d6c0d5b30e6d6eb1f272f6271f36015805a7b6bdc91439
size 3185129



================================================
FILE: data/sudoku-extreme-processed/lvl-41-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:0f75b34673c8e3c39fb8551c509406cf58aa2085c8da65c0f51ae806af1b52da
size 3088010



================================================
FILE: data/sudoku-extreme-processed/lvl-41-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:5cac85817dc594e312676912266b56968f2d5652eeba64d3694697bece0b9b4d
size 3088010



================================================
FILE: data/sudoku-extreme-processed/lvl-42-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:438f58f7ed59da981cb8bdc9de660a8c1d148f877db0fad5d8c958056598f1b6
size 2914427



================================================
FILE: data/sudoku-extreme-processed/lvl-42-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:eae3cd2f1e793aeaae6a127604085ee05bbcf33f5f23275c52f8705050a0df2d
size 2914427



================================================
FILE: data/sudoku-extreme-processed/lvl-43-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:111651261b99d83becbdfeb9c2d69285841f7d030f0c669680fbc1a1b5fb862e
size 2785232



================================================
FILE: data/sudoku-extreme-processed/lvl-43-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:41a485c13f7d483ab36a41209d03c26befc20564e13964013062b03aee132fad
size 2785232



================================================
FILE: data/sudoku-extreme-processed/lvl-44-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b6b8187ac46faf96a012a3d90afb6901bb0a61e94ee6d6641cbe8df7b7fab291
size 2708768



================================================
FILE: data/sudoku-extreme-processed/lvl-44-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:5d1c2a76f584b37ab4297e6ce1487479837b59852b1150085bf214048e20cd4b
size 2708768



================================================
FILE: data/sudoku-extreme-processed/lvl-440-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:1a98d4288d2cf98c757b66167e93a7d3b41c24dc9ae2ef262e7c345509b6eb3a
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-440-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:c8ad23f0b85ec36acbecc5b5bca1b0f07e58078042c61fa68d9ec222b18ef237
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-45-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:bb705218f77de5af5a6f8d0aad2e1d3fa9681f25ed2d2023659f32b18b01dcf2
size 2596988



================================================
FILE: data/sudoku-extreme-processed/lvl-45-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:6b8506ef44f696584e1f8ec5ae663c6109be7c93fb72e238a9548ec7da7409d4
size 2596988



================================================
FILE: data/sudoku-extreme-processed/lvl-452-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:0a37f23cc45f0cd1733cbbe69facea7f49078e55c0ecdbbd375b8525aa968d77
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-452-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:19edf5fc0d7688dacf359dbe190dc996c32eac90b8cbb028be386ee9083f62cb
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-46-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:698bd1ab7c9a2064a5312766ad0a213eae4037e776d35ef9c3fac799f058f7b5
size 2473463



================================================
FILE: data/sudoku-extreme-processed/lvl-46-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:db1a9f260e20d5da70cc0efff9f9b056030551061fc9b8eeff42adfd887f61f2
size 2473463



================================================
FILE: data/sudoku-extreme-processed/lvl-465-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:44a06ebdba9f78310244d969d5cf2ba9507ec1a87fc60a48e9b93e794b4c3915
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-465-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:0ac1239d0dccbde83ae84374bddbda007e88b1efd2a87a5b4f9735dae8b80e50
size 209



================================================
FILE: data/sudoku-extreme-processed/lvl-47-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:faedc9ebbc7ce76ab01f95951b11324141a5e0382388694b0a06787e64ac0fc7
size 2410202



================================================
FILE: data/sudoku-extreme-processed/lvl-47-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:9ce87fe57c90e1a4473d185436a8d5253567e9650454c8de149a041ba59be452
size 2410202



================================================
FILE: data/sudoku-extreme-processed/lvl-48-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:7d660ca1b0dfcb198dbe096606dd4213969e97bfbbb873e1e34ff6159b3828e6
size 2283437



================================================
FILE: data/sudoku-extreme-processed/lvl-48-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:acfad3f40edfdafd944f5a7e5d1beaf9cc310a0871ca37a8426ead60e872fc69
size 2283437



================================================
FILE: data/sudoku-extreme-processed/lvl-49-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:eff7776a16c0ee6837414edb0af072f764886f4abe43e76de2b149f2c3236953
size 2200655



================================================
FILE: data/sudoku-extreme-processed/lvl-49-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:2870366acbe18bccb449c0cfddbde4ae4f5449dc9771dfafd70c9567dd4cedb0
size 2200655



================================================
FILE: data/sudoku-extreme-processed/lvl-5-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:f7434e5a490e31eefe3b686125c084d264a0493eab73d42d1422a10fbb33cb97
size 7201433



================================================
FILE: data/sudoku-extreme-processed/lvl-5-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e01a84ee6ff9ffdcecfe56b49c0c93fa977c5e32fa3be539965499bc1b05fec3
size 7201433



================================================
FILE: data/sudoku-extreme-processed/lvl-50-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:c1dbcc8238a558dba8ed5b4f862037963451a43b0dca5b52a1896f84c118ad56
size 2084501



================================================
FILE: data/sudoku-extreme-processed/lvl-50-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:9897121c2a860a308b4861dd69925722cedd5ca22f2c18ebbbeef3eff8010788
size 2084501



================================================
FILE: data/sudoku-extreme-processed/lvl-51-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:ebcdf1384e813db64d9f449950fda1e439409c98d38ef228685ff560e354afb6
size 2003096



================================================
FILE: data/sudoku-extreme-processed/lvl-51-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:29dfb9eac06c0bbbf11118aedc347d8c448f93b27561b04a1524690c1e4be4a8
size 2003096



================================================
FILE: data/sudoku-extreme-processed/lvl-52-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:d6f01f5208c8533bd10fd3508ae8e438d9f45a9508c8523922c6d05c6196be21
size 1856729



================================================
FILE: data/sudoku-extreme-processed/lvl-52-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:615e71929f240138f4260b1f54d45362ed738fd6b225e99a459484c86a6745a0
size 1856729



================================================
FILE: data/sudoku-extreme-processed/lvl-53-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:62bc8ca28c6b484ebae2539d8d9abe48ec9d0f4f688f49742cadefd6b40207dc
size 1746083



================================================
FILE: data/sudoku-extreme-processed/lvl-53-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:36ef47ff961a84f947a691ca4e7c35fd029a370effa468a255bc7604b4ea51bd
size 1746083



================================================
FILE: data/sudoku-extreme-processed/lvl-54-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:3f28bb9c94fcb76897c551aa8603c2de897c8bb3f72d2370a4622fa1272d99be
size 1649450



================================================
FILE: data/sudoku-extreme-processed/lvl-54-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b79cc045e785358d0d7e667eca0a1710e2e8eaf3d1a61b271a32124226c0c9c5
size 1649450



================================================
FILE: data/sudoku-extreme-processed/lvl-55-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:377e18c5902a449ecc1748bf3d2ede5748041211a0ac01c45a67b8912e904cd7
size 1517501



================================================
FILE: data/sudoku-extreme-processed/lvl-55-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:506c2bd19f9e1a9ed4dfd6ca86815e1eb71dbfdb15f2529be32406ec5142ca20
size 1517501



================================================
FILE: data/sudoku-extreme-processed/lvl-56-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:a63d57711e32404e434ae408cf6b13235bf1a34dc3cc2347df23123966698f21
size 1431722



================================================
FILE: data/sudoku-extreme-processed/lvl-56-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:46afd60c5a29c972c6309da08c9510f93492ad5aa64628583fa616c0b72a1add
size 1431722



================================================
FILE: data/sudoku-extreme-processed/lvl-57-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:3df971e4228ec36d40b651aaf7bfa412f01da286e14e52be608d3247b630c714
size 1346024



================================================
FILE: data/sudoku-extreme-processed/lvl-57-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:df574f19e7a6bf88d42efa8b6c565fb58f658136c62c3d24ff241728c4cadb1e
size 1346024



================================================
FILE: data/sudoku-extreme-processed/lvl-58-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:20f620e49d4d2ab009a92bb60984b602741910df5897e51658b6ea972ba15589
size 1227197



================================================
FILE: data/sudoku-extreme-processed/lvl-58-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:6f29b65985f908dbd44a8f66b08727a61ce9ca86030c93b1408b6a5cc1f99ecc
size 1227197



================================================
FILE: data/sudoku-extreme-processed/lvl-59-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:13a92fc07b7c03b18040e728cd61bdebfe023b96d9767a2167e3ac8b49440f9b
size 1174952



================================================
FILE: data/sudoku-extreme-processed/lvl-59-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:53e552c34227f3bbebac4916256c4db61eb3c70aa941d6d40cb294bc98dab033
size 1174952



================================================
FILE: data/sudoku-extreme-processed/lvl-6-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:85e2d386e22312b49cd3012ae3522d431d4914410d510a1690d2fa2c25ae40ce
size 6611105



================================================
FILE: data/sudoku-extreme-processed/lvl-6-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e5f3c774cbd6100c2c1802e5942dd730e09a8fc8e2387ee42720ba61d760f85e
size 6611105



================================================
FILE: data/sudoku-extreme-processed/lvl-60-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:ab16b0d1b02f828b9628834f609f810caf99265ad8fb984e7d97ca57b2ba18bb
size 1105616



================================================
FILE: data/sudoku-extreme-processed/lvl-60-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:847c710d5db537f7a9e1f295f12cc800692fd14357c3e7a21d49b66ef0e7ad08
size 1105616



================================================
FILE: data/sudoku-extreme-processed/lvl-61-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:ee60cea37146bbd3f08784c7bd2ab68c18d838d2ce5694f63fd90758450f5ba2
size 1018460



================================================
FILE: data/sudoku-extreme-processed/lvl-61-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:03d7eff1a580fa04c86e50a64ff2b3c477e7e2f9cb21ec5a8a24c0f1655fb69c
size 1018460



================================================
FILE: data/sudoku-extreme-processed/lvl-62-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:6551c8a0a209479c1ae331a00267a6f5e56a638cd372f240d7d8202697c78da4
size 946046



================================================
FILE: data/sudoku-extreme-processed/lvl-62-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:2ab3f827be0ffbd8b05262ac9674dec24b975e65f55826c0b0fc96ee7894db7b
size 946046



================================================
FILE: data/sudoku-extreme-processed/lvl-63-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:bd48a855e687be9dd544d09f0bb469ce93e7d1112aedb401d94de92920eef6ea
size 904007



================================================
FILE: data/sudoku-extreme-processed/lvl-63-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b6ca23f6e99484a3060c6febe5259806b6204d88c2e5d815573070cc035f05ad
size 904007



================================================
FILE: data/sudoku-extreme-processed/lvl-64-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:450a3384cf457b75ea8ad06f07751b0c12a7dcfc80f83119b02efc703de1574d
size 863588



================================================
FILE: data/sudoku-extreme-processed/lvl-64-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:c454ccd9785c77a41facb34e1407d4ee0679c1313b24f0962e9a5b3c89868378
size 863588



================================================
FILE: data/sudoku-extreme-processed/lvl-65-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:1df187a9dcbba8c43ac6b349c6807398051f15028ffbb3b7af0877e704a88959
size 801461



================================================
FILE: data/sudoku-extreme-processed/lvl-65-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:c70326671525112bb29d92a3c144accd36e0ef46403057114820448da598898a
size 801461



================================================
FILE: data/sudoku-extreme-processed/lvl-66-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:9483b949ea9014c65c718a8d9d82719b66a9e852a7d8d9ec1a81c4da7c4949e8
size 755615



================================================
FILE: data/sudoku-extreme-processed/lvl-66-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:2e9bf2186b3759ed8a3f6f89ef36a48d5c02f74f6fded48e2f46557a3fe5037e
size 755615



================================================
FILE: data/sudoku-extreme-processed/lvl-67-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:23aeaaf49f2fa984e602fd5a351375b9d8d1797a308aac5ebf244b95a5fc75da
size 722243



================================================
FILE: data/sudoku-extreme-processed/lvl-67-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:c96511ca32895e4e5deee76f0f9186a92451a6421492d2053f62787958539292
size 722243



================================================
FILE: data/sudoku-extreme-processed/lvl-68-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:95cc48c2582e686b3a62be4f3278b7d44f774b524be9cf19cb4fd2be3d6277d9
size 678827



================================================
FILE: data/sudoku-extreme-processed/lvl-68-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:a3c3926cdb49a5a4714a156ca98bf65f2b2e091bc771ca2df31ecbd12f878687
size 678827



================================================
FILE: data/sudoku-extreme-processed/lvl-69-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:1ad6655f7d0f9dce2661480a6c1fcf7e96d1bad29f0ab8c02e8403efd91172fd
size 657848



================================================
FILE: data/sudoku-extreme-processed/lvl-69-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e8de1823e366451089cb0c30f1e8259a99aada4766540549c8d0f97da03eab92
size 657848



================================================
FILE: data/sudoku-extreme-processed/lvl-7-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:ae3b5feac333deccbb71072e102b0cb173784935f4072b4f1e105193a68b40d7
size 6079016



================================================
FILE: data/sudoku-extreme-processed/lvl-7-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:feaea5f8e56230330c24f5a60b7a611370a509fed515a350b744b84e41f27370
size 6079016



================================================
FILE: data/sudoku-extreme-processed/lvl-70-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:09e1c1d09076ca788bdf0cb1704b829ba71efaffcbfbe78bb932607394fd5003
size 608276



================================================
FILE: data/sudoku-extreme-processed/lvl-70-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:a06c9dad1ad4772ad296c37774bdad139fba10548171beeec31e8d444156058b
size 608276



================================================
FILE: data/sudoku-extreme-processed/lvl-71-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:9dff69cea70659dd51daa9cf2e71947d833e35bd9e4c989727cbf8a6bbe605b7
size 592400



================================================
FILE: data/sudoku-extreme-processed/lvl-71-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:81faa87addbd4e89afa470ac9a4ca73454372deb54c599baaed846fa3c5a9f5d
size 592400



================================================
FILE: data/sudoku-extreme-processed/lvl-72-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:375ab1e034bdd3513d1aa0160ac1d20e6611544fa500fe8ac1d08071ab8581b0
size 543719



================================================
FILE: data/sudoku-extreme-processed/lvl-72-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:06ef408e71755bdfa31a9e8340c291c7d3fa79d27ffac6871d2d4c61c5f62924
size 543719



================================================
FILE: data/sudoku-extreme-processed/lvl-73-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:7ad8eaf03dee14bf0944086227e4e7eb0aaced98de5606164c369c939b4ca640
size 520229



================================================
FILE: data/sudoku-extreme-processed/lvl-73-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:a057f45f9fa0dfcaa5d387552626e82e9f40f8c728431a582f37d8f725b06b6b
size 520229



================================================
FILE: data/sudoku-extreme-processed/lvl-74-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:a4b154a5a6542504be3e08aa2f1a2609045e4358ec1177fca92d7bb8ef4d0843
size 502895



================================================
FILE: data/sudoku-extreme-processed/lvl-74-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:5092f5b6c2cf39aa61f8500e951e43f42e49db2145d1f74f167bfbeb230586a7
size 502895



================================================
FILE: data/sudoku-extreme-processed/lvl-75-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:3a1647f6468effcc162d70511b8a848d8da499a74734932e7806148165b5bd20
size 483860



================================================
FILE: data/sudoku-extreme-processed/lvl-75-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:280fe28ece428e30e766665a2c72c0f92c6e3355aaaa231ecb120c5003ebe862
size 483860



================================================
FILE: data/sudoku-extreme-processed/lvl-76-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:4b0bc392ceb7a4a9987b650a3b13104943ee06b2195619291bf62f51d3554b2e
size 459155



================================================
FILE: data/sudoku-extreme-processed/lvl-76-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:ee7a7427e16e88b11b62236fd0b82097833a1c116cd78215c16f8e4c673c9243
size 459155



================================================
FILE: data/sudoku-extreme-processed/lvl-77-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:d5a829e022c822bf77be506c92fd8a629783f09fbfbb0554465eccf3ed7a3d24
size 431210



================================================
FILE: data/sudoku-extreme-processed/lvl-77-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:d185c2bc57e9f84ab3c00ddf6705a594d587284a443e2632c82564484b42ec4e
size 431210



================================================
FILE: data/sudoku-extreme-processed/lvl-78-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:933b4057e698343ab67ceee699ab01b0d6149b0cc1626521ea96145891dea123
size 414524



================================================
FILE: data/sudoku-extreme-processed/lvl-78-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:bad6a44a53974b4849fcfd7c7e976e8b4dda3f9024e21f63a8fedfa74e06448b
size 414524



================================================
FILE: data/sudoku-extreme-processed/lvl-79-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:0090c6272be4a34cb03759dc387e0b8a8b12db094a8a998d9ceab5d277d30103
size 393869



================================================
FILE: data/sudoku-extreme-processed/lvl-79-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:997f091e1eb579c118a3ec3f9df433e58f39e4e5740a51d36d7151857127c522
size 393869



================================================
FILE: data/sudoku-extreme-processed/lvl-8-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:20f3841502d821fd24a2394ade61653f0bd92d29e809243882e2c924b0752974
size 6051314



================================================
FILE: data/sudoku-extreme-processed/lvl-8-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e872a387dcf49e844dbf3070e13577c9bf7591ff0ec41ef66e3458d09587c980
size 6051314



================================================
FILE: data/sudoku-extreme-processed/lvl-80-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:edd9dc933d5350bbb6fb6905b184737f5dd075704c7bcdd5676e62290a6c544d
size 372161



================================================
FILE: data/sudoku-extreme-processed/lvl-80-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:4a8b70ba4dc2532240a0aeac2a34c7fadba6f3d618866e776edc2fc007e6eb57
size 372161



================================================
FILE: data/sudoku-extreme-processed/lvl-81-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:c64bc8292fe5a71a6652ee13195366a25a77a1e87e2dd4c840e0b111d4dde896
size 356447



================================================
FILE: data/sudoku-extreme-processed/lvl-81-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:31f6859ceb1da23d4cf7e8bb03286fbfd0a1a9e98c76ea2a06538a8def0819f8
size 356447



================================================
FILE: data/sudoku-extreme-processed/lvl-82-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:47d398ec617f4795d5455379719e0b82bdd71be2f68389228dc7d8f5fbf5d6ae
size 338546



================================================
FILE: data/sudoku-extreme-processed/lvl-82-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:ff33545bf6d154bd38a8841df19eb59ffa5f206ef3813e5cac941b2e448c9e71
size 338546



================================================
FILE: data/sudoku-extreme-processed/lvl-83-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:5598b4639c63be76eae524efebdeef22c6c97428a73a4762d08579c93f62b96e
size 321860



================================================
FILE: data/sudoku-extreme-processed/lvl-83-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:e3179926762c3cff860545b5287e2f3c4513437a8c0e1dfbda0c0d38f41edce1
size 321860



================================================
FILE: data/sudoku-extreme-processed/lvl-84-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:685fa0dd9e392e7b61e6309ca4a39723e9d818629c4db4472764c6ecc72dbd24
size 299585



================================================
FILE: data/sudoku-extreme-processed/lvl-84-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:43c2399d4eecd774709c99f2062f779eea1e331b9c56ab57616c575e93953aac
size 299585



================================================
FILE: data/sudoku-extreme-processed/lvl-85-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:a84c7bc236220976333fb24ab37cdd9fcd89f03aa902f01c17c4f8fbd0d069ef
size 302096



================================================
FILE: data/sudoku-extreme-processed/lvl-85-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:7b55d4f5e703e31d54db08831ec81817c0f0aea6cc342a3889b8a261b2196847
size 302096



================================================
FILE: data/sudoku-extreme-processed/lvl-86-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:9fa3f7a8ab0e239f89d70e26f8b52f1d98a32ab085a5df28b959deefd77f9bbc
size 289298



================================================
FILE: data/sudoku-extreme-processed/lvl-86-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b844158d555047f5d3927bfe7648b5f2b51dd4df8e3ef6cbe7bb0dc01a85b8af
size 289298



================================================
FILE: data/sudoku-extreme-processed/lvl-87-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:dbc3a83bbe24a183bd1cb21cd997249bb4cb54156d31045db723bc28b79ab610
size 282413



================================================
FILE: data/sudoku-extreme-processed/lvl-87-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:8610825565162a72cdf80c3966d555a200a1aea102f9ac94446435ec566abace
size 282413



================================================
FILE: data/sudoku-extreme-processed/lvl-88-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:0e84c58d51d5eb541d9dbc400bcb461988090290a431a7e470fdabdf0a8c5591
size 259733



================================================
FILE: data/sudoku-extreme-processed/lvl-88-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:8292574846bf3a0799caa147ce8cfc5359f044d0f841854bf2e7312b4fc51613
size 259733



================================================
FILE: data/sudoku-extreme-processed/lvl-89-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:f0eb48d7fbccf49f1b3959576e6db35cfcb5c5c18097a78639dc73c8cdc65ae3
size 245720



================================================
FILE: data/sudoku-extreme-processed/lvl-89-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:ea59be78af9212573f2c96e6e96c575652d6a8a710db3962bcf8503ef9125e7b
size 245720



================================================
FILE: data/sudoku-extreme-processed/lvl-9-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:9d8b0d5cfd7f20100e6b6d7ee82f2ae68120ca5ff916b5be6ce2de41b3a52c0b
size 5906486



================================================
FILE: data/sudoku-extreme-processed/lvl-9-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:332d3762ab30a99a3d83389beb0f0a486cd7997514e05a35a208eadb3e7304bb
size 5906486



================================================
FILE: data/sudoku-extreme-processed/lvl-90-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:d5ec14a226a4a5bf99af9e8815f1c6a56809770942e9f052a5d5b497299dad5c
size 234299



================================================
FILE: data/sudoku-extreme-processed/lvl-90-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:12c73817014ceb81bb5f1235220702c233c088b2c8cfc9d22d1325812e5179f9
size 234299



================================================
FILE: data/sudoku-extreme-processed/lvl-91-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:af87514b283b537d9e97e8b1a23d49f0ce156ff960335ee9486d107cdaeb58e2
size 226847



================================================
FILE: data/sudoku-extreme-processed/lvl-91-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:eba56556f48ada236502bc1551a010309fa1263bd4240e742cfd1525918312e2
size 226847



================================================
FILE: data/sudoku-extreme-processed/lvl-92-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:1306876bf2d4d7fa56fcaca9c929ba222caef841e7466ca7f944799a18da866f
size 214211



================================================
FILE: data/sudoku-extreme-processed/lvl-92-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:fe3bca7d604c21f6b20f9ac52daed07d1889bca3d30bc1250f699089e2df26d9
size 214211



================================================
FILE: data/sudoku-extreme-processed/lvl-93-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:99ae06180b7cabad3fe24412d9e66682eb937d114a6002fd7b11ea078918d048
size 207407



================================================
FILE: data/sudoku-extreme-processed/lvl-93-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:da0623272ef662c5378d22ca1928c68afaa5d7621cf80348798c568cdcaa8f4e
size 207407



================================================
FILE: data/sudoku-extreme-processed/lvl-94-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:52787b169c71311af1ede4d64fca325d1055b6c58799b3cd00d3b92c3a23203a
size 200441



================================================
FILE: data/sudoku-extreme-processed/lvl-94-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:fd99077a7f40b600733f354a056f33f865cd1fcc585a15c7cd15c16541bae8a9
size 200441



================================================
FILE: data/sudoku-extreme-processed/lvl-95-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:262754403bd7b1dba8fabb94c536b5a3110ba7c165fe59790ddd2002c323719a
size 186347



================================================
FILE: data/sudoku-extreme-processed/lvl-95-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:14482488d29a57efc982f367558240bce9a973b145c4e0761bcc49e765f6cf21
size 186347



================================================
FILE: data/sudoku-extreme-processed/lvl-96-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:7721d045202662349d0e9c49cfdff279520f56228e19dba64a4506e382a0924a
size 189830



================================================
FILE: data/sudoku-extreme-processed/lvl-96-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:df5143f80447d2744cec9eee1833dd29ece24179480fb13489f440de417a2406
size 189830



================================================
FILE: data/sudoku-extreme-processed/lvl-97-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b53131dca9cb06236cdfbcc70eb584cf13bfa0b91f97d10de63c03cfd2fb00f5
size 173954



================================================
FILE: data/sudoku-extreme-processed/lvl-97-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:69288c3d1a2ee18061db9f713dc3b2a18f9e51afdd673b9f078f59e62b48ae11
size 173954



================================================
FILE: data/sudoku-extreme-processed/lvl-98-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:b92b86cf11b43e9f12dfa969f289d745ab8083f3117914d3ba93ff22b073d3a8
size 169499



================================================
FILE: data/sudoku-extreme-processed/lvl-98-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:a789602c81a8e3059fdcbd28e3ede5980d268f028b3675b32f7520fef79557d9
size 169499



================================================
FILE: data/sudoku-extreme-processed/lvl-99-inputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:60510261093ef294214ae61df410f0fbedc827f51da332702dc21776bc90d9f5
size 154433



================================================
FILE: data/sudoku-extreme-processed/lvl-99-outputs.npy
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:86d274ee25de12b9c167caa9701d25f6234a6c225b723630eb13b48963be69d4
size 154433



================================================
FILE: engine/__init__.py
================================================
"""Core solving and display engine."""



================================================
FILE: engine/display.py
================================================
# Display helpers: pretty printing grids and rendering sequences

import numpy as np

from .utils import candidate_mask_init, apply_deductions


def pretty_print_grid(grid: np.ndarray, prev_grid: np.ndarray = None) -> None:
    """Pretty-print a single 9x9 Sudoku grid.

    Newly placed numbers compared to ``prev_grid`` are highlighted in red.

    Args:
        grid: The current grid to print.
        prev_grid: Optional previous grid for change highlighting.
    """

    RED = "\033[31m"
    RESET = "\033[0m"

    print("┌───────┬───────┬───────┐")
    for i in range(9):
        row_parts = []
        for block in range(3):
            block_cells = []
            for j in range(3):
                col = block * 3 + j
                cell = grid[i, col]
                val = str(cell) if cell != 0 else "."
                if (
                    prev_grid is not None
                    and grid[i, col] != prev_grid[i, col]
                    and cell != 0
                ):
                    val = RED + val + RESET
                block_cells.append(val)
            row_parts.append(" ".join(block_cells))
        print("│ " + " │ ".join(row_parts) + " │")
        if (i + 1) % 3 == 0 and i != 8:
            print("├───────┼───────┼───────┤")
    print("└───────┴───────┴───────┘")


def format_deduction(pos, val, typ) -> str:
    row = chr(ord("A") + int(pos[0]))
    col = int(pos[1]) + 1
    if typ == "naked_single":
        nice_typ = "Naked Single"
    elif typ.startswith("hidden_single_"):
        scope = typ.split("_")[-1].title()
        nice_typ = f"Hidden Single - {scope}"
    else:
        nice_typ = typ.replace("_", " ").title()
    return f"{val} at {row}{col} ({nice_typ})"


def display_sequence(initial_grid: np.ndarray, sequence: list[dict]):
    """Replay a solution sequence with pretty printing and summary statistics."""

    grid = initial_grid.copy()
    mask = candidate_mask_init(grid[np.newaxis])
    total_placements = 0
    for idx, step_info in enumerate(sequence):
        deductions = step_info["deductions"]
        prev_grid = grid.copy()
        apply_deductions(grid[np.newaxis], mask, [deductions])

        # Determine which cells actually changed this step
        diff = (prev_grid == 0) & (grid != prev_grid)
        changed_positions = np.argwhere(diff)
        delta = len(changed_positions)
        total_placements += delta

        pretty_print_grid(grid, prev_grid)
        print()

        print(f"T-{step_info['step'] + 1}:  Δ +{delta}")

        # Only report deductions that resulted in new placements
        changed_set = {tuple(pos) for pos in changed_positions}
        unique_deds = {}
        for ded in deductions:
            if "value" in ded:
                pos = tuple(map(int, ded["position"]))
                if pos in changed_set:
                    val = int(ded["value"])
                    key = (pos, val)
                    if key not in unique_deds:
                        unique_deds[key] = ded["type"]

        for key, typ in unique_deds.items():
            pos, val = key
            print(format_deduction(pos, val, typ))

        print()
        if idx != len(sequence) - 1:
            print("------------------------------------")
            print()

    return grid, len(sequence), total_placements


# ---- Main program section helpers ----


def print_program_header() -> None:
    """Print the program's banner."""

    print()
    print("====================================")
    print("Sudoku Solver v1.0")
    print("====================================")
    print()


def print_puzzle_selection(level: int, num_puzzles: int, idx: int) -> None:
    """Print information about the randomly selected puzzle."""

    print("Puzzle Chosen:")
    print(f"- Difficulty Level: {level}")
    print(f"- Puzzles @ Level : {num_puzzles-1}")
    print(f"- Selected Puzzle : {idx}")
    print()


def print_initial_grid(grid: np.ndarray) -> None:
    """Print the initial puzzle grid."""

    print("Initial Puzzle Grid:")
    pretty_print_grid(grid)
    print()


def print_step_header() -> None:
    """Print the header before the step-by-step solution."""

    print("====================================")
    print("Step by Step Solution:")
    print("====================================")
    print()


def print_final_output(
    final_grid: np.ndarray, steps: int, total_placements: int, solved: bool
) -> None:
    """Print the final grid and summary information.

    Args:
        final_grid: The resulting grid after applying deductions.
        steps: Number of steps taken.
        total_placements: Total placements applied.
        solved: Whether the puzzle was solved.
    """

    print("====================================")
    print("Final Grid:")
    print("====================================")
    print()
    pretty_print_grid(final_grid)
    print()
    if solved:
        print("Puzzle Solved!")
    else:
        print("Puzzle Unsolved.")
    print(f"- Total Steps: {steps}")
    print(f"- Total Placements: {total_placements}")
    print()
    print("====================================")
    print("PROGRAM END.")
    print("====================================")
    print()




================================================
FILE: engine/solver.py
================================================
"""Core solving routines for Sudoku puzzles."""

from __future__ import annotations

import os
from typing import Dict, List, Tuple

import numpy as np

from strategies import find_deductions_batch, TIERS
from .utils import candidate_mask_init, apply_deductions, is_solved


def solve_batch(
    inputs: np.ndarray,
    outputs: np.ndarray,
    max_steps: int = 100,
    max_tier: int = 3,
) -> Tuple[List[List[Dict]], List[bool]]:
    """Solve a batch of Sudoku puzzles using ordered strategy tiers.

    The solver applies strategies in increasing difficulty. At each step it
    exhausts the current tier and only escalates when no progress is made.

    Args:
        inputs: ``(N, 9, 9)`` initial puzzles.
        outputs: ``(N, 9, 9)`` solutions for validation (unused here).
        max_steps: Maximum iterations per puzzle.
        max_tier: Highest strategy tier to use (see ``strategies.TIERS``).

    Returns:
        Two lists of length ``N``:
            * A sequence of deduction dictionaries for each puzzle.
            * Flags indicating whether each puzzle was solved.
    """

    N = inputs.shape[0]
    grids = inputs.copy()
    masks = candidate_mask_init(grids)
    sequences: List[List[Dict]] = [[] for _ in range(N)]
    solved_flags = [False] * N

    for n in range(N):
        grid = grids[n]
        mask = masks[n]
        seq = sequences[n]
        step = 0
        solved = is_solved(grid)[0]

        while not solved and step < max_steps:
            cumulative: list[str] = []
            progress = False

            for tier in range(1, max_tier + 1):
                cumulative.extend(TIERS[tier])
                prev_grid = grid.copy()
                deductions = find_deductions_batch(mask[np.newaxis], cumulative)[0]
                if not deductions:
                    continue

                apply_deductions(grid[np.newaxis], mask[np.newaxis], [deductions])
                if np.array_equal(grid, prev_grid):
                    continue

                seq.append(
                    {
                        "step": step,
                        "grid_state": prev_grid.flatten().tolist(),
                        "deductions": deductions,
                    }
                )
                progress = True
                break

            if not progress:
                solved = False
                break

            step += 1
            solved = is_solved(grid)[0]

        solved_flags[n] = solved

    return sequences, solved_flags


def load_and_solve_difficulty(
    diff: int,
    data_dir: str = "data/sudoku-extreme-processed",
    subsample: int | None = None,
) -> Tuple[List[List[Dict]], List[bool]]:
    """Load puzzles for a difficulty level and solve them."""

    inputs_path = os.path.join(data_dir, f"lvl-{diff}-inputs.npy")
    outputs_path = os.path.join(data_dir, f"lvl-{diff}-outputs.npy")

    if not os.path.exists(inputs_path):
        raise FileNotFoundError(f"No data for level {diff}")

    inputs = np.load(inputs_path)
    outputs = np.load(outputs_path)

    if subsample:
        inputs = inputs[:subsample]
        outputs = outputs[:subsample]

    if diff <= 2:
        max_tier = 1
    elif diff <= 5:
        max_tier = 2
    else:
        max_tier = 3

    return solve_batch(inputs, outputs, max_tier=max_tier)




================================================
FILE: engine/utils.py
================================================
from pathlib import Path
import os
import re
import random

import numpy as np

# Precompute houses
ROWS = [[(r, c) for c in range(9)] for r in range(9)]
COLS = [[(r, c) for r in range(9)] for c in range(9)]
BLOCKS = [
    [
        (r, c)
        for r in range(br * 3, br * 3 + 3)
        for c in range(bc * 3, bc * 3 + 3)
    ]
    for br in range(3)
    for bc in range(3)
]
HOUSES = ROWS + COLS + BLOCKS

# Peers for assignments
PEERS = [[set() for _ in range(9)] for _ in range(9)]
for r in range(9):
    for c in range(9):
        peers = set(ROWS[r] + COLS[c] + BLOCKS[(r // 3) * 3 + (c // 3)])
        peers.remove((r, c))
        PEERS[r][c] = peers


def digits_from_cand(cand_rc: np.ndarray) -> list[int]:
    """Return list of 1-based digits present in a candidate boolean slice."""
    return [d + 1 for d in range(9) if cand_rc[d]]


def candidate_mask_init(grids: np.ndarray) -> np.ndarray:
    """Compute boolean candidate masks for a batch of grids."""
    if grids.ndim == 2:
        grids = grids[None, ...]
    N = grids.shape[0]
    mask = np.ones((N, 9, 9, 9), dtype=bool)
    for n in range(N):
        grid = grids[n]
        for r in range(9):
            for c in range(9):
                val = int(grid[r, c])
                if val:
                    d = val - 1
                    mask[n, r, c, :] = False
                    mask[n, r, c, d] = True
                    mask[n, r, :, d] = False
                    mask[n, :, c, d] = False
                    br, bc = r // 3, c // 3
                    mask[n, br * 3 : br * 3 + 3, bc * 3 : bc * 3 + 3, d] = False
                    mask[n, r, c, d] = True
    return mask


def assign(grid: np.ndarray, mask: np.ndarray, r: int, c: int, d0idx: int) -> None:
    """Assign digit index ``d0idx`` (0-based) to cell ``(r, c)`` updating peers."""
    grid[r, c] = d0idx + 1
    mask[r, c, :] = False
    mask[r, c, d0idx] = True
    mask[r, :, d0idx] = False
    mask[:, c, d0idx] = False
    br, bc = r // 3, c // 3
    mask[br * 3 : br * 3 + 3, bc * 3 : bc * 3 + 3, d0idx] = False
    mask[r, c, d0idx] = True


def apply_deductions(
    grids: np.ndarray, mask: np.ndarray, all_deductions: list[list[dict]]
) -> int:
    """Apply recorded deductions to grids and masks in-place."""
    if grids.ndim == 2:
        grids = grids[None, ...]
        mask = mask[None, ...]
    changes = 0
    for n, deds in enumerate(all_deductions):
        for ded in deds:
            if "value" in ded and "position" in ded:
                r, c = ded["position"]
                d = ded["value"] - 1
                if grids[n, r, c] == 0:
                    assign(grids[n], mask[n], r, c, d)
                    changes += 1
            if "eliminations" in ded:
                for (r, c), vals in ded["eliminations"]:
                    for val in vals:
                        d = val - 1
                        if mask[n, r, c, d]:
                            mask[n, r, c, d] = False
                            changes += 1
    return changes


def is_solved(grids: np.ndarray) -> np.ndarray:
    """Check whether each puzzle in the batch is completely filled."""
    arr = grids if grids.ndim == 3 else grids[None, ...]
    return np.all(arr != 0, axis=(1, 2))


def is_valid(grids: np.ndarray) -> np.ndarray:
    """Validate each puzzle: no duplicates in rows, columns or boxes (ignoring zeros)."""
    N = grids.shape[0]
    valid = np.ones(N, dtype=bool)

    # Check rows
    for i in range(9):
        row_vals = grids[:, i, :]
        for n in range(N):
            if not valid[n]:
                continue
            non_zero = row_vals[n][row_vals[n] != 0]
            if len(non_zero) != len(np.unique(non_zero)):
                valid[n] = False

    # Check columns
    for j in range(9):
        col_vals = grids[:, :, j]
        for n in range(N):
            if not valid[n]:
                continue
            non_zero = col_vals[n][col_vals[n] != 0]
            if len(non_zero) != len(np.unique(non_zero)):
                valid[n] = False

    # Check boxes
    for br in range(3):
        for bc in range(3):
            subgrids = grids[:, br*3:(br+1)*3, bc*3:(bc+1)*3]
            for n in range(N):
                if not valid[n]:
                    continue
                flat = subgrids[n].flatten()
                non_zero = flat[flat != 0]
                if len(non_zero) != len(np.unique(non_zero)):
                    valid[n] = False

    return valid


def repo_root() -> Path:
    """Return the repository root directory."""
    return Path(__file__).resolve().parents[1]


def data_dir() -> Path:
    """Return the base data directory.

    Default location is ``repo_root()/"data"/"sudoku-extreme-processed"``.
    The ``SUDOKU_DATA_DIR`` environment variable can override it.
    """
    default = repo_root() / "data" / "sudoku-extreme-processed"
    return Path(os.environ.get("SUDOKU_DATA_DIR", default))


def available_levels() -> list[int]:
    """Discover available integer levels from the data layout."""
    base = data_dir()
    levels: set[int] = set()
    for p in base.glob("lvl-*-inputs.npy"):
        m = re.search(r"lvl-(\d+)-inputs\.npy", p.name)
        if m:
            levels.add(int(m.group(1)))
    return sorted(levels)


def is_valid_level(level: int) -> bool:
    """Return ``True`` if ``level`` is a non-negative integer and exists."""
    return level >= 0 and level in set(available_levels())


def random_level() -> int:
    """Return a random available level."""
    levels = available_levels()
    if not levels:
        raise RuntimeError("No levels available in data directory")
    return random.choice(levels)




================================================
FILE: modes/__init__.py
================================================
"""CLI modes for Sudoku puzzles."""



================================================
FILE: modes/breakdown_puzzles.py
================================================
"""Analyze all puzzle levels and generate a comprehensive report."""

from __future__ import annotations

import numpy as np
from pathlib import Path

from engine.utils import data_dir, is_valid_level


def _load_level(level: int) -> tuple[np.ndarray, np.ndarray]:
    """Load input and output arrays for the given level."""
    base = data_dir()
    inputs = np.load(base / f"lvl-{level}-inputs.npy")
    outputs = np.load(base / f"lvl-{level}-outputs.npy")
    return inputs, outputs


def _get_all_levels() -> list[int]:
    """Get all available level numbers from the data directory."""
    base = data_dir()
    level_files = [f for f in base.glob("lvl-*-inputs.npy")]
    levels = []
    
    for file_path in level_files:
        # Extract level number from filename like "lvl-42-inputs.npy"
        filename = file_path.stem  # "lvl-42-inputs"
        level_str = filename.split("-")[1]  # "42"
        try:
            level = int(level_str)
            levels.append(level)
        except ValueError:
            continue
    
    return sorted(levels)


def run() -> int:
    """Analyze all puzzle levels and generate a comprehensive report."""
    print("Analyzing all puzzle levels...")
    print("=" * 50)
    
    # Get all available levels
    all_levels = _get_all_levels()
    level_stats = {}
    
    # Process each level
    for level in all_levels:
        try:
            inputs, outputs = _load_level(level)
            num_puzzles = inputs.shape[0]
            level_stats[level] = num_puzzles
            print(f"Puzzles @ Level {level}: {num_puzzles}")
        except Exception as e:
            print(f"Error loading level {level}: {e}")
            continue
    
    # Calculate total puzzles
    total_puzzles = sum(level_stats.values())
    print(f"\nTotal Puzzles: {total_puzzles}")
    
    # Calculate percentages and prepare table
    print("\n" + "=" * 50)
    print("| Level | Puzzles | Percent |")
    print("|-------|---------|---------|")
    
    for level in sorted(level_stats.keys()):
        num_puzzles = level_stats[level]
        percentage = (num_puzzles / total_puzzles) * 100
        print(f"| {level:5d} | {num_puzzles:7d} | {percentage:6.1f}% |")
    
    print("=" * 50)
    
    return 0


if __name__ == "__main__":
    run()


================================================
FILE: modes/daily_puzzle.py
================================================
"""Daily puzzle mode."""

from __future__ import annotations

from datetime import date
import random
import numpy as np

from engine.solver import solve_batch
from engine.display import (
    print_program_header,
    print_puzzle_selection,
    print_initial_grid,
    print_step_header,
    display_sequence,
    print_final_output,
)
from engine.utils import data_dir, random_level, is_valid_level


def _load_level(level: int) -> tuple[np.ndarray, np.ndarray]:
    """Load input and output arrays for a level."""
    base = data_dir()
    inputs = np.load(base / f"lvl-{level}-inputs.npy")
    outputs = np.load(base / f"lvl-{level}-outputs.npy")
    return inputs, outputs


def run(level: int | None = None) -> int:
    """Run the daily puzzle solver.

    If ``level`` is provided and valid, select the daily puzzle from that
    level. Otherwise a random level is chosen.
    """
    lvl = level if (level is not None and is_valid_level(level)) else random_level()
    inputs, outputs = _load_level(lvl)
    num_puzzles = inputs.shape[0]

    today = date.today()
    rng = random.Random(today.toordinal())
    idx = rng.randint(0, num_puzzles - 1)

    selected_input = inputs[idx : idx + 1]
    selected_output = outputs[idx : idx + 1]

    print_program_header()
    print_puzzle_selection(lvl, num_puzzles, idx)
    print_initial_grid(selected_input[0])
    sequences, solved_flags = solve_batch(selected_input, selected_output)
    print_step_header()
    final_grid, steps, total_placements = display_sequence(
        selected_input[0], sequences[0]
    )
    print_final_output(final_grid, steps, total_placements, solved_flags[0])
    return 0



================================================
FILE: modes/level_puzzle.py
================================================
"""Run a random puzzle from a specific level."""

from __future__ import annotations

import random

import numpy as np

from engine.solver import solve_batch
from engine.display import (
    print_program_header,
    print_puzzle_selection,
    print_initial_grid,
    print_step_header,
    display_sequence,
    print_final_output,
)
from engine.utils import data_dir, is_valid_level


def _load_level(level: int) -> tuple[np.ndarray, np.ndarray]:
    """Load input and output arrays for the given level."""
    base = data_dir()
    inputs = np.load(base / f"lvl-{level}-inputs.npy")
    outputs = np.load(base / f"lvl-{level}-outputs.npy")
    return inputs, outputs


def run(level: int) -> int:
    """Solve and display a random puzzle from ``level``."""
    assert is_valid_level(level), f"invalid level: {level}"
    inputs, outputs = _load_level(level)
    num_puzzles = inputs.shape[0]
    idx = random.randint(0, num_puzzles - 1)

    selected_input = inputs[idx : idx + 1]
    selected_output = outputs[idx : idx + 1]

    print_program_header()
    print_puzzle_selection(level, num_puzzles, idx)
    print_initial_grid(selected_input[0])
    sequences, solved_flags = solve_batch(selected_input, selected_output)
    print_step_header()
    final_grid, steps, total_placements = display_sequence(
        selected_input[0], sequences[0]
    )
    print_final_output(final_grid, steps, total_placements, solved_flags[0])
    return 0



================================================
FILE: modes/list_puzzle.py
================================================
# SPDX-License-Identifier: MIT
"""Print puzzle list and solve command for a random level puzzle.

The formatted command is also copied to the clipboard if possible.
"""

from __future__ import annotations

import random
from pathlib import Path
import sys
import numpy as np

if __package__ is None:  # allow running as a script
    sys.path.append(str(Path(__file__).resolve().parents[1]))

from engine.utils import data_dir, is_valid_level


def _copy(text: str) -> None:
    """Best-effort copy ``text`` to the system clipboard."""
    try:
        import pyperclip  # type: ignore

        pyperclip.copy(text)
    except Exception:
        # Ignore all clipboard errors (missing dependency, no display, etc.)
        pass


def _load_level(level: int) -> np.ndarray:
    """Load input array for the given level."""
    base = data_dir()
    return np.load(base / f"lvl-{level}-inputs.npy")


def run(level: int) -> int:
    """Pick a random puzzle from ``level`` and print it."""
    assert is_valid_level(level), f"invalid level: {level}"
    inputs = _load_level(level)
    num_puzzles = inputs.shape[0]
    idx = random.randint(0, num_puzzles - 1)
    puzzle = inputs[idx]
    puzzle_list = puzzle.flatten().tolist()
    puzzle_str = "".join(str(n) if n else "." for n in puzzle_list)
    print(puzzle_list)
    solve_cmd = f'(solve "{puzzle_str}")'
    print(solve_cmd)
    _copy(solve_cmd)
    return 0


if __name__ == "__main__":  # pragma: no cover - convenience CLI
    import sys

    if len(sys.argv) != 2:
        print("Usage: list_puzzle.py LEVEL")
        raise SystemExit(1)
    raise SystemExit(run(int(sys.argv[1])))



================================================
FILE: modes/random_puzzle.py
================================================
"""Random puzzle mode."""

from __future__ import annotations

import random

import numpy as np

from engine.solver import solve_batch
from engine.display import (
    print_program_header,
    print_puzzle_selection,
    print_initial_grid,
    print_step_header,
    display_sequence,
    print_final_output,
)
from engine.utils import data_dir, is_valid_level, random_level


def _load_level(level: int) -> tuple[np.ndarray, np.ndarray]:
    """Load arrays for ``level``."""
    base = data_dir()
    inputs = np.load(base / f"lvl-{level}-inputs.npy")
    outputs = np.load(base / f"lvl-{level}-outputs.npy")
    return inputs, outputs


def run(level: int | None = None) -> int:
    """Solve a random puzzle.

    If ``level`` is ``None`` choose uniformly from all available levels,
    otherwise choose a random puzzle from the specified level.
    """
    lvl = level if (level is not None and is_valid_level(level)) else None
    if lvl is None:
        lvl = random_level()
    inputs, outputs = _load_level(lvl)
    num_puzzles = inputs.shape[0]
    idx = random.randint(0, num_puzzles - 1)

    selected_input = inputs[idx : idx + 1]
    selected_output = outputs[idx : idx + 1]

    print_program_header()
    print_puzzle_selection(lvl, num_puzzles, idx)
    print_initial_grid(selected_input[0])
    sequences, solved_flags = solve_batch(selected_input, selected_output)
    print_step_header()
    final_grid, steps, total_placements = display_sequence(
        selected_input[0], sequences[0]
    )
    print_final_output(final_grid, steps, total_placements, solved_flags[0])
    return 0



================================================
FILE: New/main.py
================================================


# build candidate tensor from initial grid 
    # for value in list if . then make index 0
    # if not 0 

def game_setup():
    """

    """

    # Imports initial 




def assert_value(C, G, r, c, n):
    """
    Assert a value n in cell (r, c) by updating the candidate mask C in-place.

    This function enforces the assignment of value n (0-based) to cell (r, c) in the Sudoku candidate
    mask C by:
      - Removing all other candidates from cell (r, c)
      - Removing n as a candidate value from all other cells in row r, column c, and the 3x3 box containing (r, c)
      - Setting C[r, c, n] = True to indicate n is the only candidate value for (r, c)

    Parameters
    ----------
    C : np.ndarray
        Boolean candidate mask of shape (9, 9, 9), where C[r, c, v] is True if value v (0-based) is a candidate for cell (r, c).
    r : int
        Row index of the cell (0-based).
    c : int
        Column index of the cell (0-based).
    n : int
        Value index to assign (0-based, i.e., 0 for 1, 1 for 2, ..., 8 for 9).

    Returns
    -------
    None
        The function modifies C in-place.
    """

    # Remove all candidate values from cell (r, c)
    C[r, c, :] = False

    # Remove value n as a candidate from all other cells in row r
    C[r, :, n] = False

    # Remove value n as a candidate from all other cells in column c
    C[:, c, n] = False

    # Remove value n as a candidate from all other cells in the 3x3 box containing (r, c)
    br, bc = r // 3, c // 3
    C[br*3:(br+1)*3, bc*3:(bc+1)*3, n] = False

    # Set value n as the only candidate for cell (r, c)
    C[r, c, n] = True


"""
init_background()
init_candidates_from_puzzle()

while true:
  if contradiction(): halt(NO_SOLUTION)
  if solved():       halt(SOLVED)

  fired := try_in_priority_order([
    ECP, Naked/Hidden Singles,
    Subsets (S2/S3/S4),
    Fish, Uniqueness (UR/BUG),
    Chains (Whips/Braids, typed/g-labels),
    Exotic patterns (Exocets, Tridagons, Templates), …
  ])

  if not fired:
    if T&E/DFS enabled: branch with new context and continue
    else halt(STUCK)

## The Four Elementary Constraint Propagation Rules

If a value is asserted for a cell:

1. **ECP Cell**: Eliminate all other candidates from that cell.
2. **ECP Row**: Eliminate the asserted value as a candidate from each of the row's remaining cells.
3. **ECP Column**: Eliminate the asserted value as a candidate from each of the column's remaining cells.
4. **ECP Block**: Eliminate the asserted value as a candidate from each of the block's remaining cells.

# Nine by Nine

Nine-by-Nine is a NumPy-accelerated Sudoku engine built to generate explainable, human-like reasoning traces and full step-by-step resolution paths for spatiotemporal reasoning datasets. 

The Nine-by-Nine engine models each Sudoku puzzle as a Constraint Satisfaction Problem with and uses two arrays to jointly capture a complete and consistent portrait of the puzzle for every intermediate step in the resolution process.

The first is a **solution grid** `G ∈ uint8^{9×9}` where `0` denotes an empty square and `1..9` are placed numbers, and the second is a **candidate tensor** `C ∈ bool^{9×9×9}`

ECP assertions with slices (no extra structures)

When you assert (r,c)=n (Naked/Hidden Single), eliminate that digit from the row/col/block and clear the cell’s other candidates—all with slices on C:

def assert_value(C, r, c, n):        # n = 0..8 for digit 1..9
    C[r, c, :] = False               # cell: other digits out
    C[r, :, n] = False               # row: remove n elsewhere
    C[:, c, n] = False               # column: remove n elsewhere
    br, bc = r//3, c//3
    C[br*3:(br+1)*3, bc*3:(bc+1)*3, n] = False   # block: remove n elsewhere
    C[r, c, n] = True                # keep the asserted one

"""

Change = {
  "action": "assert" | "eliminate" | "assume",
  "cell": (r, c),        # 0-based indices
  "value": int,          # 1..9
  "why": str | None      # optional note per change
}

# The Four Elementary Constraint Propagation Rules
def ECP(C, r, c, n):

    # 1. **ECP Cell**: Eliminate all other candidates from that cell.
    C[r, c, :] = False

    # 2. **ECP Row**: Eliminate the asserted value as a candidate from each of the row's remaining cells.
    C[r, :, n] = False

    # 3. **ECP Column**: Eliminate the asserted value as a candidate from each of the column's remaining cells.
    C[:, c, n] = False
    
    # 4. **ECP Block**: Eliminate the asserted value as a candidate from each of the block's remaining cells.
    C[br*3:(br+1)*3, bc*3:(bc+1)*3, n] = False



"""
Step 17 — Hidden Single
R1C5 = 8
∴ Row:  R1C1,R1C2,... ≠ 8
∴ Col:  R2C5,R3C5,... ≠ 8
∴ Block: R1C4,R2C4,... ≠ 8
∴ Cell:  R1C5 ≠ {1,2,3,4,6,7,9}

"""

"""
For Sudoku candidates, use a consistent 0-based flattening of the 3-D boolean tensor `C[r,c,d_idx]` (rows, cols, digit index 0..8) into a single index `idx = r*81 + c*9 + d_idx`. This gives you a stable ID in `[0,728]` for every candidate slot `(r,c,d)` (where `digit = d_idx + 1`), perfect for sparse deltas, multi-hot targets, and pointer heads. Decode with integer ops—`r = idx // 81`, `c = (idx % 81) // 9`, `d_idx = idx % 9`—or via `np.unravel_index(idx, (9,9,9))` (C-order). Keep a separate 2-D **cell index** `cell = r*9 + c` in `[0,80]` for value assignments; pair it with `digit` when needed. The only hard rule is **consistency**: pick one order (here `(r,c,d)`), use it everywhere (storage, logging, training), and document it next to your schema so deltas, masks, and witnesses stay aligned.
"""


================================================
FILE: New/notes.md
================================================
Awesome—let’s make a clean, repeatable “rule card” you can use for every rule, and then I’ll fill it out for **Hidden Single (Row)** using your exact data structures:

* a **9×9 `grid`** of ints in `{0..9}` where `0` = empty, `1..9` = placed digit
* a **9×9×9 `C`** boolean tensor where `C[r,c,n]` is `True` iff digit `(n+1)` is a candidate at `(r,c)`

---

# Rule Card — Template

**Rule Name (English):**
**Abbrev:**
**Purpose (1 line):**

**Set Notation:**
**Spoken English (symbol-faithful):**

**Scope (quantifiers → loops):**

* Variables and domains
* Data the rule reads (grid / candidates)

**Condition (IF):**

* Math statement (counts/uniqueness)
* NumPy “vectorized find” (what to compute)

**Action (THEN):**

* Math action (`value(...)`)
* NumPy apply (placement + ECP updates)

**Notes / Guards:**

* What makes an application “effective”?
* Edge cases / contradictions (CD)

---

# Rule Card — Hidden Single (Row)

**Rule Name (English):** Hidden Single (Row)
**Abbrev:** HS(R)
**Purpose:** Place a digit when, in a given row, that digit has exactly one possible column.

**Set Notation:**

$$
\forall r\,\forall n \;\{\, \exists!\, c\;\; candidate(n,r,c)\ \Rightarrow\ value(n,r,c) \,\}
$$

**Spoken English (symbol-faithful):**
For all rows $r$ and for all numbers $n$, if there exists **exactly one** column $c$ such that $candidate(n,r,c)$ is true, then assert $(r,c)=n$.

---

## Scope (quantifiers → loops)

* Variables: $r \in \{0..8\}$ (rows), $n \in \{0..8\}$ (index for digit $n+1$).
* Reads: `C[r, :, n]` (the candidate row-slice for digit $n+1$); optionally `grid[r,:]` to skip filled cells.

## Condition (IF)

**Math:** there exists **exactly one** $c$ with $candidate(n,r,c)=\text{True}$.

**NumPy “vectorized find”:**

```python
# C shape: (9,9,9); axis 1 = columns
rn_counts = C.sum(axis=1)                 # shape (9 rows, 9 numbers)
r_idx, n_idx = np.where(rn_counts == 1)   # all (r,n) pairs satisfying ∃! c
# recover the unique column for each (r,n)
c_idx = C[r_idx, :, n_idx].argmax(axis=1) # the (unique) c for each match
matches = list(zip(r_idx, c_idx, n_idx))  # [(r, c, n), ...] in row-major order
```

## Action (THEN)

**Math:** $value(n,r,c)$ — set cell $(r,c)$ to digit $n+1$ and propagate constraints.

**NumPy apply (placement + ECP):**

```python
def apply_HS_row(grid, C, r, c, n):
    # place value
    grid[r, c] = n + 1
    # ECP eliminations
    C[r, c, :] = False
    C[r, :, n] = False
    C[:, c, n] = False
    br, bc = r//3, c//3
    C[br*3:(br+1)*3, bc*3:(bc+1)*3, n] = False
    C[r, c, n] = True
```

**Driver (vectorized “find one, then restart”):**

```python
def HS_row_find_all(C):
    rn_counts = C.sum(axis=1)
    r_idx, n_idx = np.where(rn_counts == 1)
    if r_idx.size == 0:
        return []
    c_idx = C[r_idx, :, n_idx].argmax(axis=1)
    return list(zip(r_idx, c_idx, n_idx))

# in your precedence loop:
matches = HS_row_find_all(C)
if matches:
    r, c, n = matches[0]       # first match = “first rule that applies”
    apply_HS_row(grid, C, r, c, n)
    # then restart the rule list
```

## Notes / Guards

* **Effectiveness:** skip if `grid[r,c] != 0` (already placed), or if the action makes no change.
* **Consistency:** after placement, **CD** should never trigger; if some other state created a contradiction, you’ll detect it (some cell’s candidates become empty).
* **Index mapping:** store digits 1..9 at indices `n=0..8` (`digit = n+1`).

---

## (Mini) Cards you can clone next

### Naked Single (Cell) — NS

* **Set:** $\forall r\,\forall c \{\, \exists!\,n\ candidate(n,r,c) \Rightarrow value(n,r,c) \}$
* **Condition (NumPy):** `ns_mask = (C.sum(axis=2) == 1); r,c = np.where(ns_mask); n = C[r,c,:].argmax(1)`
* **Action:** place `(r,c)=n+1`, then ECP (same slice updates).

### Hidden Single (Column) — HS(C)

* **Set:** $\forall c\,\forall n \{\, \exists!\,r\ candidate(n,r,c) \Rightarrow value(n,r,c) \}$
* **Condition (NumPy):** `cn_counts = C.sum(axis=0); c,n = np.where(cn_counts==1); r = C[:,c,n].argmax(0)`

### Hidden Single (Block) — HS(B)

* **Set:** $\forall b\,\forall n \{\, \exists!\,s\ candidate_{bn}(n,b,s) \Rightarrow value_{bn}(n,b,s) \}$
* **Condition (NumPy):**

  ```python
  B = C.reshape(3,3, 3,3, 9)             # (BR,BC, rb,cb, n)
  bn_counts = B.sum(axis=(2,3))          # (3,3,9)
  BR, BC, n = np.where(bn_counts == 1)
  # find (rb,cb) inside each winning block:
  rbcb = [np.argwhere(B[br,bc,:,:,ni]).ravel() for br,bc,ni in zip(BR,BC,n)]
  rb, cb = np.array(rbcb).T
  r = BR*3 + rb;  c = BC*3 + cb
  ```
* **Action:** place `(r,c)=n+1`, then ECP.

### Row→Block Interaction — RiB (one eliminator example)

* **Set (plain):** if row $r$’s candidates for digit $n$ lie **inside one block** $b$, eliminate $n$ from $b \setminus r$.
* **Condition (NumPy idea):** for each `(r,n)`, compute the set of blocks hit by `np.where(C[r,:,n])`; condition is “hit count == 1”.
* **Action (NumPy):** zero out `C` in that block outside row `r` for digit `n`.

---

## Organization tips

* Keep **one markdown file per rule family** (Singles, Interactions, Subsets, Chains).
* For every rule, include the **Rule Card** sections above—copy/paste the template.
* Put tiny **NumPy test snippets** under each rule so you can unit-test “find” on synthetic boards.
* Add a **naming convention** note at top (index→digit mapping, what `0` means in `grid`).
* In your solver, implement each rule with two functions:

  * `find_all_matches_vectorized(C) -> list[(r,c,n)...]` (or eliminations)
  * `apply(grid, C, match)` (returns True if it changed state)

This gives you one place that documents **set notation, spoken English, and NumPy** for each rule, and it plugs directly into your vectorized “first match, then restart” driver.



================================================
FILE: notes/architecture.md
================================================
Here’s the architecture, top-down, with the “why” baked in.

Model (state):

grid\[9×9] holds placed digits (1..9, 0 for empty).

cand\[9×9×9] is a boolean tensor where cand\[r,c,n] means digit n+1 is possible at (r,c).
Why: this mirrors the set notation (C(x) ⊆ N) directly and lets us express constraints as vectorized boolean operations.

Houses & views:

Rows, columns, and 3×3 blocks are “houses.” Blocks are handled by reshaping/viewing cand into (3,3,3,3,9) and reducing on the right axes.
Why: house logic becomes axis reductions (sum/any/argmax) and masked assignments—clean, fast, NumPy-native.

Semantics (assign & propagate):

An assignment tensor A\[9×9×9] (one-hot per cell) encodes x←n. Applying A forces the chosen digit in that cell and clears it from all peers (row/col/block) via masked writes.
Why: separating “discover assignments” from “propagate effects” makes rules idempotent and composable.

Rule detectors (vectorized):

Naked single: cells where cand.sum(axis=2)==1.

Hidden single: for each house & digit, positions where the house-slice has exactly one True.

Cover (pointing/claiming): test if a digit’s Trues in an overlap are confined to one row/col; clear elsewhere by masks.

(Extend with subsets, fish, UR using small combinations on boolean slices.)
Why: each rule is a small, readable reduction + mask; results are assignments or eliminations.

Solve loop (fixpoint):

Alternate: detect → apply assignments → propagate → apply eliminations; repeat until no change.
Why: predictable convergence, easy to test, and performance comes from keeping all heavy work inside NumPy kernels.

Optional rn/cn/bn projections:

Project cand into (r,n)→cols, (c,n)→rows, (b,n)→square views for fish/uniqueness patterns.
Why: these are just rearrangements of the same tensor, matching the set-notation projections and enabling more rules without new data structures.

Goal & rationale: Make the code read like the math, showcase NumPy fluency (broadcasting, axis reductions, reshapes, masked assignment), and provide a clear, extensible baseline where adding rules is “write a reduction, apply a mask,” not “rewrite the representation.”



================================================
FILE: notes/Berthier.md
================================================
[Binary file]


================================================
FILE: notes/current_output.md
================================================
(.venv) jake@eve:~/Developer/sudoku-solver$ uv run main.py

====================================
Sudoku Solver v1.0
====================================

Puzzle Chosen:
- Difficulty Level: 0
- Puzzles @ Level : 614135
- Selected Puzzle : 455555

Initial Puzzle Grid:
┌───────┬───────┬───────┐
│ 8 3 7 │ . . 1 │ . . 6 │
│ 6 1 . │ . 7 . │ 9 . . │
│ . . . │ . . . │ 1 . . │
├───────┼───────┼───────┤
│ . . . │ . 4 3 │ . . . │
│ . . 2 │ . . . │ . 6 . │
│ . 7 . │ 6 . . │ 2 . 4 │
├───────┼───────┼───────┤
│ . . . │ . . . │ . 2 9 │
│ . . 5 │ 8 . . │ 6 . . │
│ . 9 . │ . . 4 │ 7 . 5 │
└───────┴───────┴───────┘

====================================
Step by Step Solution:
====================================

┌───────┬───────┬───────┐
│ 8 3 7 │ . . 1 │ . . 6 │
│ 6 1 4 │ . 7 . │ 9 . . │
│ . . . │ . . . │ 1 . . │
├───────┼───────┼───────┤
│ . . . │ 2 4 3 │ . . . │
│ . . 2 │ . . . │ . 6 . │
│ . 7 . │ 6 . . │ 2 . 4 │
├───────┼───────┼───────┤
│ . . . │ . . . │ . 2 9 │
│ . . 5 │ 8 . . │ 6 . . │
│ . 9 . │ . . 4 │ 7 . 5 │
└───────┴───────┴───────┘

T-1:  Δ +2
4 at B3 (Naked Single)
2 at D4 (Hidden Single - Row)

------------------------------------

┌───────┬───────┬───────┐
│ 8 3 7 │ . 2 1 │ . . 6 │
│ 6 1 4 │ . 7 . │ 9 . . │
│ . . 9 │ . . . │ 1 . . │
├───────┼───────┼───────┤
│ . . . │ 2 4 3 │ . . . │
│ . . 2 │ . . . │ . 6 . │
│ . 7 . │ 6 . . │ 2 . 4 │
├───────┼───────┼───────┤
│ . . . │ . . . │ . 2 9 │
│ . . 5 │ 8 . . │ 6 . . │
│ . 9 . │ . . 4 │ 7 . 5 │
└───────┴───────┴───────┘

T-2:  Δ +2
9 at C3 (Naked Single)
2 at A5 (Hidden Single - Row)

------------------------------------

┌───────┬───────┬───────┐
│ 8 3 7 │ 9 2 1 │ . . 6 │
│ 6 1 4 │ . 7 . │ 9 . 2 │
│ . . 9 │ . . . │ 1 . . │
├───────┼───────┼───────┤
│ . . . │ 2 4 3 │ . . . │
│ . . 2 │ . . . │ . 6 . │
│ . 7 . │ 6 . . │ 2 . 4 │
├───────┼───────┼───────┤
│ . . . │ . . . │ . 2 9 │
│ . . 5 │ 8 . 2 │ 6 . . │
│ 2 9 . │ . . 4 │ 7 . 5 │
└───────┴───────┴───────┘

T-3:  Δ +4
2 at H6 (Hidden Single - Col)
9 at A4 (Hidden Single - Row)
2 at B9 (Hidden Single - Row)
2 at I1 (Hidden Single - Row)

------------------------------------

┌───────┬───────┬───────┐
│ 8 3 7 │ 9 2 1 │ . . 6 │
│ 6 1 4 │ . 7 . │ 9 . 2 │
│ 5 2 9 │ 4 . . │ 1 . . │
├───────┼───────┼───────┤
│ . . . │ 2 4 3 │ . . . │
│ . . 2 │ . . . │ . 6 . │
│ . 7 . │ 6 . . │ 2 . 4 │
├───────┼───────┼───────┤
│ . . . │ . . . │ . 2 9 │
│ 7 4 5 │ 8 9 2 │ 6 . . │
│ 2 9 . │ . . 4 │ 7 . 5 │
└───────┴───────┴───────┘

T-4:  Δ +6
2 at C2 (Hidden Single - Col)
4 at C4 (Hidden Single - Col)
5 at C1 (Naked Single)
4 at H2 (Naked Single)
7 at H1 (Hidden Single - Row)
9 at H5 (Hidden Single - Row)

------------------------------------

┌───────┬───────┬───────┐
│ 8 3 7 │ 9 2 1 │ . 4 6 │
│ 6 1 4 │ . 7 . │ 9 . 2 │
│ 5 2 9 │ 4 . . │ 1 . . │
├───────┼───────┼───────┤
│ . . . │ 2 4 3 │ . . . │
│ 4 . 2 │ . . . │ . 6 . │
│ . 7 . │ 6 . . │ 2 . 4 │
├───────┼───────┼───────┤
│ . . . │ . . . │ 4 2 9 │
│ 7 4 5 │ 8 9 2 │ 6 . . │
│ 2 9 . │ . . 4 │ 7 . 5 │
└───────┴───────┴───────┘

T-5:  Δ +3
4 at E1 (Hidden Single - Col)
4 at A8 (Hidden Single - Col)
4 at G7 (Hidden Single - Row)

------------------------------------

┌───────┬───────┬───────┐
│ 8 3 7 │ 9 2 1 │ 5 4 6 │
│ 6 1 4 │ . 7 . │ 9 . 2 │
│ 5 2 9 │ 4 . . │ 1 . . │
├───────┼───────┼───────┤
│ . . . │ 2 4 3 │ . . . │
│ 4 . 2 │ . . 9 │ 3 6 . │
│ . 7 . │ 6 . . │ 2 . 4 │
├───────┼───────┼───────┤
│ . . . │ . . . │ 4 2 9 │
│ 7 4 5 │ 8 9 2 │ 6 . . │
│ 2 9 . │ . . 4 │ 7 8 5 │
└───────┴───────┴───────┘

T-6:  Δ +4
3 at E7 (Hidden Single - Col)
5 at A7 (Naked Single)
9 at E6 (Hidden Single - Row)
8 at I8 (Hidden Single - Box)

------------------------------------

┌───────┬───────┬───────┐
│ 8 3 7 │ 9 2 1 │ 5 4 6 │
│ 6 1 4 │ . 7 8 │ 9 3 2 │
│ 5 2 9 │ 4 . . │ 1 . 8 │
├───────┼───────┼───────┤
│ . . . │ 2 4 3 │ 8 . . │
│ 4 . 2 │ 7 . 9 │ 3 6 . │
│ . 7 . │ 6 . . │ 2 . 4 │
├───────┼───────┼───────┤
│ . . . │ . . 7 │ 4 2 9 │
│ 7 4 5 │ 8 9 2 │ 6 . . │
│ 2 9 . │ . . 4 │ 7 8 5 │
└───────┴───────┴───────┘

T-7:  Δ +6
7 at G6 (Hidden Single - Col)
8 at D7 (Hidden Single - Col)
3 at B8 (Naked Single)
8 at B6 (Hidden Single - Row)
8 at C9 (Hidden Single - Box)
7 at E4 (Hidden Single - Box)

------------------------------------

┌───────┬───────┬───────┐
│ 8 3 7 │ 9 2 1 │ 5 4 6 │
│ 6 1 4 │ 5 7 8 │ 9 3 2 │
│ 5 2 9 │ 4 3 6 │ 1 7 8 │
├───────┼───────┼───────┤
│ . . . │ 2 4 3 │ 8 . 7 │
│ 4 . 2 │ 7 . 9 │ 3 6 1 │
│ . 7 . │ 6 . 5 │ 2 . 4 │
├───────┼───────┼───────┤
│ . . . │ . . 7 │ 4 2 9 │
│ 7 4 5 │ 8 9 2 │ 6 1 3 │
│ 2 9 . │ . . 4 │ 7 8 5 │
└───────┴───────┴───────┘

T-8:  Δ +9
5 at F6 (Hidden Single - Col)
6 at C6 (Hidden Single - Col)
3 at H9 (Hidden Single - Col)
7 at D9 (Hidden Single - Col)
5 at B4 (Naked Single)
7 at C8 (Naked Single)
1 at E9 (Naked Single)
1 at H8 (Naked Single)
3 at C5 (Hidden Single - Row)

------------------------------------

┌───────┬───────┬───────┐
│ 8 3 7 │ 9 2 1 │ 5 4 6 │
│ 6 1 4 │ 5 7 8 │ 9 3 2 │
│ 5 2 9 │ 4 3 6 │ 1 7 8 │
├───────┼───────┼───────┤
│ . . . │ 2 4 3 │ 8 5 7 │
│ 4 5 2 │ 7 8 9 │ 3 6 1 │
│ . 7 . │ 6 1 5 │ 2 9 4 │
├───────┼───────┼───────┤
│ . . . │ . 5 7 │ 4 2 9 │
│ 7 4 5 │ 8 9 2 │ 6 1 3 │
│ 2 9 . │ . . 4 │ 7 8 5 │
└───────┴───────┴───────┘

T-9:  Δ +6
5 at G5 (Hidden Single - Col)
5 at D8 (Hidden Single - Col)
8 at E5 (Naked Single)
9 at F8 (Naked Single)
5 at E2 (Hidden Single - Row)
1 at F5 (Hidden Single - Box)

------------------------------------

┌───────┬───────┬───────┐
│ 8 3 7 │ 9 2 1 │ 5 4 6 │
│ 6 1 4 │ 5 7 8 │ 9 3 2 │
│ 5 2 9 │ 4 3 6 │ 1 7 8 │
├───────┼───────┼───────┤
│ 9 6 . │ 2 4 3 │ 8 5 7 │
│ 4 5 2 │ 7 8 9 │ 3 6 1 │
│ 3 7 8 │ 6 1 5 │ 2 9 4 │
├───────┼───────┼───────┤
│ . 8 . │ . 5 7 │ 4 2 9 │
│ 7 4 5 │ 8 9 2 │ 6 1 3 │
│ 2 9 . │ . 6 4 │ 7 8 5 │
└───────┴───────┴───────┘

T-10:  Δ +6
9 at D1 (Hidden Single - Col)
8 at G2 (Hidden Single - Col)
6 at I5 (Hidden Single - Col)
6 at D2 (Naked Single)
3 at F1 (Naked Single)
8 at F3 (Hidden Single - Row)

------------------------------------

┌───────┬───────┬───────┐
│ 8 3 7 │ 9 2 1 │ 5 4 6 │
│ 6 1 4 │ 5 7 8 │ 9 3 2 │
│ 5 2 9 │ 4 3 6 │ 1 7 8 │
├───────┼───────┼───────┤
│ 9 6 1 │ 2 4 3 │ 8 5 7 │
│ 4 5 2 │ 7 8 9 │ 3 6 1 │
│ 3 7 8 │ 6 1 5 │ 2 9 4 │
├───────┼───────┼───────┤
│ 1 8 6 │ . 5 7 │ 4 2 9 │
│ 7 4 5 │ 8 9 2 │ 6 1 3 │
│ 2 9 . │ . 6 4 │ 7 8 5 │
└───────┴───────┴───────┘

T-11:  Δ +3
1 at G1 (Hidden Single - Col)
6 at G3 (Hidden Single - Col)
1 at D3 (Naked Single)

------------------------------------

┌───────┬───────┬───────┐
│ 8 3 7 │ 9 2 1 │ 5 4 6 │
│ 6 1 4 │ 5 7 8 │ 9 3 2 │
│ 5 2 9 │ 4 3 6 │ 1 7 8 │
├───────┼───────┼───────┤
│ 9 6 1 │ 2 4 3 │ 8 5 7 │
│ 4 5 2 │ 7 8 9 │ 3 6 1 │
│ 3 7 8 │ 6 1 5 │ 2 9 4 │
├───────┼───────┼───────┤
│ 1 8 6 │ 3 5 7 │ 4 2 9 │
│ 7 4 5 │ 8 9 2 │ 6 1 3 │
│ 2 9 3 │ 1 6 4 │ 7 8 5 │
└───────┴───────┴───────┘

T-12:  Δ +3
3 at I3 (Hidden Single - Col)
1 at I4 (Hidden Single - Col)
3 at G4 (Naked Single)

====================================
Final Grid:
====================================

┌───────┬───────┬───────┐
│ 8 3 7 │ 9 2 1 │ 5 4 6 │
│ 6 1 4 │ 5 7 8 │ 9 3 2 │
│ 5 2 9 │ 4 3 6 │ 1 7 8 │
├───────┼───────┼───────┤
│ 9 6 1 │ 2 4 3 │ 8 5 7 │
│ 4 5 2 │ 7 8 9 │ 3 6 1 │
│ 3 7 8 │ 6 1 5 │ 2 9 4 │
├───────┼───────┼───────┤
│ 1 8 6 │ 3 5 7 │ 4 2 9 │
│ 7 4 5 │ 8 9 2 │ 6 1 3 │
│ 2 9 3 │ 1 6 4 │ 7 8 5 │
└───────┴───────┴───────┘

Puzzle Solved!
- Total Steps: 12
- Total Placements: 54

====================================




.
├── pyproject.toml
├── README.md
├── data/                     # runtime data (gitignored or small samples only)
├── utilities/
│   └── dataset_download.py
├── core/

│   ├── __init__.py
    ├── __main__.py       # enables: python -m sudoku9x9
│   ├── cli.py            # CLI entry (argparse/Typer)
│   ├── modes/
│       │   ├── daily.py
│       │   ├── random_mode.py
│       │   └── selection.py
│       ├── core/
│       │   ├── display.py
│       │   ├── solver.py
│       │   └── utils.py
│       └── strategies/
│           ├── __init__.py
│           ├── base.py       # previously strategy/strategies.py
│           ├── singles.py
│           ├── intersections.py
│           ├── subsets.py
│           ├── wings.py
│           ├── fish.py
│           └── chains.py
└── tests/



================================================
FILE: notes/desired_output.md
================================================
(.venv) jake@eve:~/Developer/sudoku-solver$ uv run main.py

====================================
Sudoku Solver v1.0
====================================

Puzzle Chosen:
- Difficulty Level: 0
- Puzzles @ Level : 614135
- Selected Puzzle : 455555

Initial Puzzle Grid:
┌───────┬───────┬───────┐
│ 8 3 7 │ . . 1 │ . . 6 │
│ 6 1 . │ . 7 . │ 9 . . │
│ . . . │ . . . │ 1 . . │
├───────┼───────┼───────┤
│ . . . │ . 4 3 │ . . . │
│ . . 2 │ . . . │ . 6 . │
│ . 7 . │ 6 . . │ 2 . 4 │
├───────┼───────┼───────┤
│ . . . │ . . . │ . 2 9 │
│ . . 5 │ 8 . . │ 6 . . │
│ . 9 . │ . . 4 │ 7 . 5 │
└───────┴───────┴───────┘

====================================
Step by Step Solution:
====================================

┌───────┬───────┬───────┐
│ 8 3 7 │ . . 1 │ . . 6 │
│ 6 1 4 │ . 7 . │ 9 . . │
│ . . . │ . . . │ 1 . . │
├───────┼───────┼───────┤
│ . . . │ 2 4 3 │ . . . │
│ . . 2 │ . . . │ . 6 . │
│ . 7 . │ 6 . . │ 2 . 4 │
├───────┼───────┼───────┤
│ . . . │ . . . │ . 2 9 │
│ . . 5 │ 8 . . │ 6 . . │
│ . 9 . │ . . 4 │ 7 . 5 │
└───────┴───────┴───────┘

T-1:  Δ +2
4 at B3 (Naked Single)
2 at D4 (Hidden Single - Row)

------------------------------------

┌───────┬───────┬───────┐
│ 8 3 7 │ . 2 1 │ . . 6 │
│ 6 1 4 │ . 7 . │ 9 . . │
│ . . 9 │ . . . │ 1 . . │
├───────┼───────┼───────┤
│ . . . │ 2 4 3 │ . . . │
│ . . 2 │ . . . │ . 6 . │
│ . 7 . │ 6 . . │ 2 . 4 │
├───────┼───────┼───────┤
│ . . . │ . . . │ . 2 9 │
│ . . 5 │ 8 . . │ 6 . . │
│ . 9 . │ . . 4 │ 7 . 5 │
└───────┴───────┴───────┘

T-2:  Δ +2
9 at C3 (Naked Single)
2 at A5 (Hidden Single - Row)

------------------------------------

┌───────┬───────┬───────┐
│ 8 3 7 │ 9 2 1 │ . . 6 │
│ 6 1 4 │ . 7 . │ 9 . 2 │
│ . . 9 │ . . . │ 1 . . │
├───────┼───────┼───────┤
│ . . . │ 2 4 3 │ . . . │
│ . . 2 │ . . . │ . 6 . │
│ . 7 . │ 6 . . │ 2 . 4 │
├───────┼───────┼───────┤
│ . . . │ . . . │ . 2 9 │
│ . . 5 │ 8 . 2 │ 6 . . │
│ 2 9 . │ . . 4 │ 7 . 5 │
└───────┴───────┴───────┘

T-3:  Δ +4
2 at H6 (Hidden Single - Col)
9 at A4 (Hidden Single - Row)
2 at B9 (Hidden Single - Row)
2 at I1 (Hidden Single - Row)

------------------------------------

┌───────┬───────┬───────┐
│ 8 3 7 │ 9 2 1 │ . . 6 │
│ 6 1 4 │ . 7 . │ 9 . 2 │
│ 5 2 9 │ 4 . . │ 1 . . │
├───────┼───────┼───────┤
│ . . . │ 2 4 3 │ . . . │
│ . . 2 │ . . . │ . 6 . │
│ . 7 . │ 6 . . │ 2 . 4 │
├───────┼───────┼───────┤
│ . . . │ . . . │ . 2 9 │
│ 7 4 5 │ 8 9 2 │ 6 . . │
│ 2 9 . │ . . 4 │ 7 . 5 │
└───────┴───────┴───────┘

T-4:  Δ +6
2 at C2 (Hidden Single - Col)
4 at C4 (Hidden Single - Col)
5 at C1 (Naked Single)
4 at H2 (Naked Single)
7 at H1 (Hidden Single - Row)
9 at H5 (Hidden Single - Row)

------------------------------------

┌───────┬───────┬───────┐
│ 8 3 7 │ 9 2 1 │ . 4 6 │
│ 6 1 4 │ . 7 . │ 9 . 2 │
│ 5 2 9 │ 4 . . │ 1 . . │
├───────┼───────┼───────┤
│ . . . │ 2 4 3 │ . . . │
│ 4 . 2 │ . . . │ . 6 . │
│ . 7 . │ 6 . . │ 2 . 4 │
├───────┼───────┼───────┤
│ . . . │ . . . │ 4 2 9 │
│ 7 4 5 │ 8 9 2 │ 6 . . │
│ 2 9 . │ . . 4 │ 7 . 5 │
└───────┴───────┴───────┘

T-5:  Δ +3
4 at E1 (Hidden Single - Col)
4 at A8 (Hidden Single - Col)
4 at G7 (Hidden Single - Row)

------------------------------------

┌───────┬───────┬───────┐
│ 8 3 7 │ 9 2 1 │ 5 4 6 │
│ 6 1 4 │ . 7 . │ 9 . 2 │
│ 5 2 9 │ 4 . . │ 1 . . │
├───────┼───────┼───────┤
│ . . . │ 2 4 3 │ . . . │
│ 4 . 2 │ . . 9 │ 3 6 . │
│ . 7 . │ 6 . . │ 2 . 4 │
├───────┼───────┼───────┤
│ . . . │ . . . │ 4 2 9 │
│ 7 4 5 │ 8 9 2 │ 6 . . │
│ 2 9 . │ . . 4 │ 7 8 5 │
└───────┴───────┴───────┘

T-6:  Δ +4
3 at E7 (Hidden Single - Col)
5 at A7 (Naked Single)
9 at E6 (Hidden Single - Row)
8 at I8 (Hidden Single - Box)

------------------------------------

┌───────┬───────┬───────┐
│ 8 3 7 │ 9 2 1 │ 5 4 6 │
│ 6 1 4 │ . 7 8 │ 9 3 2 │
│ 5 2 9 │ 4 . . │ 1 . 8 │
├───────┼───────┼───────┤
│ . . . │ 2 4 3 │ 8 . . │
│ 4 . 2 │ 7 . 9 │ 3 6 . │
│ . 7 . │ 6 . . │ 2 . 4 │
├───────┼───────┼───────┤
│ . . . │ . . 7 │ 4 2 9 │
│ 7 4 5 │ 8 9 2 │ 6 . . │
│ 2 9 . │ . . 4 │ 7 8 5 │
└───────┴───────┴───────┘

T-7:  Δ +6
7 at G6 (Hidden Single - Col)
8 at D7 (Hidden Single - Col)
3 at B8 (Naked Single)
8 at B6 (Hidden Single - Row)
8 at C9 (Hidden Single - Box)
7 at E4 (Hidden Single - Box)

------------------------------------

┌───────┬───────┬───────┐
│ 8 3 7 │ 9 2 1 │ 5 4 6 │
│ 6 1 4 │ 5 7 8 │ 9 3 2 │
│ 5 2 9 │ 4 3 6 │ 1 7 8 │
├───────┼───────┼───────┤
│ . . . │ 2 4 3 │ 8 . 7 │
│ 4 . 2 │ 7 . 9 │ 3 6 1 │
│ . 7 . │ 6 . 5 │ 2 . 4 │
├───────┼───────┼───────┤
│ . . . │ . . 7 │ 4 2 9 │
│ 7 4 5 │ 8 9 2 │ 6 1 3 │
│ 2 9 . │ . . 4 │ 7 8 5 │
└───────┴───────┴───────┘

T-8:  Δ +9
5 at F6 (Hidden Single - Col)
6 at C6 (Hidden Single - Col)
3 at H9 (Hidden Single - Col)
7 at D9 (Hidden Single - Col)
5 at B4 (Naked Single)
7 at C8 (Naked Single)
1 at E9 (Naked Single)
1 at H8 (Naked Single)
3 at C5 (Hidden Single - Row)

------------------------------------

┌───────┬───────┬───────┐
│ 8 3 7 │ 9 2 1 │ 5 4 6 │
│ 6 1 4 │ 5 7 8 │ 9 3 2 │
│ 5 2 9 │ 4 3 6 │ 1 7 8 │
├───────┼───────┼───────┤
│ . . . │ 2 4 3 │ 8 5 7 │
│ 4 5 2 │ 7 8 9 │ 3 6 1 │
│ . 7 . │ 6 1 5 │ 2 9 4 │
├───────┼───────┼───────┤
│ . . . │ . 5 7 │ 4 2 9 │
│ 7 4 5 │ 8 9 2 │ 6 1 3 │
│ 2 9 . │ . . 4 │ 7 8 5 │
└───────┴───────┴───────┘

T-9:  Δ +6
5 at G5 (Hidden Single - Col)
5 at D8 (Hidden Single - Col)
8 at E5 (Naked Single)
9 at F8 (Naked Single)
5 at E2 (Hidden Single - Row)
1 at F5 (Hidden Single - Box)

------------------------------------

┌───────┬───────┬───────┐
│ 8 3 7 │ 9 2 1 │ 5 4 6 │
│ 6 1 4 │ 5 7 8 │ 9 3 2 │
│ 5 2 9 │ 4 3 6 │ 1 7 8 │
├───────┼───────┼───────┤
│ 9 6 . │ 2 4 3 │ 8 5 7 │
│ 4 5 2 │ 7 8 9 │ 3 6 1 │
│ 3 7 8 │ 6 1 5 │ 2 9 4 │
├───────┼───────┼───────┤
│ . 8 . │ . 5 7 │ 4 2 9 │
│ 7 4 5 │ 8 9 2 │ 6 1 3 │
│ 2 9 . │ . 6 4 │ 7 8 5 │
└───────┴───────┴───────┘

T-10:  Δ +6
9 at D1 (Hidden Single - Col)
8 at G2 (Hidden Single - Col)
6 at I5 (Hidden Single - Col)
6 at D2 (Naked Single)
3 at F1 (Naked Single)
8 at F3 (Hidden Single - Row)

------------------------------------

┌───────┬───────┬───────┐
│ 8 3 7 │ 9 2 1 │ 5 4 6 │
│ 6 1 4 │ 5 7 8 │ 9 3 2 │
│ 5 2 9 │ 4 3 6 │ 1 7 8 │
├───────┼───────┼───────┤
│ 9 6 1 │ 2 4 3 │ 8 5 7 │
│ 4 5 2 │ 7 8 9 │ 3 6 1 │
│ 3 7 8 │ 6 1 5 │ 2 9 4 │
├───────┼───────┼───────┤
│ 1 8 6 │ . 5 7 │ 4 2 9 │
│ 7 4 5 │ 8 9 2 │ 6 1 3 │
│ 2 9 . │ . 6 4 │ 7 8 5 │
└───────┴───────┴───────┘

T-11:  Δ +3
1 at G1 (Hidden Single - Col)
6 at G3 (Hidden Single - Col)
1 at D3 (Naked Single)

------------------------------------

┌───────┬───────┬───────┐
│ 8 3 7 │ 9 2 1 │ 5 4 6 │
│ 6 1 4 │ 5 7 8 │ 9 3 2 │
│ 5 2 9 │ 4 3 6 │ 1 7 8 │
├───────┼───────┼───────┤
│ 9 6 1 │ 2 4 3 │ 8 5 7 │
│ 4 5 2 │ 7 8 9 │ 3 6 1 │
│ 3 7 8 │ 6 1 5 │ 2 9 4 │
├───────┼───────┼───────┤
│ 1 8 6 │ 3 5 7 │ 4 2 9 │
│ 7 4 5 │ 8 9 2 │ 6 1 3 │
│ 2 9 3 │ 1 6 4 │ 7 8 5 │
└───────┴───────┴───────┘

T-12:  Δ +3
3 at I3 (Hidden Single - Col)
1 at I4 (Hidden Single - Col)
3 at G4 (Naked Single)

====================================
Final Grid:
====================================

┌───────┬───────┬───────┐
│ 8 3 7 │ 9 2 1 │ 5 4 6 │
│ 6 1 4 │ 5 7 8 │ 9 3 2 │
│ 5 2 9 │ 4 3 6 │ 1 7 8 │
├───────┼───────┼───────┤
│ 9 6 1 │ 2 4 3 │ 8 5 7 │
│ 4 5 2 │ 7 8 9 │ 3 6 1 │
│ 3 7 8 │ 6 1 5 │ 2 9 4 │
├───────┼───────┼───────┤
│ 1 8 6 │ 3 5 7 │ 4 2 9 │
│ 7 4 5 │ 8 9 2 │ 6 1 3 │
│ 2 9 3 │ 1 6 4 │ 7 8 5 │
└───────┴───────┴───────┘

Puzzle Solved!
- Total Steps: 12
- Total Placements: 54

====================================




================================================
FILE: notes/grid.md
================================================
[Binary file]


================================================
FILE: notes/HRM.md
================================================
RoPE encodes a token’s 1-D index by applying **unit-circle rotations** to **pairs of embedding dimensions** (treating each consecutive pair as a complex number and multiplying by $e^{i\theta(m)}$ at frequency-scaled angles). Because these 2×2 rotations are orthogonal, they preserve the Euclidean norm and satisfy the absolute-to-relative identity $\langle R_m q,\; R_n k\rangle=\langle q,\; R_{n-m}k\rangle$; blockwise application across all pairs (with a multiscale frequency schedule) extends to higher-dimensional embeddings.&#x20;

MonSTERs mirror this structure in spacetime: they encode a token’s **4-D spacetime position** $s=(t,x,y,z)$ by applying **bivector-generated Lorentz rotors (boosts + spatial rotations)** to **blockwise 4-D subspaces** of the embedding (organized per-frequency triads for X/Y/Z). The rapidities/angles are linear in $s$ (scaled by per-frequency wavelengths), so the transform $L(s)$ is an isometry of the **Minkowski metric** $\mathrm{diag}(1,-1,-1,-1)$, preserving the Minkowski norm and yielding the RoPE-style fusion $\langle L(s_q)q,\; L(s_k)k\rangle_{\eta}=\langle q,\; L(s_k-s_q)k\rangle_{\eta}$. In short: RoPE uses **unit-circle rotations on pairs** to encode 1-D positions; MonSTERs use **Lorentz rotors on 4-D blocks** to encode 4-D spacetime—both achieving exact absolute-relative equivalence at multiple scales. &#x20;


---

# A practical playbook for learning *from* each other across big differences

Below is a field-tested style plan you could run with an alien species or an uncontacted culture—or just two people raised in totally different worlds. It pulls lessons from Daniel Everett’s work living with the Pirahã (in *Don’t Sleep, There Are Snakes*) and the film *Arrival* without getting academic. The aim: reach real communication fast so knowledge can flow both ways.

---

## Phase 0 — Safety and posture (hours–day 1)

1. **Visible non-threat**: Open hands, slow movements, no sudden advances. Keep physical distance they can control.
2. **Mirroring & consent**: Mirror simple postures, then stop; wait for them to mirror back. This tests willingness to engage.
3. **Trade a harmless loop**: Offer and accept a low-value item (food, tool, drawing). Reciprocity builds trust without words.
4. **Define stop signals**: Establish obvious “pause/stop” gestures. If you can’t reliably stop, nothing else matters.

**Everett lesson**: Respect the other group’s priorities and rhythm. Don’t force your agenda or timetable.

---

## Phase 1 — Bootstrapping signals (day 1–3)

5. **Ground everything in the here-and-now**: Point to a rock, hold it up, gesture “you?”/“me?”, then exchange it. Ostension (pointing/showing) beats abstract talk early.
6. **One board, two pens** (*Arrival* vibe): Create a shared surface for marks/signs. You write/draw what you *mean*, they do the same. Keep it visible to both.
7. **Establish yes/no/unknown**: Three distinct signals (e.g., nod/shake/hand flat). Practice on obvious truths (“Is this water?”).
8. **Name objects with pointing**: Point to an object; each side makes a sound/mark. Repeat thrice per item to fix association. Collect your first 30–50 “nouns.”

**Tip**: Don’t assume your categories (colors, numbers, kinship) exist for them. Let categories emerge.

---

## Phase 2 — Build a tiny lexicon & simple grammar (days 2–10)

9. **Cross-situational mapping**: Show the same object in different contexts to separate word from scene.
10. **Actions next**: Mime “give,” “come,” “eat,” “look.” Pair action with object (“eat fish”).
11. **Minimal pairs**: When two words sound close, use side-by-side tests to catch contrast (helps phoneme discovery).
12. **Pronouns & deixis**: Lock down “I/you/we/this/that/here/there/now/later” with gestures and placement.
13. **Negation & questions**: Teach a clear “not” gesture/marker and a question marker (tone, eyebrow, symbol).
14. **Numbers/time only if they care**: Some cultures don’t count like you expect (Everett). Don’t push it; follow their utility.
15. **Record a phrasebook**: A few dozen high-frequency patterns (greetings, barter, permission, warning).

**Arrival lesson**: Beware polysemy. “Tool” vs “weapon” confusion comes from assuming identical meanings. Test meanings in multiple contexts.

---

## Phase 3 — Mutual teaching loops (days 3–30)

16. **Teach-ask cycles**: For every thing you teach, ask them to teach you one. Keep the exchange symmetrical.
17. **Do tasks together**: Build a shelter, cook, repair a net. Language sticks best when tied to real joint projects.
18. **Picture stories**: Draw a 3–4 panel story; each side narrates using their system. Then swap stories and retell.
19. **Error as data**: When misunderstandings happen, freeze the moment, replay, and annotate your board with what *each* thought it meant.
20. **Prototype a pidgin**: A stripped-down shared code with the fewest moving parts (no fancy inflections) to get work done. It can evolve later.

---

## Phase 4 — Scale up knowledge exchange (weeks 2–8)

21. **Domains > dictionary**: Pick topics that matter to *them* (river, food, danger, kin, trade). Build vocab around those first.
22. **Terminology canvases**: For each domain, lay out a big sheet: items, actions, properties, outcomes. Fill it together.
23. **Demonstrable truths**: Prefer knowledge that can be shown or tested jointly (medicine works, boat floats). Shared evidence beats persuasion.
24. **Rituals & norms**: Ask (and watch) how they signal respect, ownership, taboo. Learn the “don’ts” early; it prevents rifts.
25. **Story exchanges**: Myths, histories, route maps. Draw timelines and maps; anchor stories in places and objects.

---

## Fast-track toolkit (things that work surprisingly well)

* **Ostensive dictionary**: Box of small objects; for each, both sides record name/gesture/mark.
* **Action cards**: Sketch verbs (give/run/cut). Combine with objects to form phrases.
* **Three-way confirmation**: gesture + spoken/marked token + result (“give fish” → actually give fish).
* **Repair phrases**: “Repeat,” “Slow,” “Different,” “Not that, this.”
* **Shadowing**: Repeat their utterance right after they do while pointing; they’ll correct you naturally.
* **Total Physical Response**: Hear/see command → do the action. It quickly validates comprehension.

---

## What to measure (so you know you’re actually learning)

* **Referential success**: Out of 20 point-and-name trials, how many are right first try? Aim for 80%+ within a week.
* **Core lexicon**: Count of high-frequency items you both can use in sentences (target \~200 by end of month one).
* **Turn-taking**: Average turns before a breakdown; want longer coherent stretches over time.
* **Task completion**: Can you complete joint tasks with only the shared code? (Yes/No and where it fails.)

---

## Common traps (and how to dodge them)

* **Category projection**: Forcing your concepts (numbers, colors, time) can stall progress. Let utility drive scope.
* **False friends**: Same sound/mark ≠ same meaning. Always test in fresh contexts.
* **Over-interpreting silence**: Could mean “thinking,” “polite no,” or “taboo”—not disinterest.
* **Speed over trust**: Pushing pace can backfire. Small, consistent wins beat big leaps.
* **One-way learning**: If only one side is sharing, you’ll hit resistance. Keep the exchange balanced.

---

## A 10-day starter plan (hour-by-hour sketch)

**Day 1–2**: Safety, trade loop, yes/no/unknown, 30 objects.
**Day 3**: 10 actions, combine with objects (“give fish,” “look fire”).
**Day 4–5**: Pronouns, here/there, now/later, negation; start repair phrases.
**Day 6**: Do a simple joint task using only shared code. Log every breakdown.
**Day 7**: Picture stories; build a 50-item domain canvas they care about (e.g., river life).
**Day 8**: Rituals/norms brief; learn greetings, permission, apology forms.
**Day 9**: Second joint task (harder). Add 30 new terms from the task.
**Day 10**: Review + compress into a pidgin phrasebook; set next domain (medicine, maps, tools).

---

## Core principles in one line each

* **Show before you say.**
* **Name what matters to them first.**
* **Let errors teach you.**
* **Build a tiny shared code, then refine.**
* **Make learning a two-way trade.**

That’s the shortest path to real communication—and to actually learning *from* each other, not just talking past one another.


I think I want to develop a paradigm called, "Relay Learning," that combines the classical AI expert systems approach with the scalable compute and statistical approaches that aren't tied to human expertise. In essence I want to paint the "bitter lesson" as a false paradigm. It's not an either/or. It's both. The models need to be able to learn for themselves through experience when there are not human experts available (disconnecting the chains that keep expert system models bound to their human contributors) and they also need to be able to learn from and also teach humans, so that when there is expertise around, the computer doesn't need to go through evolution for itself. That's the point of language after all, that someone can pass on verifiable knowledge so that I may benefit from their experience, verify for myself that it's true, and not have to reject tradition and wisdom. Additionally, what is the point of AI if it does not help us advance and learn more rapidly and more quickly. It takes gigantic super computers to mimic the flexibility and scale of a single human brain, if the AI can offload some of that compute to humans that's a big deal. And it won't be able to offload it if there's no reciprocity, no common substrate, no common canon. Think of it like we need to pass the baton back and forth, and there needs to be mechanisms to make that easy.

hmm, that's not quite it. The paradigm needs to be about not passing knowledge back and forth, but about building the tools, infrastructure, interaction set, and "substrate" that make communication between model and human easy.

In, "The Bitter Lesson," Sutton argues, "general methods that leverage computation are ultimately the most effective, and by a large margin."

He continues, "These two need not run counter to each other, but in practice they tend to. Time spent on one is time not spent on the other. There are psychological commitments to investment in one approach or the other. And the human-knowledge approach tends to complicate methods in ways that make them less suited to taking advantage of general methods leveraging computation."

He cites, "In computer chess, the methods that defeated the world champion, Kasparov, in 1997, were based on massive, deep search. At the time, this was looked upon with dismay by the majority of computer-chess researchers who had pursued methods that leveraged human understanding of the special structure of chess. When a simpler, search-based approach with special hardware and software proved vastly more effective, these human-knowledge-based chess researchers were not good losers. They said that ``brute force" search may have won this time, but it was not a general strategy, and anyway it was not how people played chess. These researchers wanted methods based on human input to win and were disappointed when they did not."

However, this ignores the immense amounts of expert knowledge brought in by the team behind deep blue. They essentially combined human expert systems, but then allowed the model to go on to augment them and learn additional methods as it became specialized.

Sutton analyzes the question, "Why did expert systems approaches who shunned brute force or statistical methods lose the race to superiority?" As human's we have a bias for survival, and against waste. This is why researchers are reluctant to launch in to big scale brute force or statistical approaches. A more insightful question Sutton might ask is, "Why have the greatest successes in Chess, Go, etc, that used brute force and search, failed to translate into wide adoption? What prevents such systems from being adapted to other uses?" He might also ask, "What about ChatGPT and the GPT architecture have given them such staying power, such broad general abilities and usefulness, and such broad adoption." ChatGPT is used by consumers, average joes, every day people. It is as useful to them as it is to researchers and scientists.

I want to argue that it is because it is a system well adapted to Relay Learning. It is able to absorb vast amounts of human expertise and systems thinking because of the one substrate that truly matters: time. The transformer, paired with temporal position encoding, enabled parallel computation of serial information. It gave the spinal column TIME to the model, to the AI to lay all of its knowledge upon it. Now according to the book, "Don't Sleep There Are Snakes," language arises from needs, needs created by our local environments and experiences. By giving ChatGPT a temporal environment, it was able to develop language very similar to ours, that also developed in a changing temporal environment. By modeling everything as next token prediction ChatGPT was given the greatest scaffold of all. Chess and Go are limited to their specific domains, the grid, of different sizes with different rules. Their highly specific goals and domain spaces have led to their long term inutility. 

Does that make sense? So we need to add more of that scaffolding so that the world that the model experiences more closely resembles that of our own. In this way it can learn from us more easily. And we can craft datasets to enable meta learning, language and knowledge transfer, etc.



you’re zeroing in on the real lever: build the substrate that makes human↔model communication cheap, precise, and scalable. not “hand the baton back and forth,” but make handing it off trivial—so general learning can keep compounding while expertise is injected or extracted with near-zero friction.

Think: “Don’t specialize the policy; specialize the interface.”

Why GPT “stuck” (and chess/go didn’t): time + a general substrate

Temporal substrate: Transformers make serial information parallelizable via attention + positional encodings (RoPE etc.). That gave models a time axis compatible with human language and storytelling (causal, stepwise, revisable).

Universal interface: Text is the lowest-friction API for expertise. Anyone can contribute examples, rules of thumb, counterexamples, and critiques—then the system scales these with compute.

Open-ended goals: Language tasks aren’t bounded like chess/go boards; they span many domains with shared tokens and shared temporal structure. That yields re-use and adoption.

Your MonSTERs idea (4D spacetime encoding) is a concrete way to extend that temporal substrate to spatial sets and procedures—exactly the right direction.




what other words could we use besides point? or how could we make it more clear? point and pointers are super overloaded I feel like?

point is about unambiguous reference
a pointer (a precise part of a state: one cell, a 3×3 box, a text span, a code block)
point(...) = mark a specific referent

Like ideally, in the case of Sudoku, there's each of the following sub spaces:

1. The Puzzle Grid (The Landscape)
2. The Candidate Tensor (The Remaining Options)
3. The Logic or Scratch Pad (Working Memory)
4. The Delta Log (List of Changes)
5. The Relay (Messaging Space or Console)

In addition there are each of the following pieces that can be "played" or "written" by the model to those spaces:

1. Values/Numbers {0-9} with 0 for empty.
2. Booleans {T, F} 
3. Landmarks {Rows, Columns, Boxes, Cells}
4. Symbols {∃, ≠, ?, <, ∵, ∀, ⇒, ¬, etc.}
5. Markers {Colors}




| Domain (Sutton)        | Breakthrough                                      | Compute-leveraged pieces                                                                  | Human-leveraged pieces (heuristics, supervision, evaluation)                                                                                                                                                                                                                                              | Brittleness / reuse today                                                                                                                                                             |
| ---------------------- | ------------------------------------------------- | ----------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Chess**              | IBM **Deep Blue** beats Kasparov (1997)           | Massive parallel alpha-beta search; specialized VLSI; hundreds of millions of nodes/sec   | Large **opening books** curated by GMs; **hand-engineered evaluation** with thousands of terms; **endgame tablebases**; parameters fine-tuned by experts. ([Wikipedia][1])                                                                                                                                | **Non-portable.** IBM dismantled Deep Blue; the two racks sit in museums (Smithsonian & Computer History Museum). It wasn’t repurposed for other tasks. ([Wikipedia][1])              |
| **Go**                 | **AlphaGo** → **AlphaGo Zero** (2016–2017)        | Huge self-play + MCTS search; large-scale training on TPUs/GPUs                           | First AlphaGo **pre-trained on human expert games** before RL; **rules, MCTS design, evaluation protocols** are human choices. (AlphaGo Zero removed human game data but still bakes in human-designed architecture & search.) ([ResearchGate][2], [Nature][3])                                           | **Narrow & retired.** AlphaGo was **retired from competition**; research moved on to AlphaZero. Great at board games, not a general scientist. ([Google DeepMind][4], [Science][5])   |
| **Speech recognition** | HMM era → **deep neural acoustic models** (2010s) | Scalable training on large speech corpora; deep LSTM/DNN models vastly reduce WER vs GMMs | Classic systems relied on **pronunciation lexicons** & **language models**; even modern systems depend on **human-labeled transcripts**, dictionaries, and human-chosen **WER** evaluation—plus well-documented **biases** across dialects. ([Google Research][6], [publications.idiap.ch][7], [PNAS][8]) | **Data brittleness.** Accuracy varies by accent/race and noise; models can underperform outside training distributions—expensive to fix without more targeted human data. ([PNAS][8]) |
| **Computer vision**    | **CNNs on ImageNet** (AlexNet, 2012)              | GPU training at scale; deep conv nets that keep improving with more compute/data          | **Massive human labeling (ImageNet)**; **architecture choices** (convolution, pooling) encode human inductive bias; evaluation via **Top-1/Top-5** designed by humans; known **dataset bias** issues. ([NeurIPS Proceedings][9], [image-net.org][10], [MIT CSAIL][11])                                    | **Generalization brittleness.** Cross-dataset performance drops; vulnerable to **adversarial examples**—strong but fragile. ([MIT CSAIL][11], [Google Research][12])                  |

[1]: https://en.wikipedia.org/wiki/Deep_Blue_%28chess_computer%29 "Deep Blue (chess computer) - Wikipedia"
[2]: https://www.researchgate.net/publication/292074166_Mastering_the_game_of_Go_with_deep_neural_networks_and_tree_search?utm_source=chatgpt.com "(PDF) Mastering the game of Go with deep neural networks ..."
[3]: https://www.nature.com/articles/nature24270?utm_source=chatgpt.com "Mastering the game of Go without human knowledge"
[4]: https://deepmind.google/discover/blog/alphagos-next-move/?utm_source=chatgpt.com "AlphaGo's next move"
[5]: https://www.science.org/doi/10.1126/science.aar6404?utm_source=chatgpt.com "A general reinforcement learning algorithm that masters ..."
[6]: https://research.google/pubs/deep-neural-networks-for-acoustic-modeling-in-speech-recognition/?utm_source=chatgpt.com "Deep Neural Networks for Acoustic Modeling in Speech ..."
[7]: https://publications.idiap.ch/downloads/papers/2012/Rasipuram_INTERSPEECH_2012.pdf?utm_source=chatgpt.com "Combining Acoustic Data Driven G2P and Letter-to-Sound ..."
[8]: https://www.pnas.org/doi/10.1073/pnas.1915768117?utm_source=chatgpt.com "Racial disparities in automated speech recognition"
[9]: https://proceedings.neurips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf?utm_source=chatgpt.com "ImageNet Classification with Deep Convolutional Neural ..."
[10]: https://www.image-net.org/static_files/papers/imagenet_cvpr09.pdf?utm_source=chatgpt.com "ImageNet: A Large-Scale Hierarchical Image Database"
[11]: https://people.csail.mit.edu/torralba/publications/datasets_cvpr11.pdf?utm_source=chatgpt.com "Unbiased Look at Dataset Bias - People | MIT CSAIL"
[12]: https://research.google.com/pubs/archive/42503.pdf?utm_source=chatgpt.com "Intriguing properties of neural networks"



Love it. If you want one main term, go with **compute-conductive** as the adjective. Then keep the noun forms around for metrics.

# Naming + style (use this in your README)

* **compute-conductive** *(adj.)* — an architecture/model that readily turns platform upgrades (GPUs, kernels, compilers, runtimes) into real speed/throughput **without changing the math**.

  > “Our AR solver is **compute-conductive**; CUDA 12 + FlashAttention gave a 1.5× speedup with no model changes.”

* **compute conductance (Gᶜ)** *(noun, metric)* — measured fraction of a platform win your model actually captures.

  $$
  \textbf{Tailwind Gain (TG)}=\frac{\text{throughput}_{\text{new}}}{\text{throughput}_{\text{old}}},\quad
  \mathbf{G^{c}}=\frac{\mathrm{TG}_{\text{model}}}{\mathrm{TG}_{\text{microbench}}}
  $$

* **compute conductivity (κᶜ)** *(noun, optional)* — architecture-level tendency to be compute-conductive across platforms (geometric mean of $G^{c}$ across upgrades).

### Tiny style guide

* Hyphenate when used before a noun: “**compute-conductive** design.”
* No hyphen in predicate is okay: “this model is compute conductive.”
* Avoid the adverb (“compute-conductively”)—it reads clunky.

# Drop-in blurb (definition + metrics)

> **Compute-conductive** models ride platform tailwinds with almost no code changes. We report **Tailwind Gain (TG)** and **compute conductance (Gᶜ)** for each release. Transformers typically show higher **κᶜ** than step-wise RNNs because attention parallelizes token work and maps to heavily optimized kernels.

# Example table you can reuse

| Build                     | TG (↑) | Microbench TG | **Gᶜ** (↑) |
| ------------------------- | -----: | ------------: | ---------: |
| AR Transformer (portable) |  1.52× |         1.86× |   **0.82** |
| LSTM (chunked)            |  1.18× |         1.86× |       0.63 |

# When to use the variants

* Use **compute-conductive** in prose (“is/are compute-conductive”).
* Use **Gᶜ** in perf sections/figures.
* Use **κᶜ** only in comparative architecture talks/papers.

If you want, I can weave these into a short “Performance & Tailwinds” section for your repo with a tiny benchmark script that prints TG and $G^{c}$.



1. Compute-Conductive
2. Expert-Independent

3. Knowledge-Conductive
4. Substrate-Elastic
5. Resilient-Adaptive
stable plastic

Time Spent Idle


================================================
FILE: notes/Levels.md
================================================
1. Parse input
2. For given in givens:
    - assert value
    - elementary constraint propagation
    - 

engine



# Nine by Nine

Nine-by-Nine is a NumPy-accelerated Sudoku engine built to generate explainable, human-like reasoning traces and full step-by-step resolution paths for spatiotemporal reasoning datasets. 

The Nine-by-Nine engine models each Sudoku puzzle as a Constraint Satisfaction Problem with and uses two arrays to jointly capture a complete and consistent portrait of the puzzle for every intermediate step in the resolution process.

The first is a **solution grid** `G ∈ uint8^{9×9}` where `0` denotes an empty square and `1..9` are placed numbers, and the second is a **candidate tensor** `C ∈ bool^{9×9×9}`




Given a 9x9 grid, partially filled with numbers from 1 to 9 (the "entries" of the
problem, also called the "clues" or the "givens"), complete it with numbers from 1 to
9 so that in every of the nine rows, in every of the nine columns and in every of the
nine disjoint blocks of 3x3 contiguous cells, the following property holds:
– there is at most one occurrence of each of these numbers.

Since rows, columns and blocks play similar roles in the defining constraints,
they will naturally appear to do so in many other places and it is convenient to intro-
duce a word that makes no difference between them: a unit is either a row or a
column or a block. And we say that two cells share a unit if they are either in the
same row or in the same column or in the same block (where "or" is non exclusive).
We also say that these two cells are linked, or that they see each other. It should be
noticed that this (symmetric) relation between two cells, whichever of the three
equivalent names it is given, does not depend in any way on the content of these
cells but only on their place in the grid; it is therefore a straightforward and quasi
physical notion.

The problem statement lists the constraints a solution grid must satisfy, i.e. it
says what we want. It does not say anything about how we can obtain it: this is the
job of the resolution methods and the resolution rules on which they are based.

at any stage of the resolution process, candidates
for a cell are the numbers that are not yet explicitly known to be impossible values
for this cell.

the resolution process is a sequence of steps consisting of repeatedly
applying "resolution rules" (some of which have become very classical and some of
which may be very complex) of the general condition-action type: if some pattern
(i.e. configuration) of cells, links, values and candidates for these cells is present on
the grid, then carry out the action specified by the rule.

According to the type of their action part, such rules can be classified into three
categories:
– either assert the final value of a cell (when it is proven there is only one possi-
bility left for it); there are very few rules of this type;
– or delete some candidate(s) (which we call the target values of the pattern)
from some cell(s) (which we call the target cells of the pattern); as appears from a
quick browsing of the available literature and as will be confirmed by this book,
most resolution rules are of this type; they express specific forms of constraints
propagation; their general form is: if such a pattern is present, then it is impossible
for some value(s) to be in some cell(s) and the corresponding candidates must be
deleted from them;
– or, for some very difficult grids, recursively make a hypothesis on the value of
a cell, analyse its consequences and apply the eliminations induced by the
contradictions thus discovered;

The four simpler constraints propagation rules (obviously valid) are the direct
translation of the initial problem formulation into operational rules for managing
candidates. We call them "the (four) elementary constraints propagation rules"
(ECP):
– ECP(cell): "if a value is asserted for a cell (as is the case for the initial values),
then remove all the other candidates for this cell";
– ECP(row): "if a value is asserted for a cell (as is the case for the initial values),
then remove this value from the candidates for any other cell in the same row";
– ECP(col): "if a value is asserted for a cell (as is the case for the initial values),
then remove this value from the candidates for any other cell in the same column";
– ECP(blk): "if a value is asserted for a cell (as is the case for the initial values),
then remove this value from the candidates for any other cell in the same block".
The simpler assertion rule (also obviously valid) is called Naked-Single:
– NS: "if a cell has only one candidate left, then assert it as the only possible
value of the cell".
Together with NS, the four elementary constraints propagation rules constitute
"the (five) elementary rules".

ok, we build a hierarchy of rules progressi-
vely, based on:
– a distinction between three general classes of rules: subset rules, interaction
rules and chain rules;
– a generalised notion of logical symmetry and associated representations;
– a second guiding principle: a rule obtained from another by some (generalised
or not) logical symmetry must be granted the same logical complexity.

Moreover, to every resolution method one can associate a simple systematic
procedure for solving a puzzle:
List the all the resolution rules in a way compatible with their precedence ordering
(i.e. among the different possibilities of doing so choose one)
Loop until a solution is found (or until it is proven there can be no solution)
⎢
Do until a rule applies effectively
⎢
⎢
Take the first rule not yet tried in the list
⎢
⎢
Do until its conditions pattern effectively maps to the grid
⎢
⎢
⎢
Try all possible mappings of the conditions pattern

Introduction
25
⎢
⎢
End do
⎢
End do
⎢
Apply rule on selected matching pattern
End loop






# Level 0: The Five Elementary Rules

## The Four Elementary Constraint Propagation Rules

If a value is asserted for a cell:

1. **ECP Cell**: Eliminate all other candidates from that cell.
2. **ECP Row**: Eliminate the asserted value as a candidate from each of the row's remaining cells.
3. **ECP Column**: Eliminate the asserted value as a candidate from each of the column's remaining cells.
4. **ECP Block**: Eliminate the asserted value as a candidate from each of the block's remaining cells.

## The Naked Single

∀r∀c {∃!n candidate(n, r, c) => value(n, r, c)}

If a cell has only one remaining candidate:

5. **NS**: Assert it as the cell's value.


# Level 1: Hidden Singles & House Interactions

– NS:∀r∀c {∃!n candidate(n, r, c) => value(n, r, c)}
– HS(row):∀r∀n {∃!c candidate(n, r, c) => value(n, r, c)}
For all rows r, and all numbers n, if there is exactly one column c in exists a single candidate for any cell 

“For every row r and every digit n: if there is exactly one column c in that row where n is allowed, put n in that one cell (r, c).”

– HS(col):∀c∀n {∃!r candidate(n, r, c) => value(n, r, c)}
– HS(blk):∀b∀n {∃!s candidate[n, b, s] => value[n, b, s]}

– HS(row): if, in abstract row-number space, there is a rn-cell (r, n) with only
one candidate (column), then assert it as the value of this rn-cell;
– HS(col): if, in abstract column-number space, there is a cn-cell (c, n) with only
one candidate (row), then assert it as the value of this cn-cell;
– HS(blk): if, in abstract block-number space, there is a bn-cell (b, n) with only
one candidate (square), then assert it as the value of this bn-cell.

import numpy as np

# C: (9, 9, 9) bool, C[r,c,n] True iff (r,c) allows digit n+1

# --- NS (Naked Single) in rc-space ---
ns_mask = (C.sum(axis=2) == 1)             # shape (9,9)
# To extract (r,c,n) triples:
r_ns, c_ns = np.where(ns_mask)
n_ns = C[r_ns, c_ns, :].argmax(axis=1)     # unique True along n-axis

# --- HS(row): “only one column for (r,n)” ---
# counts over columns for each (r,n)
rn_counts = C.sum(axis=1)                  # shape (9 rows, 9 numbers)
hsr_mask = (rn_counts == 1)
r_hsr, n_hsr = np.where(hsr_mask)
# the winning column for each (r,n)
c_hsr = C[r_hsr, :, n_hsr].argmax(axis=1)

# --- HS(col): “only one row for (c,n)” ---
# counts over rows for each (c,n)
cn_counts = C.sum(axis=0)                  # shape (9 cols, 9 numbers)
hsc_mask = (cn_counts == 1)
c_hsc, n_hsc = np.where(hsc_mask)
# the winning row for each (c,n)
r_hsc = C[:, c_hsc, n_hsc].argmax(axis=0)

# --- HS(block): “only one square for (b,n)” ---
# group rows/cols 3×3, then sum within each block
B = C.reshape(3,3, 3,3, 9)                 # (block_row, block_col, r_in_blk, c_in_blk, n) — view
bn_counts = B.sum(axis=(2,3))              # shape (3,3,9)
bn_counts = bn_counts.reshape(9,9)         # (block b=0..8, number n)
hsb_mask = (bn_counts == 1)
b_hsb, n_hsb = np.where(hsb_mask)

# recover the unique (r,c) inside each block for HS(block)
br, bc = np.divmod(b_hsb, 3)
# sub-block is a 3×3 view; find its True position
rb, cb = np.array([
    np.argwhere(B[BR, BC, :, :, n]).ravel()   # exactly one (rb,cb)
    for BR, BC, n in zip(br, bc, n_hsb)
]).T
r_hsb = br*3 + rb
c_hsb = bc*3 + cb

def assert_value(C, r, c, n):        # n = 0..8 for digit 1..9
    C[r, c, :] = False               # cell: other digits out
    C[r, :, n] = False               # row: remove n elsewhere
    C[:, c, n] = False               # column: remove n elsewhere
    br, bc = r//3, c//3
    C[br*3:(br+1)*3, bc*3:(bc+1)*3, n] = False   # block: remove n elsewhere
    C[r, c, n] = True                # keep the asserted one



================================================
FILE: notes/plan.md
================================================
# Status of Strategy Implementation

The solver now supports singles, subsets, basic intersection techniques, fish strategies (X-Wing and Swordfish), and wing strategies (XY-Wing and XYZ-Wing). The elimination handler has been implemented to support immediate candidate updates from advanced strategies. The chains.py file still contains only placeholder comments, meaning chain techniques (Coloring, Forcing Chain, and Nishio) are not yet implemented.

# Plan to Complete Remaining Strategies

## Implement remaining strategy family

- Chain strategies (chains.py): Implement Coloring, Forcing Chain, and Nishio to capture implication-based eliminations or forced fills. Use the existing elimination handler to propagate effects from these chain-based deductions.

## Integrate and register

- Ensure the newly implemented fish and wing strategies are added to `STRATEGY_FUNCTIONS` in `strategies/strategies.py`.
- Expand the default strategy list in `solver.py` to include fish and wing strategies now that they are stable.
- Once chain strategies are implemented, add them to `STRATEGY_FUNCTIONS` and the default strategy list as well.

## Testing & validation

- Create small puzzle sets or unit tests that specifically exercise the new fish and wing strategies, in addition to the existing ones.
- Develop tests for chain strategies once implemented.
- Confirm that eliminations and fills from all strategies (including the new ones) are correct, improve overall solver progress, and do not introduce conflicts.
- Validate that the elimination handler correctly propagates changes across strategies for more complex puzzles.

Following this updated roadmap will complete the solver’s planned strategy suite, enabling comprehensive human-style deduction sequences for even the hardest puzzles.





TODO:

1. Separate utility and display functions by creating new display.py file for our pretty print and other output functions.
2. Create helper functions for the headers and other print functionality in the main.py file and move them to display.py
3. Give main.py optional args to set the difficulty level to select from with default 0

1. Ensure that if there are no changes made to the grid even after escalating through all available tiers that the solve loop returns early and marks a boolean, solved = False. No need to run steps 8-100 if none of those steps will add new strategies we can use.
2. Update the puzzle solved display function so that it only says solved if we find a solution. It shouldn't by default print, "Puzzle Solved!"



T1  Receive Task [Sudoku]
T2  Inspect Task [Sudoku]
    Rows [9]
    Stacks [9]
    Board [ ┌───────┬───────┬───────┐
            │ 8 3 7 │ . . 1 │ . . 6 │
            │ 6 1 4 │ . 7 . │ 9 . . │
            │ . . . │ . . . │ 1 . . │
            ├───────┼───────┼───────┤
            │ . . . │ 2 4 3 │ . . . │
            │ . . 2 │ . . . │ . 6 . │
            │ . 7 . │ 6 . . │ 2 . 4 │
            ├───────┼───────┼───────┤
            │ . . . │ . . . │ . 2 9 │
            │ . . 5 │ 8 . . │ 6 . . │
            │ . 9 . │ . . 4 │ 7 . 5 │
            └───────┴───────┴───────┘ ] (Maybe this is just a list of the filled spaces with their values like address and value? idk)
T3  Make Lattice [
    9x9x9 all 1s
]
T4  Update Lattice [
    There's probably a better name for this?
]



================================================
FILE: notes/PLAN2.MD
================================================
Look at our BIG PICTURE PLAN HERE:

*WE WILL NOT IMPLEMENT ALL THE STEPS HERE TODAY - SEE END FOR DETAILS*

Status of Strategy Implementation
The solver currently supports only singles, subsets, and basic intersection techniques, as listed in the “Implemented Strategies” section of the README. Files for fish, wing, and chain techniques exist but contain only placeholder comments, meaning these methods are not yet implemented:

fish.py – intended for X-Wing and Swordfish

wings.py – intended for XY-Wing and XYZ-Wing

chains.py – intended for Coloring, Forcing Chain, and Nishio

Plan to Complete Remaining Strategies
Enable elimination handling

Extend utils.apply_deductions (and/or a candidate-management helper) so elimination-type deductions can update candidates immediately, allowing advanced strategies to propagate their effects.

Implement missing strategy families

Fish strategies (fish.py): X-Wing and Swordfish with a generic pattern-scanning helper.

Wing strategies (wings.py): XY-Wing and XYZ-Wing using bivalue/trivalue pivots to remove candidates.

Chain strategies (chains.py): Coloring, Forcing Chain, and Nishio to capture implication-based eliminations or forced fills.

Integrate and register

Add each new strategy function to STRATEGY_FUNCTIONS in strategies/strategies.py and expand the default strategy list in solver.py as they become stable.

Testing & validation

Create small puzzle sets or unit tests that exercise each strategy.

Confirm eliminations/fills are correct and improve overall solver progress without conflicts.

Following this roadmap will complete the solver’s planned strategy suite and enable more human-style deduction sequences across harder puzzles.

=========================================

Now look at the taxonomy here:

To make the code more modular and maintainable, yes, breaking it into multiple files is a good idea—especially as we add more strategies, which could make a single `human_strategies.py` file bloated and hard to navigate. Since your goal is to generate extended sequences of solving steps (mimicking human logic) for each puzzle in the dataset, organizing by strategy type or complexity will help keep related functions together and make it easier to extend (e.g., adding new strategies without touching unrelated code).

### Suggested File Names and Structure
Based on the taxonomy below, I recommend grouping strategies logically by their complexity and type of operation. This aligns with common Sudoku solver implementations, where simpler strategies (like singles) are applied first in the solver loop for efficiency, before escalating to more complex ones (like chains). Here's a breakdown:

- **singles.py**: For basic single-candidate strategies (Naked Single and Hidden Single). These are the simplest and most frequent, resulting in direct certainties (filling a cell).
- **subsets.py**: For pair/triplet/quad strategies (Naked Pair/Triplet/Quad and Hidden Pair/Triplet/Quad). These operate on small groups (2-4) of cells or candidates, often leading to eliminations.
- **intersections.py**: For Locked Candidates (also known as Pointing Pairs/Triples or Claiming). This focuses on intersections between units, leading to eliminations.
- **fish.py**: For grid-pattern strategies like X-Wing and Swordfish (extendable to Jellyfish if needed). These are column/row-based eliminations on larger patterns.
- **wings.py**: For hinge/chain starter strategies like XY-Wing and XYZ-Wing. These introduce simple chain logic for eliminations.
- **chains.py**: For advanced chain-based strategies (Coloring, Forcing Chain, Nishio). These are more complex, often involving graph-like traversals or trials, and can lead to either certainties or eliminations.

This gives us 6 files instead of 2, but they're small and focused—better for scalability. If you prefer just two files to start, we could do `basic_strategies.py` (singles + intersections + subsets) and `advanced_strategies.py` (fish + wings + chains), but the finer split will pay off as we implement more.

Each file would contain:
- The strategy functions (e.g., `find_naked_singles(candidates, all_deductions)`).
- Possibly sub-functions if needed (e.g., separate row/col/box handlers for hidden subsets).

Then, create a central `strategies.py` file that:
- Imports all the strategy functions from the above files.
- Maintains the `STRATEGY_FUNCTIONS` dictionary (mapping names to functions).
- Handles group expansions (e.g., `'hidden_single'` → row/col/box variants).
- Exports `find_deductions_batch` (which computes candidates once, then calls the requested strategies).

This way, your solver can import from `strategies.py` without knowing the internal file split.

### Outline of the Whole Repo
Here's how the repo could look and work together. The flow is: Download/process data → Load puzzles by difficulty → For each puzzle, run a solver loop that applies strategies step-by-step, recording each deduction/elimination as part of a "sequence" (e.g., a list of states or steps) → Save or analyze the sequences.

```
sudoku-solver-repo/
├── dataset_download.py     # Downloads CSVs from HF, processes into difficulty-bucketed .npy files (inputs/outputs as 9x9 arrays).
├── strategies/             # Directory for strategy modules (to keep root clean).
│   ├── __init__.py         # Empty, or exports all for easy imports.
│   ├── strategies.py       # Central hub: imports all functions, defines STRATEGY_FUNCTIONS dict, implements find_deductions_batch.
│   ├── singles.py          # Naked Single, Hidden Single (row/col/box).
│   ├── subsets.py          # Naked/Hidden Pairs/Triplets/Quads (row/col/box variants).
│   ├── intersections.py    # Locked Candidates (pointing and claiming).
│   ├── fish.py             # X-Wing, Swordfish.
│   ├── wings.py            # XY-Wing, XYZ-Wing.
│   └── chains.py           # Coloring, Forcing Chain, Nishio.
├── solver.py               # The core solver: Loads .npy files, for each puzzle: initialize grid, loop until solved/stuck: compute candidates → find deductions (via strategies.py) → apply fills/eliminations → record step (e.g., as a dict: {'step': i, 'grid_state': copy_of_grid, 'deductions': list_of_dicts}). Handles batching for efficiency. Outputs sequences as .npy or JSON per difficulty.
├── utils.py                # Helpers: Grid validation (is_valid_sudoku), pretty-print grid, apply_deduction (fill or eliminate on grid), maybe candidate computation if we extract it.
├── main.py                 # Entry point: Args for difficulty levels/subsample, calls dataset_download if needed, then solver, perhaps prints stats (e.g., avg steps per difficulty).
├── requirements.txt        # numpy, huggingface_hub, tqdm, etc.
├── data/                   # Generated: lvl-*-inputs.npy, lvl-*-outputs.npy, and later sequence files.
└── README.md               # Explains setup, how to run, and strategy taxonomy.
```

**How It Works Together**:
1. Run `dataset_download.py` (once): Fetches data, buckets by difficulty into `data/`.
2. In `main.py`: Parse args (e.g., difficulties to process), load inputs/outputs from .npy.
3. Call functions from `solver.py`: For a batch of puzzles (e.g., all level 5), initialize grids from inputs.
4. Solver loop per puzzle (or batched where possible):
   - While not solved and progress possible:
     - Call `find_deductions_batch` from `strategies.py` with desired strategies (e.g., start with basics, escalate if stuck).
     - Apply deductions: Fill certainties first, then eliminations. Update grid.
     - Record the step: Current grid snapshot + list of deductions applied.
   - Validate against output (solution) if needed.
   - Collect sequences (lists of steps) for ML dataset generation.
5. Save sequences (e.g., per difficulty as .npy: array of [puzzle_id, step_id, grid_flat, deductions_json]).

This structure supports your "extended sequence" goal: Each sequence is a chain of states from initial grid to solved, with human-like steps annotated by strategy type.

### Taxonomy of Strategies
Sudoku strategies can be classified in a few ways, but no single taxonomy is perfect—they overlap. I'll break them down by:
- **Action Type**: Does it result in a *certainty* (definite fill of a cell) or an *operation on unknowns* (eliminate candidates, reducing possibilities without filling)?
- **Complexity/Size**: Based on the number of cells/candidates involved (single=1, double/pair=2, triple=3, quad=4, or more for chains).
- **Scope**: Unit-based (row/col/box), intersection (between units), pattern/grid-wide, or chain/trial (implications across the grid).
- **Notes**: Brief description, why it's "human-like," and typical order in solvers (simpler first to avoid unnecessary complexity).

| Strategy              | Action Type          | Complexity/Size | Scope              | Notes |
|-----------------------|----------------------|-----------------|--------------------|-------|
| **Naked Single**     | Certainty (fill cell) | Single (1 candidate in cell) | Cell-only | Simplest: Cell has only 1 possible candidate left after basic eliminations. Applied first in most solvers. |
| **Hidden Single**    | Certainty (fill cell) | Single (1 cell for a candidate in unit) | Unit (row/col/box) | Candidate appears in only 1 cell in a unit; fill it. Similar to naked but "hidden" among other candidates. |
| **Locked Candidates** | Operation on unknowns (eliminate candidates) | Pair/Triple (2-3 cells in intersection) | Intersection (box-row/col) | Candidate locked to a box-line intersection; eliminate from rest of line or box. AKA Pointing (box→line) or Claiming (line→box). |
| **Naked Pair/Triplet/Quad** | Operation on unknowns (eliminate candidates) | Pair (2), Triple (3), Quad (4) cells/candidates | Unit (row/col/box) | Group of cells in unit with exactly those candidates; eliminate them from other cells in unit. |
| **Hidden Pair/Triplet/Quad** | Operation on unknowns (eliminate candidates) | Pair (2), Triple (3), Quad (4) candidates/cells | Unit (row/col/box) | Group of candidates appear only in those cells in unit; eliminate other candidates from those cells. Inverse of naked subsets. |
| **XY-Wing**          | Operation on unknowns (eliminate candidates) | Triple (3 cells in chain) | Chain (bivalue cells connected) | Pivot cell (XY) linked to two wings (XZ, YZ); eliminates Z where wings "see" it. Simple chain strategy. |
| **XYZ-Wing**         | Operation on unknowns (eliminate candidates) | Triple (3 cells, pivot has 3 candidates) | Chain (trivalue pivot + bivalue wings) | Extension of XY-Wing; pivot (XYZ) + wings (XZ, YZ); eliminates Z in common peer cells. |
| **X-Wing**           | Operation on unknowns (eliminate candidates) | Quad (4 cells in rectangle) | Grid-wide (2 rows + 2 cols) | Candidate in 2 rows only at 2 cols each, forming rectangle; eliminate from those cols elsewhere. Basic "fish" pattern. |
| **Swordfish**        | Operation on unknowns (eliminate candidates) | 9 cells (3x3 grid) | Grid-wide (3 rows + 3 cols) | Like X-Wing but for 3 rows/cols; eliminates in aligned cols/rows. Advanced fish. |
| **Coloring**         | Operation on unknowns (eliminate) or certainty (if contradiction) | Variable (chain length) | Chain (candidate graph) | Treat candidates as graph nodes, color chains; if same color sees each other, eliminate. Handles complex implications. |
| **Forcing Chain**    | Operation on unknowns (eliminate) or certainty (fill if all paths lead to same) | Variable (chain length) | Chain (implications across grid) | Follow "if A then B then C" chains; if contradiction or forced value, act. Can be short (nice loops) or long. |
| **Nishio**           | Operation on unknowns (eliminate via trial) | Variable (assumption + chain) | Trial/chain (assume candidate true/false) | Assume a candidate is true, propagate; if contradiction, eliminate it. Lightweight backtracking/trial-and-error. |

**Overall Patterns**:
- **Certainty vs. Unknowns**: Singles always fill (certainty). Most others eliminate (reducing unknowns), which may indirectly create new singles. Chains/trials can do both.
- **Single/Double/Triple**: Singles are "single," subsets scale to quad, wings/fish are fixed-size patterns (triple/quad+), chains are variable (often >3).
- **Human-Like Progression**: Humans start with singles (obvious fills), then subsets/intersections (local patterns), then fish/wings (grid scans), and chains/trials last (deductive reasoning). Your solver should apply in this order to generate natural sequences.
- **Implementation Tip**: All rely on candidates array. Simpler ones (singles/subsets) are unit-based and fast; chains are slower (graph traversal), so apply sparingly.

==================================================

And looking at this discussion with an AI about fish strategies here:

### Understanding Fish Strategies in Sudoku

Fish strategies are a family of advanced Sudoku solving techniques that focus on eliminating candidates based on patterns formed across multiple rows and columns (or vice versa). They are called "fish" because the patterns resemble fish shapes when diagrammed, with "fins" or extensions sometimes added in more complex variants. These strategies are particularly useful for medium to hard puzzles where simpler techniques like singles, subsets, or intersections don't make further progress.

At their core, fish strategies exploit alignments of candidates in a grid-wide manner. They operate on **candidates** (the possible numbers that could go in unsolved cells) and result in **eliminations** (removing candidates from cells), which can indirectly lead to fills via naked singles or other follow-on deductions. They don't directly fill cells but reduce possibilities.

Fish strategies are parameterized by size:
- **X-Wing**: The smallest and most common, for size 2 (like a 2x2 rectangle).
- **Swordfish**: For size 3 (a 3x3 pattern).
- Higher-order ones like Jellyfish (size 4) exist but are rarer and more computationally intensive; your solver plan focuses on X-Wing and Swordfish, which cover most cases.

These can be applied in two orientations:
- **Row-based**: Looking at candidates in rows that align to specific columns.
- **Column-based**: The symmetric case, swapping rows and columns.

I'll explain each in detail, starting with the general principle, then specifics for X-Wing and Swordfish. Since your context is implementing this in `fish.py`, I'll include implementation notes tied to a typical Sudoku solver setup (e.g., using a 9x9 grid and a candidates structure like a list of sets per cell).

#### General Principle of Fish Strategies
For a candidate number **k** (1-9):
1. **Scan for limited occurrences**: Identify a set of **n** rows where **k** appears as a candidate in exactly **n** columns across those rows (and no more).
2. **Check alignment**: Those occurrences must be confined to the same **n** columns. In other words, in those n rows, **k** only shows up in those n columns, forming a "base" pattern.
3. **Eliminate elsewhere**: Because **k** is "locked" to those n columns in the n rows, it means that in those n columns, **k** **cannot** appear in the other (9-n) rows—otherwise, it would violate Sudoku rules (no duplicates in columns). Thus, eliminate **k** from any cells in those n columns that are outside the n base rows.
4. **Symmetry**: Repeat the process swapping rows and columns (column-based fish).

This is efficient because it scans the entire grid but focuses on one candidate at a time. "Fins" can extend this (e.g., extra candidates outside the base that don't break the pattern but allow more eliminations), but basic implementations start without them.

Key benefits:
- Human-like: Solvers (and humans) spot these by scanning rows/columns for patterns, often after marking candidates.
- Efficiency: In code, it's O(1) per candidate (since grid is fixed 9x9), but you compute candidates first.

#### X-Wing: Detailed Explanation
X-Wing is the size-2 fish, named for the "X" shape formed by the four cells (like the wings of an X-wing fighter).

**How it Works (Step-by-Step)**:
1. **Select a candidate k**: Loop over each possible k (1-9).
2. **Build row candidate positions**: For each row (0-8), collect the list of columns where k is a candidate (i.e., unsolved cells in that row where k is possible).
3. **Find base rows**: Look for exactly two rows where the candidate positions for k are **exactly the same two columns**. For example:
   - Row 1: k possible only in columns 3 and 7.
   - Row 5: k possible only in columns 3 and 7.
   These two rows form the "base," and columns 3 and 7 are the "cover."
4. **Validate no extras**: Ensure that in these base rows, k doesn't appear elsewhere (already checked by the "exactly two" positions).
5. **Eliminate**: In columns 3 and 7, remove k from all other rows (except rows 1 and 5). Why? Because if k were in, say, row 2 column 3, then:
   - Row 1's k must go in column 7 (since column 3 is taken).
   - Row 5's k must go in column 3 or 7, but this creates conflicts in the columns.
   Essentially, the pattern forces k to be placed in the four cells (row1-col3, row1-col7, row5-col3, row5-col7) like a rectangle, and Sudoku forbids k duplicates in columns, so no other k in those columns.
6. **Check boxes**: Importantly, these positions shouldn't all be in the same box (subgrid), as that might be handled by simpler techniques, but X-Wing works across boxes.
7. **Column-based variant**: Repeat by transposing: Find two columns where k is only in the same two rows, then eliminate k from those rows in other columns.

**Example**:
Imagine a grid where candidate 5 is possible in:
- Row 2: Columns 1 and 4.
- Row 7: Columns 1 and 4.
- And elsewhere in columns 1 and 4, but not in rows 2 or 7.

This is an X-Wing on rows 2/7, columns 1/4. Eliminate 5 from all other cells in columns 1 and 4 (e.g., row 0 col 1, row 3 col 4, etc.).

**Visual**:
```
Columns: 1   4
Row 2:   [5] [5]
Row 7:   [5] [5]
```
The "X" connects the diagonals, implying eliminations vertically.

**Implementation Notes for `fish.py`**:
- Use a candidates structure: e.g., `candidates[row][col]` = set of possible numbers (or a 9x9x9 boolean array for speed).
- Function signature: `find_x_wing(candidates: list[list[set]]) -> list[dict]`, where each dict is a deduction like `{'type': 'eliminate', 'candidate': k, 'row': r, 'col': c}`.
- Steps in code:
  - For k in 1..9:
    - row_positions = [[] for _ in range(9)]  # list of cols where k is candidate in each row
    - For r in 0..8:
      for c in 0..8:
        if unsolved(r,c) and k in candidates[r][c]:
          row_positions[r].append(c)
    - Now, find pairs of rows where len(row_positions[r1]) == 2, len(row_positions[r2]) == 2, and set(row_positions[r1]) == set(row_positions[r2]).
    - For each such pair (r1, r2), cols = row_positions[r1]
    - For each col in cols:
      for other_r not in [r1, r2]:
        if k in candidates[other_r][col]:
          add deduction: eliminate k from (other_r, col)
- Do the same for column-based (transpose the logic: col_positions = [[] for _ in range(9)], etc.).
- Edge cases: Ignore if positions are in same box, or if no eliminations possible. Also, ensure the two rows aren't the same.
- Integrate: In `strategies.py`, add to STRATEGY_FUNCTIONS, call in solver loop after simpler strategies.

This should be straightforward and fast; test on puzzles where X-Wing is needed (e.g., from your dataset's medium levels).

#### Swordfish: Detailed Explanation
Swordfish is the size-3 fish, extending X-Wing to three rows and three columns. It's rarer but powerful for harder puzzles.

**How it Works (Step-by-Step)**:
1. **Select a candidate k**: Same as above.
2. **Build row candidate positions**: For each row, list columns where k is a candidate, but now look for rows where k appears in **at most 3 columns** (ideally exactly 3, but allowing 2 for "degenerate" cases).
3. **Find base rows**: Identify a combination of three rows where the **union** of their candidate columns for k has **exactly 3 columns**, and each row has k in at least two of those columns (to ensure coverage). More precisely:
   - The total unique columns across the three rows <= 3.
   - But each of the three columns must be "covered" by at least two rows (though basic Swordfish requires exact alignment).
   Standard definition: Find three rows where k appears only in the same three columns (each row has k in up to those three cols).
4. **Eliminate**: In those three columns, remove k from all rows outside the three base rows. The logic is analogous: The pattern forces k's placements in those columns to be confined to the base rows, preventing duplicates.
5. **Column-based**: Symmetric, find three columns with k only in the same three rows, eliminate from other columns in those rows.

**Example**:
Suppose candidate 4 in:
- Row 0: Columns 2, 5
- Row 3: Columns 2, 5, 8
- Row 6: Columns 5, 8
The union is columns 2,5,8 (exactly 3), and occurrences are within them. This is a Swordfish; eliminate 4 from other rows in columns 2,5,8.

**Visual**:
```
Columns: 2   5   8
Row 0:   [4] [4] 
Row 3:   [4] [4] [4]
Row 6:        [4] [4]
```
The "fish" shape connects the positions; eliminations are vertical in those columns.

**Implementation Notes for `fish.py`**:
- Similar to X-Wing, but generalize to n=3.
- For better modularity, write a generic `find_fish(candidates, n=2 or 3)`:
  - Use combinations from itertools: for base_rows in combinations(range(9), n):
    - Collect union_cols = set()
    - For r in base_rows:
      cols_for_r = [c for c in range(9) if k in candidates[r][c]]
      if len(cols_for_r) > n: skip
      union_cols.update(cols_for_r)
    - If len(union_cols) == n:
      - Check coverage: For each col in union_cols, count how many base_rows have k in that col; should be at least 2 (for strong links).
      - If valid, eliminate k from other_rows in union_cols where present.
- This handles both X-Wing (n=2) and Swordfish (n=3) in one function.
- Optimizations: Skip if union_cols > n early. For n=3, it's more combinatorial (C(9,3)=84), but still fast.
- Testing: Use puzzles requiring Swordfish; validate no false eliminations (e.g., run is_valid_sudoku after).

#### Generic Pattern-Scanning Helper
As per your plan, add a helper in `fish.py` for scanning: e.g., `scan_for_fish(candidates, k, n, is_row_based=True)` that returns potential bases and covers. This makes it extensible (e.g., to Jellyfish n=4 later).

#### Integration into Solver
- In `solver.py`: After computing candidates, call `find_fish_deductions` in the strategy loop, after intersections/subsets.
- Update `utils.apply_deductions`: Ensure it handles eliminations by removing from candidates and checking for new singles.
- Record steps: Each elimination batch as a step dict with strategy='fish', subtype='x-wing' or 'swordfish', affected cells.
- Testing: Create unit tests with minimal grids (e.g., almost solved but with one fish pattern), confirm eliminations lead to progress without conflicts.

This should complete your fish implementation, enabling the solver to tackle harder puzzles with human-like pattern recognition. If you need code snippets or examples from your dataset, let me know!

======================================================

MAIN INSTRUCTIONS HERE:

ENABLE ELIMINATION HANDLING

Extend utils.apply_deductions (and/or a candidate-management helper) so elimination-type deductions can update candidates immediately, allowing advanced strategies to propagate their effects.

IMPLEMENT FISH STRATEGIES

Fish strategies (fish.py): X-Wing and Swordfish with a generic pattern-scanning helper.

KEY DETAILS

THE NEW IMPLEMENTATIONS MUST MATCH OR UPDATE CURRENT API SO THAT OPERATIONS CAN REMAIN HIGH SPEED VECTORIZED. HERE IS A POSSIBLE METHOD:

You are an expert Python developer specializing in vectorized NumPy implementations for batch processing, particularly for Sudoku solvers. Your task is to implement the fish strategies (X-Wing and Swordfish) in a new file called `fish.py`, ensuring they integrate holistically into the existing Sudoku solver codebase. The goal is to match the style, methods, and API of the existing strategies (from `singles.py`, `subsets.py`, and `intersections.py`) as closely as possible, while being flexible to update the overall API where bending the fish implementation to fit the original would be inelegant or inefficient. Prioritize clean, maintainable code that supports batch processing over N puzzles, uses NumPy for vectorization, and minimizes loops to small fixed sizes (e.g., 9 rows/cols/values, 3 boxes).

### Key Principles for Matching and Integration:
- **API Matching**: All strategy functions take `candidates: np.ndarray` (shape `(N, 9, 9, 9)` boolean, where last dim is for values 1-9) and `all_deductions: list[list[dict]]` (list per puzzle, append dicts in-place). Return None. Use `np` operations like `np.sum`, `np.any`, `np.where` for vectorization, similar to how singles use masks (e.g., `cell_counts = np.sum(candidates, axis=3) == 1`) and subsets use `combinations` per unit.
- **Deductions Format**: Match existing formats exactly. For eliminations (fish are elimination-only, like subsets/intersections): `{'type': 'x_wing_row' or 'swordfish_col', 'positions': list of (r,c) tuples for the base pattern, 'candidate': int (the value k), 'eliminations': list of [((r,c), [candidates_to_elim])]}`. Include pattern details like `'base_rows': list[int]`, `'cover_cols': list[int]` for clarity, similar to `'box': (br,bc)` in intersections.
- **Vectorization Style**: Hybrid like subsets (vectorized over batch/N, loops over 9/3/k/combos). Use bitmasks for column sets (e.g., `row_bitmasks = np.sum(cand_k * (1 << np.arange(9))[None, None, :], axis=2)`) to efficiently compute unions and counts, as this is elegant for fish patterns without overcomplicating.
- **Variants**: Fish need row-based and column-based (symmetric). Implement as separate functions or a generic one with a param, but prefer explicit variants like `_row`/`_col` to match hidden singles (`_row`/`_col`/`_box`) and intersections (`_row`/`_col`).
- **Flexibility for API Updates**: If exact matching is awkward (e.g., fish combos are more combinatorial than singles), update shared parts like `apply_deductions` in `utils.py` to handle eliminations by mutating `candidates` (e.g., `candidates[n, r, c, val-1] = False` for each elim). Also, update `strategies.py` to group fish (e.g., `'fish': ['x_wing_row', 'x_wing_col', ...]`). In `solver.py`, add to default `strategies` list after intersections for escalation order.
- **Holistic Integration**: Ensure fish propagates effects (eliminations create new singles/subsets). Update the solver loop in `solver.py` to recompute candidates after applying eliminations if needed. Test for no conflicts using `is_valid`. Make sure `main.py` and sequence display handle new types (e.g., format fish in `format_deduction`).
- **Implementation Details**:
  - **Candidates Handling**: Extract `cand_k = candidates[..., k-1]` for each k=1-9, vectorized.
  - **Bitmasks and Popcount**: Use bitmasks for row/column positions (efficient for unions via `np.bitwise_or.reduce`). For popcount, use `np.popcount` if available, else a vectorized alternative like `np.array([bin(x).count('1') for x in union_bits])`.
  - **Combinations**: Use `itertools.combinations(range(9), n)` for base rows/cols (n=2 for X-Wing, 3 for Swordfish), check union count == n and each base has <=n positions >0.
  - **Coverage**: Optionally ensure each cover col appears in >=2 bases for strong links, but start with basic.
  - **Column-Based**: Duplicate logic with `candidates.swapaxes(1,2)`, adjust types/keys accordingly.
  - **Edge Cases**: Skip if no elims, ignore same-box patterns (handled by simpler strategies), ensure unsolved cells only.
  - **Updates to Other Files**:
    - `strategies.py`: Add to `STRATEGY_FUNCTIONS` (e.g., `'x_wing_row': find_x_wing_rows, ...`). Expand groups like `'fish'` in `find_deductions_batch`.
    - `utils.py`: Extend `apply_deductions` to loop over eliminations and mutate candidates (pass candidates as arg). Update `format_deduction` for fish types.
    - `solver.py`: In `solve_batch`, after `apply_deductions`, recompute candidates if elims applied. Add fish to `strategies` list.
    - `README.md`: Update "Implemented Strategies" with fish.

### Output Requirements:
- Provide the full code for `fish.py`.
- Provide diffs or full updated code for modified files (`strategies.py`, `utils.py`, `solver.py`).
- Include a brief explanation of changes and why they match/update the API.
- Ensure the implementation is performant for large batches (e.g., dataset's ~4M puzzles).
======================================================

GO. IMPLEMENT MAIN INSTRUCTIONS.


================================================
FILE: notes/PLAN3.md
================================================
I've been working with a dataset creator that creates vectorized numpy arrays representing various puzzles and it flattens everything into a sequence at the end for fast processing. I've invented a new type of positional encoding called MonSTERs (Minkowski Space-Time Embedding Rotors) that allows transformers to see more than just temporal sequences. Along with that I've come up with the following next step for my implementation plan:

Step 1: Extend dataset metadata for coordinate support
Key Files & Modules: dataset/common.py, dataset/*_dataset.py

Conceptual Changes Required:

Add fields to PuzzleDatasetMetadata describing coordinate dimensionality (e.g., coord_dims or per‑axis sizes).

Modify builders (build_sudoku_dataset.py, build_arc_dataset.py, etc.) so every example outputs a positions array of shape (seq_len, coord_dims) representing the coordinate of each token. Save these arrays in .npy alongside existing inputs/labels.

Dependencies & Rationale:

Metadata must describe coordinate shapes before the loader or model can use them.

Builders must emit coordinates so the loader and positional encoders have explicit spatial information.

I've attached some scripts so you can see how it works right now, but the one thing I think I need to figure out is this:

So in previous discussions we've had we've talked about the utility of using some function z = f(x,y) to augment our encoders on tasks involving 2d grids. If we don't use the z dimension at all, or the t dimension at all for that matter, we're leaving valuable parameters on the table and only encoding positional information into 1/2 of the parameters. (I think, right?) One function that's been working super well so far for the MonSTER encodings for sudoku has been z = (x % 2) + (y % 2) which gives more texture to the encodings in a symmetric double tri stripe pattern. Does this plan have any solid place for us to put our "z functions" or whether or not we'll even have one?

I mean we probably want to put that into the dataset creation part right? Like for all of the MonSTER encodings the dataset should always return a full 4d position for each token right?

But we will also have different RoPE setups too. So we need a way to parameterize these settings from the get go.

Like, for example, if we use a 9x9 sudoku puzzle, we would have different datasets for each of the following, right?

1. RoPE but using a flattened grid > sequence 1x81, [t]
2. RoPE but for a two dimensional non temporal grid 9x9 [x,y]
3. RoPE but for a two dimensional grid with solving steps Tx9x9 [t,x,y]
4. RoPE but for a three dimensional grid with time [t,x,y,z]

5. MonSTER but only using the 2d grid [0,x,y,0]
6. MonSTER but using a density function [0,x,y,z]
7. MonSTER but using a density function and temporal steps [t,x,y,z]

For the multidimensional RoPE see this excerpt from the Eleuther blog:

"### Extension to multiple dimensions

With relative ease RoPE can be extended into the multidimensional case. To represent two dimensions, two independent 1-dimensional rotary embeddings can be used. To implement this, we can split each of $\mathbf{q}$ and $\mathbf{k}$ in half and apply rotary piece-wise as follows:

$$\begin{align}
\langle f(\mathbf{q}, m, i), f(\mathbf{k}, n, j) \rangle 
&= \left\langle f_1\left(\mathbf{q}_{:d/2}, m\right), f_1\left(\mathbf{k}_{:d/2}, n\right) \right\rangle + \left\langle f_2\left(\mathbf{q}_{d/2:}, i\right), f_2\left(\mathbf{k}_{d/2:}, j\right) \right\rangle \\
&= g_1\left(\mathbf{q}_{:d/2}, \mathbf{k}_{:d/2}, m-n\right) + g_2\left(\mathbf{q}_{d/2:}, \mathbf{k}_{d/2:}, i-j\right) \\
&= g(\mathbf{q}, \mathbf{k}, m-n, i-j)
\end{align}$$

This formulation can also be further extended to data of an arbitrary number of dimensions. This sort of multi-dimensional relative coding would let us, for example, implement relative timing and relative pitch embeddings similar to Music Transformer [4] in a drastically simpler manner. More generally, we believe there is potentially a large class of invariances that first-principles positional codes like RoPE may enable us to capture."

I guess when it's all said and done I want it to work like described in this blog post:

"With the new generation of large language models, much of coding is becoming a solved problem. The real challenge now lies in systems engineering. One key lesson from years of working in distributed systems is to make your systems parametric—design them so that key variables and configurations are easy to adjust without rewriting core logic.

Each system should be organized into a file per “entity,” with clearly defined parameters or directives placed at the top for easy access. This approach makes it faster to adjust, test, and refine the system. The ultimate goal is to maximize the speed of experimentation and learning—you have to actively build and try things in order to discover what to do next."

So maybe at the very top we have some parameters:

1. Puzzle Native Dimensions (needs to denote spatial vs temporal and pair explicitly with txyz coords, so maybe an enum? For Sudoku this would clearly be t,x,y since the puzzle includes a starting board, an ending board, and rows and columns.
2. Encoder Selection (RoPE, MonSTER, Learned) Each encoder selection comes with its default dimensions and coordinate systems. 


================================================
FILE: notes/Steps.md
================================================
Set Notation Notes

Awesome prompt. Here’s a compact “Sudoku-as-CSP” in set notation that captures the essentials SudoRules is building, plus the core deductions it fires.

# Core sets & notation

Let

* $N=\{1,\dots,9\}$ (digits), $R=C=\{1,\dots,9\}$ (rows, cols),
* $X=R\times C$ (cells), and $B$ be the set of 9 blocks (each $b\subseteq X$).
* For a cell $x=(r,c)$, define its houses
  $\mathrm{row}(x)=\{(r,c')\}$, $\mathrm{col}(x)=\{(r',c)\}$, $\mathrm{blk}(x)\in B$.
  A *house* $H$ is any row, column, or block.
  Peers: $\mathrm{Peers}(x)=\big(\mathrm{row}(x)\cup \mathrm{col}(x)\cup \mathrm{blk}(x)\big)\setminus\{x\}$.

Candidates:

* A state is a map $C:X\to \mathcal{P}(N)$.
  For $x\in X$, $C(x)\subseteq N$ is the current candidate set of $x$.
* For a house $H$ and digit $n$, positions of $n$ in $H$ are
  $\mathrm{Pos}(H,n)=\{x\in H\mid n\in C(x)\}$.

Assignment semantics (value placed): $x\gets n$ means $C(x)=\{n\}$ and for all $y\in \mathrm{Peers}(x)$, remove $n$ from $C(y)$.

---

# Fundamental rules (few but powerful)

### 1) Cell single (a.k.a. naked single)

If $|C(x)|=1$, let $C(x)=\{n\}$. Then assign $x\gets n$.

### 2) House single (a.k.a. hidden single)

If $|\mathrm{Pos}(H,n)|=1$ with $\mathrm{Pos}(H,n)=\{x\}$, then assign $x\gets n$.

### 3) General *cover* rule (unifies pointing & claiming)

For any two houses $H_1,H_2$ that overlap (e.g., a row and the block it intersects) and any $n\in N$:

* If $\mathrm{Pos}(H_1,n)\subseteq H_1\cap H_2$, then
  eliminate $n$ from $H_2\setminus H_1$:
  $\forall y\in (H_2\setminus H_1):\; C(y)\leftarrow C(y)\setminus\{n\}$.
  (This is “pointing”.)
* Symmetrically, if $\mathrm{Pos}(H_2,n)\subseteq H_1\cap H_2$, eliminate $n$ from $H_1\setminus H_2$.
  (This is “claiming”.)

### 4) Naked subset (pairs/triples/quads)

Let $H$ be a house and $K\subseteq H$ with $|K|=k$. Define
$U=\bigcup_{x\in K} C(x)$.
If $|U|=k$ (i.e., exactly $k$ digits occupy exactly these $k$ cells), then

$$
\forall y\in H\setminus K:\; C(y)\leftarrow C(y)\setminus U .
$$

### 5) Hidden subset (pairs/triples/quads)

Let $H$ be a house and $D\subseteq N$ with $|D|=k$. Define
$K=\bigcup_{n\in D}\mathrm{Pos}(H,n)$.
If $|K|=k$ (i.e., these $k$ digits occur only in these $k$ cells), then

$$
\forall x\in K:\; C(x)\leftarrow C(x)\cap D .
$$

### 6) $k$-Fish (X-Wing/Swordfish/Jellyfish) — row form

Fix $n\in N$. Choose $R^\*\subseteq R$ with $|R^\*|=k$. Let

$$
C^\* \;=\; \bigcup_{r\in R^\*}\{\, c\in C \mid (r,c)\in \mathrm{Pos}(\mathrm{row}(r),n)\,\}.
$$

If $|C^\*|=k$ and for all $r\in R^\*$,
$\{\,c\mid (r,c)\in \mathrm{Pos}(\mathrm{row}(r),n)\,\}\subseteq C^\*$,
then eliminate $n$ from all cells in rows $R\setminus R^\*$ at columns $C^\*$:

$$
\forall r\notin R^\*,\;\forall c\in C^\*:\; C(r,c)\leftarrow C(r,c)\setminus\{n\}.
$$

(Transpose rows/cols for the column form.)

### 7) Uniqueness (UR Type 1) — a minimal statement

Let $r_1\neq r_2$, $c_1\neq c_2$, and $Q=\{(r_i,c_j): i,j\in\{1,2\}\}$.
If there exists $D\subseteq N$ with $|D|=2$ such that

* for three $x\in Q$, $C(x)=D$,
* for the fourth $x_0\in Q$, $D\subseteq C(x_0)$ and $\exists d\in C(x_0)\setminus D$,
  then to preserve uniqueness $x_0$ must take $d$: $C(x_0)=\{d\}$.

---

# (Optional) Multi-space view (rn/cn/bn)

The same candidate facts can be projected into *rn*, *cn*, *bn* spaces:

$$
\begin{aligned}
\mathrm{Pos}_{rn}(r,n)&=\{\, c\in C\mid (r,c)\in \mathrm{Pos}(\mathrm{row}(r),n)\,\},\\
\mathrm{Pos}_{cn}(c,n)&=\{\, r\in R\mid (r,c)\in \mathrm{Pos}(\mathrm{col}(c),n)\,\},\\
\mathrm{Pos}_{bn}(b,n)&=\{\, s\in \{1,\dots,9\}\mid \text{square }s\text{ of }b\text{ contains an }n\text{-candidate}\,\}.
\end{aligned}
$$

Assignments are equivalent across these views via the natural bijections between $(r,c)$, $(r,n)$, $(c,n)$, and $(b,s)$.

---

These seven rules (two singles, one cover, two subset rules, fish, and a basic uniqueness axiom) cover the lion’s share of what the loader + modules enable, and they’re enough to express most practical deductions SudoRules performs—while staying crisp in set notation.

---

Short answer: yes. If you model candidates as arrays, the rules you listed drop out cleanly.

* **Bool tensor**: `cand[r, c, n] ∈ {0,1}` says “digit `n+1` is still possible at `(r,c)`”.
* **Bitmask grid** (my favorite): `mask[r, c] ∈ uint16` where bit `n` is set iff digit `n+1` is a candidate.

Bitmasks make subset/fish/UR detection painless (bitwise ops + popcount). Below is a compact skeleton showing the core machinery and 4 rules (naked/hidden single, pointing, claiming). The others follow the same pattern with small combinatorics.

```python
import numpy as np
from itertools import combinations

DIGS = np.arange(9)              # 0..8 represent digits 1..9
ALL = (1 << 9) - 1               # 0b1_1111_1111

# --- helpers to build house index lists ---
ROWS = [[(r, c) for c in range(9)] for r in range(9)]
COLS = [[(r, c) for r in range(9)] for c in range(9)]
BLOCKS = []
for br in range(3):
    for bc in range(3):
        BLOCKS.append([(r, c)
                       for r in range(3*br, 3*br+3)
                       for c in range(3*bc, 3*bc+3)])
HOUSES = ROWS + COLS + BLOCKS

def popcount16(x: np.ndarray) -> np.ndarray:
    # numpy's vectorized bit_count is available for integer dtype
    return x.astype(np.uint16).bit_count()

def singleton_digit(mask_rc):
    """Return digit index if mask has exactly one bit, else -1."""
    if mask_rc and (mask_rc & (mask_rc-1)) == 0:
        return int(np.log2(mask_rc))
    return -1

# --- representation ---
# grid: 9x9 np.int8 with 0 for empty, 1..9 for fixed/solved values
# mask: 9x9 np.uint16 bitmasks for candidates

def init_masks_from_grid(grid):
    mask = np.full((9,9), ALL, dtype=np.uint16)
    for r in range(9):
        for c in range(9):
            v = grid[r, c]
            if v:
                m = 1 << (v-1)
                mask[r, c] = m
                # eliminate from peers
                for rr, cc in set(ROWS[r] + COLS[c] + BLOCKS[(r//3)*3 + (c//3)]):
                    if (rr, cc) != (r, c):
                        mask[rr, cc] &= ~m
    return mask

def assign(grid, mask, r, c, d):  # d is 0..8
    vmask = 1 << d
    grid[r, c] = d+1
    mask[r, c] = vmask
    changed = False
    # remove from peers
    peers = set(ROWS[r] + COLS[c] + BLOCKS[(r//3)*3 + (c//3)])
    peers.discard((r,c))
    for rr, cc in peers:
        if mask[rr, cc] & vmask:
            mask[rr, cc] &= ~vmask
            changed = True
    return changed or True

# ----------------- RULES -----------------

def rule_naked_single(grid, mask):
    """Cell single: |C(x)|=1."""
    prog = False
    pcs = popcount16(mask)
    rs, cs = np.where((grid == 0) & (pcs == 1))
    for r, c in zip(rs, cs):
        d = singleton_digit(mask[r, c])
        prog |= assign(grid, mask, r, c, d)
    return prog

def rule_hidden_single(grid, mask):
    """House single: |Pos(H,n)|=1."""
    prog = False
    for H in HOUSES:
        # For each digit, collect presence mask over cells in H
        cells = np.array(H)
        r_idx, c_idx = cells[:,0], cells[:,1]
        for d in DIGS:
            bit = 1 << d
            present = (mask[r_idx, c_idx] & bit) != 0
            if present.sum() == 1:
                k = int(np.flatnonzero(present)[0])
                r, c = r_idx[k], c_idx[k]
                if grid[r, c] == 0:
                    prog |= assign(grid, mask, r, c, d)
    return prog

def rule_pointing_and_claiming(grid, mask):
    """
    General cover rule on row/block and col/block overlaps.
    - Pointing: in a block, digit n only appears in one row (or one col) -> remove n in that row (col) outside the block.
    - Claiming: in a row, n only appears in the cells that lie in one block -> remove n from that block outside the row.
    """
    prog = False
    # Pointing (block -> row/col)
    for bidx, B in enumerate(BLOCKS):
        cells = np.array(B); br = (bidx//3)*3; bc = (bidx%3)*3
        for d in DIGS:
            bit = 1 << d
            inB = (mask[cells[:,0], cells[:,1]] & bit) != 0
            if not inB.any(): 
                continue
            rows_in_B = {r for r in range(br, br+3)
                         if ((mask[r, bc:bc+3] & bit) != 0).any()}
            if len(rows_in_B) == 1:
                r = rows_in_B.pop()
                # eliminate in row r outside the block
                out_cols = [c for c in range(9) if not (bc <= c < bc+3)]
                row_mask = mask[r, out_cols]
                hit = (row_mask & bit) != 0
                if hit.any():
                    mask[r, out_cols] &= (~bit)
                    prog = True
            cols_in_B = {c for c in range(bc, bc+3)
                         if ((mask[br:br+3, c] & bit) != 0).any()}
            if len(cols_in_B) == 1:
                c = cols_in_B.pop()
                out_rows = [r for r in range(9) if not (br <= r < br+3)]
                col_mask = mask[out_rows, c]
                hit = (col_mask & bit) != 0
                if hit.any():
                    mask[out_rows, c] &= (~bit)
                    prog = True

    # Claiming (row/col -> block)
    for r in range(9):
        cells = np.array(ROWS[r])
        for d in DIGS:
            bit = 1 << d
            pos = (mask[cells[:,0], cells[:,1]] & bit) != 0
            if not pos.any(): 
                continue
            blocks = {(r//3)*3 + (c//3) for _, c in cells[pos]}
            if len(blocks) == 1:
                bidx = next(iter(blocks)); br = (bidx//3)*3; bc = (bidx%3)*3
                # eliminate bit in block outside row r
                rows = [rr for rr in range(br, br+3) if rr != r]
                blk = mask[rows, bc:bc+3]
                hit = (blk & bit) != 0
                if hit.any():
                    mask[rows, bc:bc+3] &= (~bit)
                    prog = True
    for c in range(9):
        cells = np.array(COLS[c])
        for d in DIGS:
            bit = 1 << d
            pos = (mask[cells[:,0], cells[:,1]] & bit) != 0
            if not pos.any(): 
                continue
            blocks = {(r//3)*3 + (c//3) for r, _ in cells[pos]}
            if len(blocks) == 1:
                bidx = next(iter(blocks)); br = (bidx//3)*3; bc = (bidx%3)*3
                cols = [cc for cc in range(bc, bc+3) if cc != c]
                blk = mask[br:br+3, cols]
                hit = (blk & bit) != 0
                if hit.any():
                    mask[br:br+3, cols] &= (~bit)
                    prog = True
    return prog
```

### Subsets, fish, UR — how they look

* **Naked subset (k≤4)** in a house `H`:
  get the 9 masks `m_i` of the cells in `H`. For each combination of `k` cells, `U = OR(m_i)`; if `popcount(U)==k`, clear bits `U` from all other cells in `H`. This is \~27·(C(9,2)+C(9,3)+C(9,4)) checks — tiny.

* **Hidden subset (k≤4)** is the dual: for each digit subset `D` (combine bits), union the *positions* where those bits appear; if exactly `k` cells, intersect those cells’ masks with `D`.

* **k-Fish** for a digit `d`:
  form a 9×9 boolean matrix `A[r,c] = (mask[r,c] & bit(d))!=0`.
  For rows: choose `k` rows; let `C*` be the union of columns with a 1 in those rows. If `|C*|==k`, clear `d` from all other rows at columns `C*`. Columns version is transposed. Limiting to `k∈{2,3,4}` is plenty.

* **UR Type 1**: enumerate each 2×2 cell rectangle `Q`. Let `U = OR(masks on Q)`. If `popcount(U)==2` and exactly three cells in `Q` equal `U`, then the fourth must keep only the extra bit (i.e., assign it).

### Solve loop

```python
def solve(grid):
    mask = init_masks_from_grid(grid.copy())
    progress = True
    while progress:
        progress = False
        progress |= rule_naked_single(grid, mask)
        progress |= rule_hidden_single(grid, mask)
        progress |= rule_pointing_and_claiming(grid, mask)
        # progress |= rule_naked_subset(grid, mask, k_max=4)
        # progress |= rule_hidden_subset(grid, mask, k_max=4)
        # progress |= rule_fish(grid, mask, k_max=4)
        # progress |= rule_ur_type1(grid, mask)
    return grid, mask
```

### How “straightforward” is it?

* **Singles & cover (pointing/claiming)**: fully vectorizable/broadcast-friendly → very straightforward.
* **Subsets/fish/UR**: clean in code, but rely on small **combinational searches** (choose k rows/digits/cells). With bitmasks, those loops are tiny and fast for Sudoku sizes.
* **Chains/whips/etc.**: those are graph search; not asked here.

If you want, I can drop a complete, runnable `numpy` solver (with subsets/fish/UR included) into a file you can tweak and benchmark.











# Overview

1. General
    - Background:
        - It defines numbers, rows, columns, blocks, and squares, essentially setting up the framework for reasoning about Sudoku grids.
        - Defines the entities used in Sudoku:
            Numbers → the symbols placed in cells (typically 1–9).
            Rows, Columns, Blocks → the basic structural units of the Sudoku grid.
            Squares → individual cells in the grid.
        - Provides a mapping system so external symbols (like digits) are mapped to internal integers.
2. 



Strategy ordering and the salience system
CSP‑Rules applies its techniques strictly in a “simplest‑first” order, achieved through a hierarchy of salience levels.
Salience is just an integer priority; the engine decrements it as it moves to more complex techniques, ensuring that easy rules fire before harder ones.

Level 0 – Basic Resolution Technique (BRT)

Contradiction detection

Elementary constraints propagation

Singles (assign a value when a CSP variable has only one candidate)

Higher levels – chain families ordered by increasing complexity
For each chain length L (the solver implements lengths up to at least 36), the salience file defines the following sequence. The excerpt below shows level 11 as a representative example; the ordering is identical at other lengths:

Typed bivalue-chains

Bivalue-chains

Typed z-chains

z-chains

Oddagons and anti‑oddagons

Typed t‑whips

t‑whips

Typed whips

Whips

g‑bivalue-chains

g2‑whips

Typed g‑whips

g‑whips

Braids

g‑braids

Extended families and forcing variants
After the base chains, more elaborate techniques become eligible, still respecting chain length:

OR₂–OR₈ forcing whips → OR₂–OR₈ whips

OR₂–OR₈ forcing g‑whips → OR₂–OR₈ g‑whips

Forcing whips, forcing g‑whips, forcing braids, forcing g‑braids

w*-whips, b*-braids

biwhips, bibraids

Fallback search
Only after all pattern-based rules fail does the solver resort to Trial‑and‑Error (T&E) or its bi-directional variant, each with their own salience to ensure they run after every deterministic rule family

In summary, Berthier’s salience system enforces a clear progression: contradiction checks and singles first, then progressively longer and more general chains, then OR‑based and forcing variants, culminating in exhaustive search only as a last resort.


================================================
FILE: notes/taxonomy.md
================================================
To make the code more modular and maintainable, yes, breaking it into multiple files is a good idea—especially as we add more strategies, which could make a single `human_strategies.py` file bloated and hard to navigate. Since your goal is to generate extended sequences of solving steps (mimicking human logic) for each puzzle in the dataset, organizing by strategy type or complexity will help keep related functions together and make it easier to extend (e.g., adding new strategies without touching unrelated code).

### Suggested File Names and Structure
Based on the taxonomy below, I recommend grouping strategies logically by their complexity and type of operation. This aligns with common Sudoku solver implementations, where simpler strategies (like singles) are applied first in the solver loop for efficiency, before escalating to more complex ones (like chains). Here's a breakdown:

- **singles.py**: For basic single-candidate strategies (Naked Single and Hidden Single). These are the simplest and most frequent, resulting in direct certainties (filling a cell).
- **subsets.py**: For pair/triplet/quad strategies (Naked Pair/Triplet/Quad and Hidden Pair/Triplet/Quad). These operate on small groups (2-4) of cells or candidates, often leading to eliminations.
- **intersections.py**: For Locked Candidates (also known as Pointing Pairs/Triples or Claiming). This focuses on intersections between units, leading to eliminations.
- **fish.py**: For grid-pattern strategies like X-Wing and Swordfish (extendable to Jellyfish if needed). These are column/row-based eliminations on larger patterns.
- **wings.py**: For hinge/chain starter strategies like XY-Wing and XYZ-Wing. These introduce simple chain logic for eliminations.
- **chains.py**: For advanced chain-based strategies (Coloring, Forcing Chain, Nishio). These are more complex, often involving graph-like traversals or trials, and can lead to either certainties or eliminations.

This gives us 6 files instead of 2, but they're small and focused—better for scalability. If you prefer just two files to start, we could do `basic_strategies.py` (singles + intersections + subsets) and `advanced_strategies.py` (fish + wings + chains), but the finer split will pay off as we implement more.

Each file would contain:
- The strategy functions (e.g., `find_naked_singles(candidates, all_deductions)`).
- Possibly sub-functions if needed (e.g., separate row/col/box handlers for hidden subsets).

Then, create a central `strategies.py` file that:
- Imports all the strategy functions from the above files.
- Maintains the `STRATEGY_FUNCTIONS` dictionary (mapping names to functions).
- Handles group expansions (e.g., `'hidden_single'` → row/col/box variants).
- Exports `find_deductions_batch` (which computes candidates once, then calls the requested strategies).

This way, your solver can import from `strategies.py` without knowing the internal file split.

### Outline of the Whole Repo
Here's how the repo could look and work together. The flow is: Download/process data → Load puzzles by difficulty → For each puzzle, run a solver loop that applies strategies step-by-step, recording each deduction/elimination as part of a "sequence" (e.g., a list of states or steps) → Save or analyze the sequences.

```
sudoku-solver-repo/
├── dataset_download.py     # Downloads CSVs from HF, processes into difficulty-bucketed .npy files (inputs/outputs as 9x9 arrays).
├── strategies/             # Directory for strategy modules (to keep root clean).
│   ├── __init__.py         # Empty, or exports all for easy imports.
│   ├── strategies.py       # Central hub: imports all functions, defines STRATEGY_FUNCTIONS dict, implements find_deductions_batch.
│   ├── singles.py          # Naked Single, Hidden Single (row/col/box).
│   ├── subsets.py          # Naked/Hidden Pairs/Triplets/Quads (row/col/box variants).
│   ├── intersections.py    # Locked Candidates (pointing and claiming).
│   ├── fish.py             # X-Wing, Swordfish.
│   ├── wings.py            # XY-Wing, XYZ-Wing.
│   └── chains.py           # Coloring, Forcing Chain, Nishio.
├── solver.py               # The core solver: Loads .npy files, for each puzzle: initialize grid, loop until solved/stuck: compute candidates → find deductions (via strategies.py) → apply fills/eliminations → record step (e.g., as a dict: {'step': i, 'grid_state': copy_of_grid, 'deductions': list_of_dicts}). Handles batching for efficiency. Outputs sequences as .npy or JSON per difficulty.
├── utils.py                # Helpers: Grid validation (is_valid_sudoku), pretty-print grid, apply_deduction (fill or eliminate on grid), maybe candidate computation if we extract it.
├── main.py                 # Entry point: Args for difficulty levels/subsample, calls dataset_download if needed, then solver, perhaps prints stats (e.g., avg steps per difficulty).
├── requirements.txt        # numpy, huggingface_hub, tqdm, etc.
├── data/                   # Generated: lvl-*-inputs.npy, lvl-*-outputs.npy, and later sequence files.
└── README.md               # Explains setup, how to run, and strategy taxonomy.
```

**How It Works Together**:
1. Run `dataset_download.py` (once): Fetches data, buckets by difficulty into `data/`.
2. In `main.py`: Parse args (e.g., difficulties to process), load inputs/outputs from .npy.
3. Call functions from `solver.py`: For a batch of puzzles (e.g., all level 5), initialize grids from inputs.
4. Solver loop per puzzle (or batched where possible):
   - While not solved and progress possible:
     - Call `find_deductions_batch` from `strategies.py` with desired strategies (e.g., start with basics, escalate if stuck).
     - Apply deductions: Fill certainties first, then eliminations. Update grid.
     - Record the step: Current grid snapshot + list of deductions applied.
   - Validate against output (solution) if needed.
   - Collect sequences (lists of steps) for ML dataset generation.
5. Save sequences (e.g., per difficulty as .npy: array of [puzzle_id, step_id, grid_flat, deductions_json]).

This structure supports your "extended sequence" goal: Each sequence is a chain of states from initial grid to solved, with human-like steps annotated by strategy type.

### Taxonomy of Strategies
Sudoku strategies can be classified in a few ways, but no single taxonomy is perfect—they overlap. I'll break them down by:
- **Action Type**: Does it result in a *certainty* (definite fill of a cell) or an *operation on unknowns* (eliminate candidates, reducing possibilities without filling)?
- **Complexity/Size**: Based on the number of cells/candidates involved (single=1, double/pair=2, triple=3, quad=4, or more for chains).
- **Scope**: Unit-based (row/col/box), intersection (between units), pattern/grid-wide, or chain/trial (implications across the grid).
- **Notes**: Brief description, why it's "human-like," and typical order in solvers (simpler first to avoid unnecessary complexity).

| Strategy              | Action Type          | Complexity/Size | Scope              | Notes |
|-----------------------|----------------------|-----------------|--------------------|-------|
| **Naked Single**     | Certainty (fill cell) | Single (1 candidate in cell) | Cell-only | Simplest: Cell has only 1 possible candidate left after basic eliminations. Applied first in most solvers. |
| **Hidden Single**    | Certainty (fill cell) | Single (1 cell for a candidate in unit) | Unit (row/col/box) | Candidate appears in only 1 cell in a unit; fill it. Similar to naked but "hidden" among other candidates. |
| **Locked Candidates** | Operation on unknowns (eliminate candidates) | Pair/Triple (2-3 cells in intersection) | Intersection (box-row/col) | Candidate locked to a box-line intersection; eliminate from rest of line or box. AKA Pointing (box→line) or Claiming (line→box). |
| **Naked Pair/Triplet/Quad** | Operation on unknowns (eliminate candidates) | Pair (2), Triple (3), Quad (4) cells/candidates | Unit (row/col/box) | Group of cells in unit with exactly those candidates; eliminate them from other cells in unit. |
| **Hidden Pair/Triplet/Quad** | Operation on unknowns (eliminate candidates) | Pair (2), Triple (3), Quad (4) candidates/cells | Unit (row/col/box) | Group of candidates appear only in those cells in unit; eliminate other candidates from those cells. Inverse of naked subsets. |
| **XY-Wing**          | Operation on unknowns (eliminate candidates) | Triple (3 cells in chain) | Chain (bivalue cells connected) | Pivot cell (XY) linked to two wings (XZ, YZ); eliminates Z where wings "see" it. Simple chain strategy. |
| **XYZ-Wing**         | Operation on unknowns (eliminate candidates) | Triple (3 cells, pivot has 3 candidates) | Chain (trivalue pivot + bivalue wings) | Extension of XY-Wing; pivot (XYZ) + wings (XZ, YZ); eliminates Z in common peer cells. |
| **X-Wing**           | Operation on unknowns (eliminate candidates) | Quad (4 cells in rectangle) | Grid-wide (2 rows + 2 cols) | Candidate in 2 rows only at 2 cols each, forming rectangle; eliminate from those cols elsewhere. Basic "fish" pattern. |
| **Swordfish**        | Operation on unknowns (eliminate candidates) | 9 cells (3x3 grid) | Grid-wide (3 rows + 3 cols) | Like X-Wing but for 3 rows/cols; eliminates in aligned cols/rows. Advanced fish. |
| **Coloring**         | Operation on unknowns (eliminate) or certainty (if contradiction) | Variable (chain length) | Chain (candidate graph) | Treat candidates as graph nodes, color chains; if same color sees each other, eliminate. Handles complex implications. |
| **Forcing Chain**    | Operation on unknowns (eliminate) or certainty (fill if all paths lead to same) | Variable (chain length) | Chain (implications across grid) | Follow "if A then B then C" chains; if contradiction or forced value, act. Can be short (nice loops) or long. |
| **Nishio**           | Operation on unknowns (eliminate via trial) | Variable (assumption + chain) | Trial/chain (assume candidate true/false) | Assume a candidate is true, propagate; if contradiction, eliminate it. Lightweight backtracking/trial-and-error. |

**Overall Patterns**:
- **Certainty vs. Unknowns**: Singles always fill (certainty). Most others eliminate (reducing unknowns), which may indirectly create new singles. Chains/trials can do both.
- **Single/Double/Triple**: Singles are "single," subsets scale to quad, wings/fish are fixed-size patterns (triple/quad+), chains are variable (often >3).
- **Human-Like Progression**: Humans start with singles (obvious fills), then subsets/intersections (local patterns), then fish/wings (grid scans), and chains/trials last (deductive reasoning). Your solver should apply in this order to generate natural sequences.
- **Implementation Tip**: All rely on candidates array. Simpler ones (singles/subsets) are unit-based and fast; chains are slower (graph traversal), so apply sparingly.



∴   Therefore
∵   Because
∄   There Does Not Exist
∁   Complement
𝍸   Tally
∈   Element of; indicates membership in a set.
∉   Not an element of; indicates non-membership.

±   
∑
÷
∞
∅   Empty set; a set with no elements.
∩   Intersection; common elements between sets.
∪   Union; combines elements from sets.
⊆   Subset of or equal to; all elements of one set are in another.

+/−/=/</>

?𝍸4

| Symbol | Unicode | Meaning                                                   |
|:------:|:-------:|:---------------------------------------------------------:|
|   =    | U+003D  | Equality; two expressions have the same value.            |
|   ≠    | U+2260  | Inequality; two expressions differ in value.              |
|   <    | U+003C  | Less than; one value smaller than another.                |
|   >    | U+003E  | Greater than; one value larger than another.              |
|   ≤    | U+2264  | Less than or equal to; inclusive lower bound.             |
|   ≥    | U+2265  | Greater than or equal to; inclusive upper bound.          |
|   ≈    | U+2248  | Approximately equal; values close but not identical.      |
|   ≡    | U+2261  | Congruent; strong equivalence or identical nature.        |
|   ∁    | U+2201  | Complement; elements not in the original set.             |
|   ∵    | U+2235  | Because; indicates reason in logical arguments.           |
|   ∴    | U+2234  | Therefore; indicates conclusion in logical arguments.     |
|   ∄    | U+2204  | Does not exist; negated existential quantifier.           |
|   ∃    | U+2203  | There exists; existential quantifier in logic.            |
|   ∌    | U+220C  | Does not contain; negated set membership.                 |
|   ∋    | U+220B  | Contains member; reverse set membership relation.         |
|   +    | U+002B  | Addition; sum of two or more values.                      |
|   −    | U+2212  | Subtraction; difference between two values.               |
|   ×    | U+00D7  | Multiplication; product of two values.                    |
|   ÷    | U+00F7  | Division; quotient of two values.                         |
|   ∑    | U+2211  | Summation; total of a series of terms.                    |
|   ∞    | U+221E  | Infinity; unbounded or limitless quantity.                |
|   ±    | U+00B1  | Plus-minus; indicates range or alternatives.              |
|   ∈    | U+2208  | Element of; membership in a set.                          |
|   ∉    | U+2209  | Not element of; non-membership in set.                    |
|   ⊆    | U+2286  | Subset equal; all elements included in another.           |
|   ∪    | U+222A  | Union; combines elements from multiple sets.              |
|   ∩    | U+2229  | Intersection; common elements in sets.                    |
|   ∅    | U+2205  | Empty set; set with no elements.                          |
|   ∀    | U+2200  | For all; universal quantifier in logic.                   |
|   ∃    | U+2203  | There exists; existential quantifier in logic.            |
|   ¬    | U+00AC  | Negation; inverts truth value of operand.                 |
|   ∧    | U+2227  | Conjunction; true if both operands true.                  |
|   ∨    | U+2228  | Disjunction; true if at least one operand true.           |
|   ⊕    | U+2295  | Exclusive or; true if exactly one operand true.           |
|   ⇒    | U+21D2  | Implication; false only if antecedent T and consequent F. |
|   ⇔    | U+21D4  | Biconditional; true if operands match in truth.           |
|   ⊤    | U+22A4  | Tautology; always true proposition.                       |
|   ⊥    | U+22A5  | Contradiction; always false proposition.                  |
|   ⊢    | U+22A2  | Proves; syntactic entailment from axioms.                 |


ASSIGN, EXCLUDE, ASSUME
ASSERT, REJECT, PROPOSE

R2C8 = 8
R2C8 ≠ 8
R2C8 = -8
R2C8 ≠ -8


 T-8:  Δ +4

 T = 8
 Δ = +4


[ROW ID, COLUMN ID, ACTION ID, VALUE ID]

IS ROW 8 COLUMN 2 EQUAL TO 3?

? R8C2 = 3 : 

Which numbers are in block 1?

? ∋ B1 (Returns B1 Placements)
? ∌ B1 (Returns B1 Absences)

? ∋ C1
? ∌ C1

∋ C1 = ?
∌ C1 ≠ ?


allowed symbols?

Is board valid?



Glossary:

REGION:
A set or collection of positions (cells) on the Sudoku board. Regions are subsets of the board's positions, varying in size and structure, and serve as foundational units for constraints and puzzle structure. All regions are disjoint or overlapping collections of positions, but core gameplay constraints (e.g., uniqueness of digits 1–9) apply specifically to certain region types.

    REGION:SQUARE
        The atomic (smallest indivisible) region. A singleton set consisting of exactly one position, which may hold a given digit (1–9) or a set of candidate digits during solving.

    REGION:HOUSE
        An intermediate region consisting of exactly nine positions, where the digits 1–9 must each appear exactly once (the core uniqueness constraint of Sudoku). Houses form the primary partitioning of the board into constraint-bearing groups and are categorized into three subtypes based on their geometric arrangement.

        REGION:HOUSE:ROW
            A horizontal house: the set of nine positions sharing the same row index (typically denoted as rows 1–9 from top to bottom).

        REGION:HOUSE:COLUMN
            A vertical house: the set of nine positions sharing the same column index (typically denoted as columns 1–9 from left to right).

        REGION:HOUSE:BOX
            A block house: the set of nine positions forming a 3×3 subgrid (typically denoted as boxes 1–9, arranged in a 3×3 meta-grid from top-left to bottom-right).

    REGION:BOARD
        The maximal (universal) region: the complete set of 81 positions, arranged in a 9×9 grid subdivided into 9 rows, 9 columns, and 9 boxes. The board is the union of all houses and the domain over which the puzzle is defined and solved.

REGION:BAND
    A horizontal meta-region (also called a "chute" in some contexts) consisting of exactly 27 positions, formed by three consecutive rows (thus encompassing three full houses of the row subtype and one horizontal row of three 3×3 boxes). Bands partition the board into three non-overlapping horizontal strips (typically labeled 1–3 from top to bottom) and are used in puzzle structure, variant rules, and advanced solving techniques (e.g., band-based patterns or symmetries).

REGION:STACK
    A vertical meta-region (also called a "chute" in some contexts) consisting of exactly 27 positions, formed by three consecutive columns (thus encompassing three full houses of the column subtype and one vertical column of three 3×3 boxes). Stacks partition the board into three non-overlapping vertical strips (typically labeled 1–3 from left to right) and are used analogously to bands in puzzle structure, variant rules, and advanced solving techniques (e.g., stack-based patterns or symmetries).


A denoted position that holds either a forced/known value or a set of candidates.
BOARD - Place 2, A collection of SQUARES arranged in a 9x9 grid containing initial values and empty cells
ROW
COLUMN
BOX
HOUSE
BAND
STACK


ASSIGN - Action 1, Filling an unfilled square with a Forced Value
EXCLUDE - Action 2, Removing a value from an unfilled squares candidate set
ASSUME - The act of filling an unfilled square with an uncertain value
ADVANCE - 

BOARD - Space 1, dimensions 9x9, contains initial values and placed values
HOUSE — any row, column, or box.
ROW - horizontal 
COLUMN - 

Contradiction – In Sudoku an illegal and therefore contradictory situation can occur if a) there are no candidates left in a cell, or b) two or more cells claim to be true. The aim of many strategies is to show a contradiction.



---

Notes:

> The first thing to consider about the way a human being tackles the problem is
> that a puzzle is never submitted in a purely logical form; on the contrary, it is always
> centred on a spatial presentation[^2], i.e.: "complete the following grid…".
>
> — Denis Berthier, *The Hidden Logic of Sudoku*, 2nd ed., **Prologue**, p. 14.

[^2]: Notice that the same remark applies to most of the so called logical games.

```bibtex
@book{berthier2007hiddenlogic,
  author    = {Denis Berthier},
  title     = {The Hidden Logic of Sudoku},
  edition   = {2nd},
  year      = {2007},
  isbn      = {978-1-84799-214-7}
}
```

---

> In every cell, one writes either the number that must definitely occupy it or (with a pencil and in smaller size) the list of all its "candidates", i.e. of all the numbers that may still occupy it. Solving the grid then consists of progressively reducing this list of candidates by constraints propagation, until only one possibility remains for each cell.
>
> — Denis Berthier, *The Hidden Logic of Sudoku*, 2nd ed., **Prologue**, pp. 14–15.

---

> This universal spatial presentation of the puzzle, together with the associated model of cells to be filled with one number each, hide some logical symmetries of the problem. And considering that eliciting these symmetries leads to the quasi identification of complex rules (such as X-Wing, Swordfish and Jellyfish) with apparently much simpler ones (such as Naked Pairs, Naked Triplets and Naked Quadruplets respectively), there is a mathematical beauty in it.
>
> As everybody knows, the Powers of Darkness do not like Beauty.
>
> — Denis Berthier, *The Hidden Logic of Sudoku*, 2nd ed., **Prologue**, p. 15.

---

> One vicious thing leading to a virtuous one, the whole process ended with this book
>
> — Denis Berthier, *The Hidden Logic of Sudoku*, 2nd ed., **Prologue**, p. 15.

---

> **1.1. Statement of the Sudoku problem**  
> Given a 9x9 grid, partially filled with numbers from 1 to 9 (the "entries" of the
> problem, also called the "clues" or the "givens"), complete it with numbers from 1 to
> 9 so that in every of the nine rows, in every of the nine columns and in every of the
> nine disjoint blocks of 3x3 contiguous cells, the following property holds:
> – there is at most one occurrence of each of these numbers.
>
> …
>
> Since rows, columns and blocks play similar roles in the defining constraints,
> they will naturally appear to do so in many other places and it is convenient to introduce a word that makes no difference between them: a unit is either a row or a
> column or a block. And we say that two cells share a unit if they are either in the
> same row or in the same column or in the same block (where "or" is non exclusive).
> We also say that these two cells are linked, or that they see each other. It should be
> noticed that this (symmetric) relation between two cells, whichever of the three
> equivalent names it is given, does not depend in any way on the content of these
> cells but only on their place in the grid; it is therefore a straightforward and quasi
> physical notion.
>
> — Denis Berthier, *The Hidden Logic of Sudoku*, 2nd ed., **Introduction**, p. 17.

---

> Figure 1 below shows the standard presentations of a problem grid (also called a
> puzzle) and of a solution grid (also called a complete Sudoku grid).
>
> — Denis Berthier, *The Hidden Logic of Sudoku*, 2nd ed., **Introduction**, p. 18.

---

> The process of solving a grid "by hand" is generally initialised
> by defining the "candidates" for each cell. For later formalisation, one must give a
> careful definition of this notion: at any stage of the resolution process, candidates
> for a cell are the numbers that are not yet explicitly known to be impossible values
> for this cell.
>
> — Denis Berthier, *The Hidden Logic of Sudoku*, 2nd ed., **Introduction**, p. 19.




# From Examples to Rules: Six Essential Questions

1. What’s essential vs. coincidence?
   From the examples, which relationships are truly part of the rule, and which are just accidental details?

2. What’s required vs. optional in each cell?
   Which candidates must be present, which can be missing, and are any extra candidates allowed?

3. How do we stop it collapsing into something simpler?
   What conditions prevent the pattern from degenerating into basic techniques (like Naked Quads)?

4. Can the structure be generalized?
   Does this fit into a bigger family of patterns or larger shapes/grids beyond the standard 9×9 case?

5. What are the basic building blocks?
   Which primitives (e.g., crosses or x2y2 segments) best capture the idea—and which are more “atomic” for proofs?

6. Where does it sit in the difficulty hierarchy?
   How should we rank/classify its complexity (e.g., roughly a 16-variable pattern) so the rule is stated precisely?


CLIPS (C Language Integrated Production System) is a classic, embeddable expert-system shell created at NASA in the 1980s by Gary Riley. It’s designed for building knowledge-based programs—especially rule-based systems—and is still widely used for teaching and for small, reliable production rule engines.


================================================
FILE: strategies/__init__.py
================================================
# Strategies package for Sudoku solving

from .strategies import find_deductions_batch, TIERS


================================================
FILE: strategies/chains.py
================================================
# Chains strategies: Coloring, Forcing Chain, Nishio
# Placeholder file - implement strategies here 


================================================
FILE: strategies/fish.py
================================================
"""Fish pattern strategies implemented on boolean candidate grids."""

from itertools import combinations
import numpy as np


def _fish(mask: np.ndarray, size: int, orient: str, name: str, out: list[list[dict]]):
    N = mask.shape[0]
    for n in range(N):
        m = mask[n]
        for digit in range(1, 10):
            d = digit - 1
            if orient == "row":
                sets = [{c for c in range(9) if m[r, c, d]} for r in range(9)]
                for rows in combinations(range(9), size):
                    cols_union = set().union(*(sets[r] for r in rows))
                    if len(cols_union) != size:
                        continue
                    if any(not sets[r] or not sets[r].issubset(cols_union) for r in rows):
                        continue
                    elims: dict[tuple[int, int], list[int]] = {}
                    for rr in range(9):
                        if rr in rows:
                            continue
                        for c in cols_union:
                            if m[rr, c, d]:
                                elims.setdefault((rr, c), []).append(digit)
                    if elims:
                        out[n].append({
                            "type": f"{name}_row",
                            "base": rows,
                            "eliminations": list(elims.items()),
                        })
            else:
                sets = [{r for r in range(9) if m[r, c, d]} for c in range(9)]
                for cols in combinations(range(9), size):
                    rows_union = set().union(*(sets[c] for c in cols))
                    if len(rows_union) != size:
                        continue
                    if any(not sets[c] or not sets[c].issubset(rows_union) for c in cols):
                        continue
                    elims: dict[tuple[int, int], list[int]] = {}
                    for cc in range(9):
                        if cc in cols:
                            continue
                        for r in rows_union:
                            if m[r, cc, d]:
                                elims.setdefault((r, cc), []).append(digit)
                    if elims:
                        out[n].append({
                            "type": f"{name}_col",
                            "base": cols,
                            "eliminations": list(elims.items()),
                        })


def find_x_wing_rows(mask: np.ndarray, out: list[list[dict]]) -> None:
    _fish(mask, 2, "row", "x_wing", out)


def find_x_wing_cols(mask: np.ndarray, out: list[list[dict]]) -> None:
    _fish(mask, 2, "col", "x_wing", out)


def find_swordfish_rows(mask: np.ndarray, out: list[list[dict]]) -> None:
    _fish(mask, 3, "row", "swordfish", out)


def find_swordfish_cols(mask: np.ndarray, out: list[list[dict]]) -> None:
    _fish(mask, 3, "col", "swordfish", out)


def find_jellyfish_rows(mask: np.ndarray, out: list[list[dict]]) -> None:
    _fish(mask, 4, "row", "jellyfish", out)


def find_jellyfish_cols(mask: np.ndarray, out: list[list[dict]]) -> None:
    _fish(mask, 4, "col", "jellyfish", out)




================================================
FILE: strategies/intersections.py
================================================
"""Intersection removal strategies using boolean candidate grids."""

import numpy as np

from engine.utils import ROWS, COLS, BLOCKS


def _cover(m: np.ndarray, H1, H2, digit: int):
    """Return elimination list when digit in ``H1`` is confined to ``H2``."""
    d = digit - 1
    pos = [rc for rc in H1 if m[rc][d]]
    if not pos:
        return []
    if all(rc in H2 for rc in pos):
        elims: dict[tuple[int, int], list[int]] = {}
        for r, c in H2:
            if (r, c) not in H1 and m[r, c, d]:
                elims.setdefault((r, c), []).append(digit)
        return list(elims.items())
    return []


def find_locked_candidates_pointing(mask: np.ndarray, out: list[list[dict]]) -> None:
    N = mask.shape[0]
    for n in range(N):
        m = mask[n]
        for B in BLOCKS:
            rows = {r for r, _ in B}
            cols = {c for _, c in B}
            for digit in range(1, 10):
                for r in rows:
                    elims = _cover(m, B, ROWS[r], digit)
                    if elims:
                        out[n].append({"type": "locked_pointing", "eliminations": elims})
                for c in cols:
                    elims = _cover(m, B, COLS[c], digit)
                    if elims:
                        out[n].append({"type": "locked_pointing", "eliminations": elims})


def find_locked_candidates_claiming(mask: np.ndarray, out: list[list[dict]]) -> None:
    N = mask.shape[0]
    for n in range(N):
        m = mask[n]
        for r in range(9):
            blocks = {(r // 3) * 3 + (c // 3) for _, c in ROWS[r]}
            for bidx in blocks:
                B = BLOCKS[bidx]
                for digit in range(1, 10):
                    elims = _cover(m, ROWS[r], B, digit)
                    if elims:
                        out[n].append({"type": "locked_claiming", "eliminations": elims})
        for c in range(9):
            blocks = {(r // 3) * 3 + (c // 3) for r, _ in COLS[c]}
            for bidx in blocks:
                B = BLOCKS[bidx]
                for digit in range(1, 10):
                    elims = _cover(m, COLS[c], B, digit)
                    if elims:
                        out[n].append({"type": "locked_claiming", "eliminations": elims})




================================================
FILE: strategies/singles.py
================================================
"""Single-digit deduction strategies using boolean candidate grids."""

import numpy as np

from engine.utils import ROWS, COLS, BLOCKS


def find_naked_singles(mask: np.ndarray, out: list[list[dict]]) -> None:
    """Identify cells that have only one remaining candidate."""
    pcs = mask.sum(axis=3)
    N = mask.shape[0]
    for n in range(N):
        rs, cs = np.where(pcs[n] == 1)
        for r, c in zip(rs, cs):
            digit = int(np.where(mask[n, r, c])[0][0] + 1)
            out[n].append({"type": "naked_single", "position": (r, c), "value": digit})


def _hidden_single(mask: np.ndarray, houses: list[list[tuple[int, int]]], tag: str, out: list[list[dict]]) -> None:
    """Common helper for hidden singles across ``houses`` with result ``tag``."""
    N = mask.shape[0]
    for n in range(N):
        m = mask[n]
        for H in houses:
            cells = np.array([m[r, c] for r, c in H])
            for digit in range(9):
                positions = np.where(cells[:, digit])[0]
                if len(positions) == 1:
                    idx = positions[0]
                    r, c = H[idx]
                    out[n].append({"type": tag, "position": (r, c), "value": digit + 1})


def find_hidden_singles_rows(mask: np.ndarray, out: list[list[dict]]) -> None:
    _hidden_single(mask, ROWS, "hidden_single_row", out)


def find_hidden_singles_cols(mask: np.ndarray, out: list[list[dict]]) -> None:
    _hidden_single(mask, COLS, "hidden_single_col", out)


def find_hidden_singles_boxes(mask: np.ndarray, out: list[list[dict]]) -> None:
    _hidden_single(mask, BLOCKS, "hidden_single_box", out)




================================================
FILE: strategies/strategies.py
================================================
import numpy as np

# --- imports (deduped; keep optional ones commented until implemented) ---
from .singles import (
    find_naked_singles,
    find_hidden_singles_rows,
    find_hidden_singles_cols,
    find_hidden_singles_boxes,
)

from .intersections import (
    find_locked_candidates_pointing,
    find_locked_candidates_claiming,
)

from .subsets import find_naked_subsets, find_hidden_subsets

from .fish import (
    find_x_wing_rows, find_x_wing_cols,
    find_swordfish_rows, find_swordfish_cols,
    find_jellyfish_rows, find_jellyfish_cols,
)

from .uniqueness import (
    find_bug,
    find_ur_type1, find_ur_type2, find_ur_type2b,
    find_ur_type3, find_ur_type4,
)
# Optional (enable if you have them)
# from .wings import find_xy_wing, find_xyz_wing, find_w_wing
# from .wings import find_xy_wing, find_xyz_wing, find_w_wing


STRATEGY_FUNCTIONS = {
    # Singles
    "naked_single": find_naked_singles,
    "hidden_single_row": find_hidden_singles_rows,
    "hidden_single_col": find_hidden_singles_cols,
    "hidden_single_box": find_hidden_singles_boxes,

    # Intersections & Subsets
    "locked_pointing": find_locked_candidates_pointing,
    "locked_claiming": find_locked_candidates_claiming,
    "naked_subsets": find_naked_subsets,
    "hidden_subsets": find_hidden_subsets,

    # Uniqueness
    "bug": find_bug,
    "ur_type1": find_ur_type1,
    "ur_type2": find_ur_type2,
    "ur_type2b": find_ur_type2b,
    "ur_type3": find_ur_type3,
    "ur_type4": find_ur_type4,

    # Advanced (fish / wings / other)
    "x_wing_row": find_x_wing_rows,
    "x_wing_col": find_x_wing_cols,
    "swordfish_row": find_swordfish_rows,
    "swordfish_col": find_swordfish_cols,
    "jellyfish_row": find_jellyfish_rows,
    "jellyfish_col": find_jellyfish_cols,
    # "xy_wing": find_xy_wing,
    # "xyz_wing": find_xyz_wing,
    # "w_wing": find_w_wing,
}

TIERS = {
    # Tier 1 — Singles (cheapest; always first)
    1: [
        "naked_single",
        "hidden_single_row", "hidden_single_col", "hidden_single_box",
    ],

    # Tier 2 — Core Subsets (intersections then subsets)
    # Run locking first to simplify candidate sets for subsets.
    2: [
        "locked_pointing", "locked_claiming",
        "naked_subsets", "hidden_subsets",
    ],

    # Tier 3 — Uniqueness & BUG (safety nets; early–mid)
    # Light UR before heavy/advanced; BUG first if you have it.
    3: [
        "bug",
        "ur_type1", "ur_type2", "ur_type2b",
    ],

    # Tier 4 — Advanced (fish/wings/other)
    # Escalate by size: X-Wing → Swordfish → Jellyfish; then heavy UR.
    4: [
        "x_wing_row", "x_wing_col",
        "swordfish_row", "swordfish_col",
        "jellyfish_row", "jellyfish_col",
        # "xy_wing", "xyz_wing", "w_wing",
        "ur_type3", "ur_type4",
    ],

    5: [],
}

def find_deductions_batch(mask: np.ndarray, strategies: list[str]) -> list[list[dict]]:
    """Run selected strategies on mask batch."""
    if mask.ndim == 3:
        mask = mask[None, ...]
    N = mask.shape[0]
    all_deductions = [[] for _ in range(N)]
    for name in strategies:
        func = STRATEGY_FUNCTIONS.get(name)
        if func:
            func(mask, all_deductions)
        else:
            print(f"Warning: Strategy '{name}' not implemented.")
    return all_deductions



================================================
FILE: strategies/subsets.py
================================================
"""Subset strategies (pairs, triples, quads) using boolean candidates."""

from itertools import combinations
import numpy as np

from engine.utils import HOUSES


def _naked_subset_in_house(mask: np.ndarray, H, out, n_idx):
    cells = np.array([mask[r, c] for r, c in H])
    for k in range(2, 5):
        for combo in combinations(range(9), k):
            subset = cells[list(combo)]
            counts = subset.sum(axis=1)
            if np.any((counts < 2) | (counts > k)):
                continue
            union = subset.any(axis=0)
            if union.sum() != k:
                continue
            elims: dict[tuple[int, int], list[int]] = {}
            for idx in range(9):
                if idx in combo:
                    continue
                overlap = cells[idx] & union
                digits = np.where(overlap)[0] + 1
                if digits.size:
                    r, c = H[idx]
                    elims.setdefault((r, c), []).extend(digits.tolist())
            if elims:
                t = {2: "naked_pair", 3: "naked_triple", 4: "naked_quad"}[k]
                out[n_idx].append({
                    "type": t,
                    "cells": [H[i] for i in combo],
                    "eliminations": list(elims.items()),
                })


def _hidden_subset_in_house(mask: np.ndarray, H, out, n_idx):
    cells = np.array([mask[r, c] for r, c in H])
    for k in range(2, 5):
        for digits in combinations(range(9), k):
            digit_mask = cells[:, digits]
            positions = np.where(digit_mask.any(axis=1))[0]
            if len(positions) != k:
                continue
            elims: dict[tuple[int, int], list[int]] = {}
            for idx in positions:
                extra = [d + 1 for d in np.where(cells[idx])[0] if d not in digits]
                if extra:
                    r, c = H[idx]
                    elims[(r, c)] = extra
            if elims:
                t = {2: "hidden_pair", 3: "hidden_triple", 4: "hidden_quad"}[k]
                out[n_idx].append({
                    "type": t,
                    "cells": [H[i] for i in positions],
                    "eliminations": list(elims.items()),
                })


def find_naked_subsets(mask: np.ndarray, out: list[list[dict]]) -> None:
    N = mask.shape[0]
    for n in range(N):
        m = mask[n]
        for H in HOUSES:
            _naked_subset_in_house(m, H, out, n)


def find_hidden_subsets(mask: np.ndarray, out: list[list[dict]]) -> None:
    N = mask.shape[0]
    for n in range(N):
        m = mask[n]
        for H in HOUSES:
            _hidden_subset_in_house(m, H, out, n)




================================================
FILE: strategies/uniqueness.py
================================================
"""Uniqueness strategies implemented with boolean candidate grids."""

import numpy as np

from engine.utils import BLOCKS


def find_bug(mask: np.ndarray, out: list[list[dict]]) -> None:
    """BUG+1 strategy (Bi-value Universal Grave).

    Detects the BUG+1 pattern where all unsolved cells are bivalue except a
    single cell with three candidates, and house-digit parity holds. The lone
    cell is solved by the digit that has no partner in any of its three houses.
    """
    N = mask.shape[0]
    pcs = mask.sum(axis=3)
    for n in range(N):
        pc = pcs[n]
        m = mask[n]
        cells3 = np.argwhere(pc == 3)
        if cells3.shape[0] != 1:
            continue
        # all other unsolved cells must be bivalue
        if np.any((pc > 1) & (pc != 2) & (pc != 3)):
            continue

        # parity checks for each house and digit
        parity_ok = True
        for d in range(9):
            for r in range(9):
                row = m[r, :, d]
                placed = np.any((pc[r] == 1) & row)
                if not placed and row.sum() != 2:
                    parity_ok = False
                    break
            if not parity_ok:
                break
            for c in range(9):
                col = m[:, c, d]
                placed = np.any((pc[:, c] == 1) & col)
                if not placed and col.sum() != 2:
                    parity_ok = False
                    break
            if not parity_ok:
                break
            for cells in BLOCKS:
                arr = np.array([m[r, c, d] for r, c in cells])
                placed = np.any([pc[r, c] == 1 and m[r, c, d] for r, c in cells])
                if not placed and arr.sum() != 2:
                    parity_ok = False
                    break
            if not parity_ok:
                break
        if not parity_ok:
            continue

        r, c = map(int, cells3[0])
        digits = np.where(m[r, c])[0]
        good: list[int] = []
        blk = (r // 3) * 3 + (c // 3)
        for d in digits:
            if (
                m[r, :, d].sum() == 1
                and m[:, c, d].sum() == 1
                and sum(m[rr, cc, d] for rr, cc in BLOCKS[blk]) == 1
            ):
                good.append(int(d))
        if len(good) == 1:
            out[n].append({
                "type": "bug",
                "position": (r, c),
                "value": int(good[0] + 1),
            })


def find_ur_type1(mask: np.ndarray, out: list[list[dict]]) -> None:
    N = mask.shape[0]
    for n in range(N):
        m = mask[n]
        for r1 in range(8):
            for r2 in range(r1 + 1, 9):
                for c1 in range(8):
                    for c2 in range(c1 + 1, 9):
                        cells = [(r1, c1), (r1, c2), (r2, c1), (r2, c2)]
                        arrs = [m[r, c] for r, c in cells]
                        pairs: dict[tuple[int, int], list[int]] = {}
                        for idx, arr in enumerate(arrs):
                            digits = np.where(arr)[0]
                            if digits.size == 2:
                                pairs.setdefault(tuple(digits), []).append(idx)
                        for digits, idxs in pairs.items():
                            if len(idxs) == 3:
                                x0 = (set(range(4)) - set(idxs)).pop()
                                arr = arrs[x0]
                                if arr[list(digits)].all():
                                    extra = [d for d in np.where(arr)[0] if d not in digits]
                                    if len(extra) == 1:
                                        r, c = cells[x0]
                                        out[n].append({
                                            "type": "ur_type1",
                                            "position": (r, c),
                                            "value": int(extra[0] + 1),
                                        })


def _ur2_patterns(m: np.ndarray):
    """Yield UR2 pattern descriptions within mask ``m``.

    Each yielded dict contains:
        orientation: 'row' or 'col'
        floor: list of two (r, c) tuples for the floor cells
        extra: 0-based digit index locked in the floor
        block: block index if the floor is within a single block, else ``None``
    """
    for r1 in range(8):
        for r2 in range(r1 + 1, 9):
            for c1 in range(8):
                for c2 in range(c1 + 1, 9):
                    x11, x12, x21, x22 = (
                        m[r1, c1],
                        m[r1, c2],
                        m[r2, c1],
                        m[r2, c2],
                    )
                    # Horizontal floor at row r2
                    roof = [x11, x12]
                    floor = [x21, x22]
                    rd0, rd1 = np.where(roof[0])[0], np.where(roof[1])[0]
                    if rd0.size == 2 and np.array_equal(rd0, rd1):
                        fd0, fd1 = np.where(floor[0])[0], np.where(floor[1])[0]
                        if (
                            fd0.size == 3
                            and fd1.size == 3
                            and set(rd0).issubset(fd0)
                            and set(rd0).issubset(fd1)
                        ):
                            extra0 = list(set(fd0) - set(rd0))
                            extra1 = list(set(fd1) - set(rd0))
                            if extra0 and extra1 and extra0[0] == extra1[0]:
                                extra = extra0[0]
                                block = None
                                if c1 // 3 == c2 // 3:
                                    block = (r2 // 3) * 3 + (c1 // 3)
                                yield {
                                    "orientation": "row",
                                    "floor": [(r2, c1), (r2, c2)],
                                    "extra": extra,
                                    "block": block,
                                }
                    # Vertical floor at column c2
                    roof = [x11, x21]
                    floor = [x12, x22]
                    rd0, rd1 = np.where(roof[0])[0], np.where(roof[1])[0]
                    if rd0.size == 2 and np.array_equal(rd0, rd1):
                        fd0, fd1 = np.where(floor[0])[0], np.where(floor[1])[0]
                        if (
                            fd0.size == 3
                            and fd1.size == 3
                            and set(rd0).issubset(fd0)
                            and set(rd0).issubset(fd1)
                        ):
                            extra0 = list(set(fd0) - set(rd0))
                            extra1 = list(set(fd1) - set(rd0))
                            if extra0 and extra1 and extra0[0] == extra1[0]:
                                extra = extra0[0]
                                block = None
                                if r1 // 3 == r2 // 3:
                                    block = (r1 // 3) * 3 + (c2 // 3)
                                yield {
                                    "orientation": "col",
                                    "floor": [(r1, c2), (r2, c2)],
                                    "extra": extra,
                                    "block": block,
                                }


def find_ur_type2(mask: np.ndarray, out: list[list[dict]]) -> None:
    """UR Type 2: line-locked common extra digit."""
    N = mask.shape[0]
    for n in range(N):
        m = mask[n]
        for pat in _ur2_patterns(m):
            digit = pat["extra"]
            elims: dict[tuple[int, int], list[int]] = {}
            if pat["orientation"] == "row":
                r = pat["floor"][0][0]
                cols = {c for _, c in pat["floor"]}
                for c in range(9):
                    if c not in cols and m[r, c, digit]:
                        elims.setdefault((r, c), []).append(int(digit + 1))
            else:
                c = pat["floor"][0][1]
                rows = {r for r, _ in pat["floor"]}
                for r in range(9):
                    if r not in rows and m[r, c, digit]:
                        elims.setdefault((r, c), []).append(int(digit + 1))
            if elims:
                out[n].append({"type": "ur_type2", "eliminations": list(elims.items())})


def find_ur_type2b(mask: np.ndarray, out: list[list[dict]]) -> None:
    """UR Type 2b: block-locked extension of UR2."""
    N = mask.shape[0]
    for n in range(N):
        m = mask[n]
        for pat in _ur2_patterns(m):
            block = pat["block"]
            if block is None:
                continue
            digit = pat["extra"]
            floor = set(pat["floor"])
            elims: dict[tuple[int, int], list[int]] = {}
            for r, c in BLOCKS[block]:
                if (r, c) not in floor and m[r, c, digit]:
                    elims.setdefault((r, c), []).append(int(digit + 1))
            if elims:
                out[n].append({"type": "ur_type2b", "eliminations": list(elims.items())})


def find_ur_type3(mask: np.ndarray, out: list[list[dict]]) -> None:
    """UR Type 3: different extras on the floor plus a {c,d} bivalue in the same house."""
    N = mask.shape[0]
    for n in range(N):
        m = mask[n]
        for r1 in range(8):
            for r2 in range(r1 + 1, 9):
                for c1 in range(8):
                    for c2 in range(c1 + 1, 9):
                        x11, x12, x21, x22 = (
                            m[r1, c1],
                            m[r1, c2],
                            m[r2, c1],
                            m[r2, c2],
                        )

                        # Horizontal floor at row r2
                        roof = [x11, x12]
                        floor = [x21, x22]
                        rd0, rd1 = np.where(roof[0])[0], np.where(roof[1])[0]
                        if rd0.size == 2 and np.array_equal(rd0, rd1):
                            a, b = rd0
                            fd0, fd1 = np.where(floor[0])[0], np.where(floor[1])[0]
                            if {a, b}.issubset(fd0) and {a, b}.issubset(fd1):
                                extras0 = set(fd0) - {a, b}
                                extras1 = set(fd1) - {a, b}
                                for c in extras0 - extras1:
                                    for d in extras1 - extras0:
                                        if c == d:
                                            continue
                                        y_cell = None
                                        for c3 in range(9):
                                            if c3 in (c1, c2):
                                                continue
                                            s = np.where(m[r2, c3])[0]
                                            if len(s) == 2 and set(s) == {c, d}:
                                                y_cell = (r2, c3)
                                                break
                                        if y_cell is None:
                                            continue
                                        elims: dict[tuple[int, int], list[int]] = {}
                                        for c4 in range(9):
                                            if c4 in (c1, c2, y_cell[1]):
                                                continue
                                            vals: list[int] = []
                                            if m[r2, c4, c]:
                                                vals.append(int(c + 1))
                                            if m[r2, c4, d]:
                                                vals.append(int(d + 1))
                                            if vals:
                                                elims[(r2, c4)] = vals
                                        if elims:
                                            out[n].append(
                                                {
                                                    "type": "ur_type3",
                                                    "eliminations": list(elims.items()),
                                                }
                                            )

                        # Vertical floor at column c2
                        roof = [x11, x21]
                        floor = [x12, x22]
                        rd0, rd1 = np.where(roof[0])[0], np.where(roof[1])[0]
                        if rd0.size == 2 and np.array_equal(rd0, rd1):
                            a, b = rd0
                            fd0, fd1 = np.where(floor[0])[0], np.where(floor[1])[0]
                            if {a, b}.issubset(fd0) and {a, b}.issubset(fd1):
                                extras0 = set(fd0) - {a, b}
                                extras1 = set(fd1) - {a, b}
                                for c in extras0 - extras1:
                                    for d in extras1 - extras0:
                                        if c == d:
                                            continue
                                        y_cell = None
                                        for r3 in range(9):
                                            if r3 in (r1, r2):
                                                continue
                                            s = np.where(m[r3, c2])[0]
                                            if len(s) == 2 and set(s) == {c, d}:
                                                y_cell = (r3, c2)
                                                break
                                        if y_cell is None:
                                            continue
                                        elims: dict[tuple[int, int], list[int]] = {}
                                        for r4 in range(9):
                                            if r4 in (r1, r2, y_cell[0]):
                                                continue
                                            vals: list[int] = []
                                            if m[r4, c2, c]:
                                                vals.append(int(c + 1))
                                            if m[r4, c2, d]:
                                                vals.append(int(d + 1))
                                            if vals:
                                                elims[(r4, c2)] = vals
                                        if elims:
                                            out[n].append(
                                                {
                                                    "type": "ur_type3",
                                                    "eliminations": list(elims.items()),
                                                }
                                            )


def find_ur_type4(mask: np.ndarray, out: list[list[dict]]) -> None:
    """UR Type 4: block-locked UR digit across the floor pair."""
    N = mask.shape[0]
    for n in range(N):
        m = mask[n]
        for r1 in range(8):
            for r2 in range(r1 + 1, 9):
                for c1 in range(8):
                    for c2 in range(c1 + 1, 9):
                        x11, x12, x21, x22 = (
                            m[r1, c1],
                            m[r1, c2],
                            m[r2, c1],
                            m[r2, c2],
                        )

                        # Horizontal floor at row r2
                        if c1 // 3 == c2 // 3:  # floor cells within same block
                            roof = [x11, x12]
                            floor = [x21, x22]
                            rd0, rd1 = np.where(roof[0])[0], np.where(roof[1])[0]
                            if rd0.size == 2 and np.array_equal(rd0, rd1):
                                a, b = rd0
                                fd0, fd1 = np.where(floor[0])[0], np.where(floor[1])[0]
                                if {a, b}.issubset(fd0) and {a, b}.issubset(fd1):
                                    block = (r2 // 3) * 3 + (c1 // 3)
                                    for d in (a, b):
                                        cells_d = [
                                            (rr, cc)
                                            for rr, cc in BLOCKS[block]
                                            if m[rr, cc, d]
                                        ]
                                        if set(cells_d) == {(r2, c1), (r2, c2)}:
                                            d_other = b if d == a else a
                                            elims: dict[tuple[int, int], list[int]] = {}
                                            for r, c in [(r2, c1), (r2, c2)]:
                                                if m[r, c, d_other]:
                                                    elims[(r, c)] = [int(d_other + 1)]
                                            if elims:
                                                out[n].append(
                                                    {
                                                        "type": "ur_type4",
                                                        "eliminations": list(elims.items()),
                                                    }
                                                )
                                            break

                        # Vertical floor at column c2
                        if r1 // 3 == r2 // 3:  # floor cells within same block
                            roof = [x11, x21]
                            floor = [x12, x22]
                            rd0, rd1 = np.where(roof[0])[0], np.where(roof[1])[0]
                            if rd0.size == 2 and np.array_equal(rd0, rd1):
                                a, b = rd0
                                fd0, fd1 = np.where(floor[0])[0], np.where(floor[1])[0]
                                if {a, b}.issubset(fd0) and {a, b}.issubset(fd1):
                                    block = (r1 // 3) * 3 + (c2 // 3)
                                    for d in (a, b):
                                        cells_d = [
                                            (rr, cc)
                                            for rr, cc in BLOCKS[block]
                                            if m[rr, cc, d]
                                        ]
                                        if set(cells_d) == {(r1, c2), (r2, c2)}:
                                            d_other = b if d == a else a
                                            elims: dict[tuple[int, int], list[int]] = {}
                                            for r, c in [(r1, c2), (r2, c2)]:
                                                if m[r, c, d_other]:
                                                    elims[(r, c)] = [int(d_other + 1)]
                                            if elims:
                                                out[n].append(
                                                    {
                                                        "type": "ur_type4",
                                                        "eliminations": list(elims.items()),
                                                    }
                                                )
                                            break




================================================
FILE: strategies/wings.py
================================================
# Wings strategies: XY-Wing, XYZ-Wing
# Placeholder file - implement strategies here 


================================================
FILE: sudoku_extreme/test.csv
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:a2fd52aea23d331d5b4ee723c856236e838a9fb9a70e66f4e0e0cf26c338c6a8
size 79360390



================================================
FILE: sudoku_extreme/train.csv
================================================
version https://git-lfs.github.com/spec/v1
oid sha256:64b46674db0148e0d73a16346dadeb2b1c00824d3fca3f85b2ae7037f6b4b38e
size 718819925



================================================
FILE: tests/test_bug.py
================================================
import numpy as np

from strategies.uniqueness import find_bug


def test_bug_negative():
    mask = np.zeros((1, 9, 9, 9), dtype=bool)
    solved = np.array([
        [1,2,3,4,5,6,7,8,9],
        [4,5,6,7,8,9,1,2,3],
        [7,8,9,1,2,3,4,5,6],
        [2,3,4,5,6,7,8,9,1],
        [5,6,7,8,9,1,2,3,4],
        [8,9,1,2,3,4,5,6,7],
        [3,4,5,6,7,8,9,1,2],
        [6,7,8,9,1,2,3,4,5],
        [9,1,2,3,4,5,6,7,8],
    ]) - 1
    for r in range(9):
        for d in range(9):
            c = np.where(solved[r] == d)[0][0]
            mask[0, r, c, d] = True
            mask[0, r, (c + 3) % 9, d] = True
    out = [[]]
    find_bug(mask, out)
    assert out[0] == []



================================================
FILE: tests/test_fish.py
================================================
import numpy as np

from strategies.fish import find_x_wing_rows, find_swordfish_rows


def test_x_wing_and_swordfish():
    # X-Wing on digit1 rows
    mask = np.zeros((1, 9, 9, 9), dtype=bool)
    rows = [0, 2]
    cols = [0, 2]
    for r in rows:
        for c in cols:
            mask[0, r, c, 0] = True
    for r in range(9):
        if r not in rows:
            for c in cols:
                mask[0, r, c, 0] = True
    out = [[]]
    find_x_wing_rows(mask, out)
    assert any(1 in dict(ded["eliminations"]).get((1, 0), []) for ded in out[0])
    # Swordfish on digit2 rows
    mask2 = np.zeros((1, 9, 9, 9), dtype=bool)
    rows3 = [0, 1, 2]
    cols3 = [0, 1, 2]
    for r in rows3:
        for c in cols3:
            mask2[0, r, c, 1] = True
    for r in range(3, 9):
        for c in cols3:
            mask2[0, r, c, 1] = True
    out2 = [[]]
    find_swordfish_rows(mask2, out2)
    assert any(2 in dict(ded["eliminations"]).get((3, 0), []) for ded in out2[0])



================================================
FILE: tests/test_intersections.py
================================================
import numpy as np

from strategies.intersections import (
    find_locked_candidates_pointing,
    find_locked_candidates_claiming,
)


def test_pointing_and_claiming():
    mask = np.zeros((1, 9, 9, 9), dtype=bool)
    # Pointing setup
    mask[0, 0, 0, 0] = True
    mask[0, 0, 1, 0] = True
    mask[0, 0, 4, 0] = True  # candidate to be eliminated
    out = [[]]
    find_locked_candidates_pointing(mask, out)
    assert any(1 in dict(ded["eliminations"]).get((0, 4), []) for ded in out[0])
    # Claiming setup
    mask2 = np.zeros((1, 9, 9, 9), dtype=bool)
    mask2[0, 0, 0, 1] = True
    mask2[0, 0, 1, 1] = True
    mask2[0, 1, 2, 1] = True  # cell in block outside row0
    out2 = [[]]
    find_locked_candidates_claiming(mask2, out2)
    assert any(2 in dict(ded["eliminations"]).get((1, 2), []) for ded in out2[0])



================================================
FILE: tests/test_singles.py
================================================
import numpy as np

from strategies.singles import (
    find_naked_singles,
    find_hidden_singles_rows,
)


def test_naked_and_hidden_singles():
    mask = np.ones((1, 9, 9, 9), dtype=bool)
    # Naked single at (0,0) digit 5
    mask[0, 0, 0, :] = False
    mask[0, 0, 0, 4] = True
    # Hidden single for digit 2 in row 0 at (0,1)
    mask[0, 0, 1, :] = False
    mask[0, 0, 1, [1, 2]] = True
    for c in range(9):
        if c != 1:
            mask[0, 0, c, 1] = False
    out = [[]]
    find_naked_singles(mask, out)
    assert out[0] == [{"type": "naked_single", "position": (0, 0), "value": 5}]
    out2 = [[]]
    find_hidden_singles_rows(mask, out2)
    assert out2[0] == [{"type": "hidden_single_row", "position": (0, 1), "value": 2}]



================================================
FILE: tests/test_subsets.py
================================================
import numpy as np
import pytest

from strategies.subsets import find_naked_subsets, find_hidden_subsets


@pytest.mark.parametrize("k, stype", [(2, "pair"), (3, "triple"), (4, "quad")])
def test_naked_subsets(k, stype):
    mask = np.ones((1, 9, 9, 9), dtype=bool)
    patterns = {
        2: [(1, 2), (1, 2)],
        3: [(1, 2), (2, 3), (1, 3)],
        4: [(1, 2), (2, 3), (3, 4), (1, 4)],
    }[k]
    for idx, digs in enumerate(patterns):
        mask[0, 0, idx, :] = False
        for d in digs:
            mask[0, 0, idx, d - 1] = True
    out = [[]]
    find_naked_subsets(mask, out)
    assert any(d["type"] == f"naked_{stype}" for d in out[0])


@pytest.mark.parametrize("k, stype", [(2, "pair"), (3, "triple"), (4, "quad")])
def test_hidden_subsets(k, stype):
    mask = np.ones((1, 9, 9, 9), dtype=bool)
    digits = list(range(1, k + 1))
    for c in range(9):
        if c >= k:
            for d in digits:
                mask[0, 0, c, d - 1] = False
    out = [[]]
    find_hidden_subsets(mask, out)
    assert any(d["type"] == f"hidden_{stype}" for d in out[0])



================================================
FILE: tests/test_uniqueness.py
================================================
import numpy as np

from strategies.uniqueness import (
    find_ur_type1,
    find_ur_type2,
    find_ur_type2b,
    find_ur_type3,
    find_ur_type4,
)


def test_ur_type1_positive():
    mask = np.zeros((1, 9, 9, 9), dtype=bool)
    for r, c in [(0, 0), (0, 1), (1, 0)]:
        mask[0, r, c, 0] = True
        mask[0, r, c, 1] = True
    mask[0, 1, 1, 0] = True
    mask[0, 1, 1, 1] = True
    mask[0, 1, 1, 2] = True
    out = [[]]
    find_ur_type1(mask, out)
    assert out[0] == [{"type": "ur_type1", "position": (1, 1), "value": 3}]


def test_ur_type1_negative():
    mask = np.zeros((1, 9, 9, 9), dtype=bool)
    for r, c in [(0, 0), (0, 1), (1, 0)]:
        mask[0, r, c, 0] = True
        mask[0, r, c, 1] = True
    mask[0, 1, 1, 0] = True
    mask[0, 1, 1, 1] = True
    mask[0, 1, 1, 2] = True
    mask[0, 1, 1, 3] = True
    out = [[]]
    find_ur_type1(mask, out)
    assert out[0] == []


def test_ur_type2_positive():
    mask = np.zeros((1, 9, 9, 9), dtype=bool)
    # Roof cells with digits 1 and 2
    for r, c in [(0, 0), (0, 1)]:
        mask[0, r, c, 0] = True
        mask[0, r, c, 1] = True
    # Floor cells with digits 1,2,3
    for r, c in [(1, 0), (1, 1)]:
        mask[0, r, c, 0] = True
        mask[0, r, c, 1] = True
        mask[0, r, c, 2] = True
    # Another cell in the floor row containing digit 3
    mask[0, 1, 2, 2] = True
    out = [[]]
    find_ur_type2(mask, out)
    assert out[0] == [
        {"type": "ur_type2", "eliminations": [((1, 2), [3])]},
    ]


def test_ur_type2b_positive():
    mask = np.zeros((1, 9, 9, 9), dtype=bool)
    # Roof cells with digits 1 and 2
    for r, c in [(0, 0), (0, 1)]:
        mask[0, r, c, 0] = True
        mask[0, r, c, 1] = True
    # Floor cells with digits 1,2,3 (same block)
    for r, c in [(1, 0), (1, 1)]:
        mask[0, r, c, 0] = True
        mask[0, r, c, 1] = True
        mask[0, r, c, 2] = True
    # Cell in the same block but outside the floor containing digit 3
    mask[0, 0, 2, 2] = True
    out = [[]]
    find_ur_type2b(mask, out)
    assert out[0] == [
        {"type": "ur_type2b", "eliminations": [((0, 2), [3])]},
    ]


def test_ur_type3_positive():
    mask = np.zeros((1, 9, 9, 9), dtype=bool)
    # Roof cells with digits 1 and 2
    for r, c in [(0, 0), (0, 1)]:
        mask[0, r, c, 0] = True
        mask[0, r, c, 1] = True
    # Floor cells with digits 1,2 and different extras 3 and 4
    mask[0, 1, 0, 0] = True
    mask[0, 1, 0, 1] = True
    mask[0, 1, 0, 2] = True  # extra 3
    mask[0, 1, 1, 0] = True
    mask[0, 1, 1, 1] = True
    mask[0, 1, 1, 3] = True  # extra 4
    # Bivalue {3,4} in same row
    mask[0, 1, 2, 2] = True
    mask[0, 1, 2, 3] = True
    # Another cell in the row containing 3 and 4 to be eliminated
    mask[0, 1, 3, 2] = True
    mask[0, 1, 3, 3] = True
    out = [[]]
    find_ur_type3(mask, out)
    assert out[0] == [
        {"type": "ur_type3", "eliminations": [((1, 3), [3, 4])]},
    ]


def test_ur_type4_positive():
    mask = np.zeros((1, 9, 9, 9), dtype=bool)
    # Roof cells with digits 1 and 2
    for r, c in [(0, 0), (0, 1)]:
        mask[0, r, c, 0] = True
        mask[0, r, c, 1] = True
    # Floor cells in same block (rows 3, cols 0-1) containing digits 1 and 2
    for c in [0, 1]:
        mask[0, 3, c, 0] = True
        mask[0, 3, c, 1] = True
    # Digit 1 appears only in the floor cells within the block
    out = [[]]
    find_ur_type4(mask, out)
    assert out[0] == [
        {"type": "ur_type4", "eliminations": [((3, 0), [2]), ((3, 1), [2])]},
    ]



